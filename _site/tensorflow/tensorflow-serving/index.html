<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Deploying Keras models using TensorFlow Serving and Flask - yjucho’s blog</title>
<meta name="description" content="  이 글은 Himanshu Rawlani의 Deploying Keras models using TensorFlow Serving and Flask을 참고하여 작성한 글입니다.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_EN">
<meta property="og:site_name" content="yjucho's blog">
<meta property="og:title" content="Deploying Keras models using TensorFlow Serving and Flask">
<meta property="og:url" content="http://localhost:4000/tensorflow/tensorflow-serving/">


  <meta property="og:description" content="  이 글은 Himanshu Rawlani의 Deploying Keras models using TensorFlow Serving and Flask을 참고하여 작성한 글입니다.">







  <meta property="article:published_time" content="2018-12-26T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/tensorflow/tensorflow-serving/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "yjucho",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="yjucho's blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">yjucho's blog</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/category/" >Category</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/img/bio-photo.jpg" alt="yjucho" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">yjucho</h3>
    
    
      <p class="author__bio" itemprop="description">
        Data science, Deep Learning, AI
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Seoul, Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:jyj0729@gmail.com"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
          
        
          
        
          
        
          
            <li><a href="https://www.facebook.com/yjucho"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i> Facebook</a></li>
          
        
          
            <li><a href="https://github.com/yjucho1"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Deploying Keras models using TensorFlow Serving and Flask">
    <meta itemprop="description" content="  이 글은 Himanshu Rawlani의 Deploying Keras models using TensorFlow Serving and Flask을 참고하여 작성한 글입니다.">
    <meta itemprop="datePublished" content="December 26, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Deploying Keras models using TensorFlow Serving and Flask
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <blockquote>
  <p>이 글은 <a href="https://towardsdatascience.com/deploying-keras-models-using-tensorflow-serving-and-flask-508ba00f1037">Himanshu Rawlani의 Deploying Keras models using TensorFlow Serving and Flask</a>을 참고하여 작성한 글입니다.</p>
</blockquote>

<ul>
  <li>원글은 tensorflow serving 설치방법을 apt-get(리눅스 환경에서만 가능)를 이용하였으나, 본 글은 docker를 이용해 설치하는 방법을 이용해 MAC OSX에서 테스트한 내용을 추가하였습니다.</li>
  <li>원글은 api서버로 Flask를 이용하였으나, 본 글은 django를 이용한 예제을 추가하였습니다.
django APP의 전체코드는 <a href="https://github.com/yjucho1/air-pollution">이 깃헙 레포지토리</a>를 참고하십시요.</li>
  <li>추가된 부분은 Blockquotes 표시되어 있습니다.</li>
</ul>

<p><img src="/assets/img/2018-12-26/fig0.png" /></p>

<p>학습한 모델을 상용환경에 배포하거나, 사용하기 쉬운 API endpoints로 제공해야할 때가 있습니다. 예를 들어, 누구든지 전처리나, 딥러닝 알고리즘에 대한 기술적인 지식없이도 POST 리퀘스트를 생성해서 모델의 추정값을 JSON 형태로 반환된 결과값을 얻을수 있게 URL endpoint를 제공할수 있습니다.</p>

<p>이 튜토리얼에서는 keras로 만들어진 이미지 분류를 위한 CNN 모델 중 하나인 InceptionV3를 배포하기 위해 Tensorflow serving server 생성하는 법을 이야기할 것입니다. 또한 POST 리퀘스트를 수락하기 위해서 간단한 Flask server(또는 Django)를 만들어, 이미지를 전처리한 후 Tensorflow serving server에 전송한 후 JSON 형태의 결과값을 반환하도록 할 예정입니다.</p>

<h2 id="what-is-tensorflow-serving---tensorflow-servign이란">What is TensorFlow Serving? - Tensorflow Servign이란?</h2>

<p>Serving은 모델을 학습한 후 학습된 모델을 실제 서비스에 적용하는 것입니다.</p>

<p><img src="/assets/img/2018-12-26/fig1.png" />
<small>더 자세히 알고 싶다면, <a href="https://www.youtube.com/watch?v=q_IkJcPyNl0">여기</a>를 참고하세요.</small></p>

<p>텐서플로우 서빙을 이용하면 모델을 상용환경에 쉽고 빠르게 적용할 수 있습니다. 새로운 모델을 안전하게 배포하고 동일한 서버 아키텍쳐와 API 환경을 유지하면서 또 다른 실험을 수행할수 있는 환경을 제공합니다. 기본적으로 TensorFlow와 호환되지만 다른 프레임워크에서 학습된 모델도 지원하고 확장할 수 있습니다.</p>

<h2 id="installing-tensorflow-serving---설치하기">Installing TensorFlow Serving - 설치하기</h2>

<p>사전 준비 : 파이썬 가상환경을 만든 후 텐서플로우 백엔드의 케라스를 설치하세요. 자세한 것은 <a href="https://keras.io/#installation">이곳</a>을 참고하세요.</p>

<p>참고 : 이 튜토리얼의 모든 커멘드는 우분투 18.04.1 LTS에서의 파이썬 가상환경에서 실행되었습니다.</p>

<p>이제 가상환경 내에서 다음과 같은 커멘드를 실행하십시오.(root 권한을 위해서 sudo 를 사용하십시오)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ apt install curl
$ echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list &amp;&amp; curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -
$ apt-get update
$ apt-get install tensorflow-model-server
$ tensorflow_model_server --version
TensorFlow ModelServer: 1.10.0-dev
TensorFlow Library: 1.11.0
$ python  --version
Python 3.6.6
</code></pre></div></div>

<p>새로운 버전으로 업그레이드하는 명령어는 다음을 사용하세요.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ apt-get upgrade tensorflow-model-server
</code></pre></div></div>

<blockquote>
  <p>apt-get이 실행되지 않는 경우, 예를 들어 MAC OSX에서는 Docker를 이용할 수 있습니다. <br /> <br />
<strong>도커 다운로드</strong> :<a href="- https://docs.docker.com/docker-for-mac/">Docker for mac</a> <br />
다운받은 도커를 실행시킨후 터미널에서 아래와 같은 명령어를 수행하면 tensorflow-serving이 설치된 이미지를 받을 수 있습니다. 텐서플루우나 케라스 패키지를 따로 설치할 필요가 없습니다.</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker pull tensorflow/serving
</code></pre></div>  </div>
</blockquote>

<h2 id="directory-overview-of-what-we-are-going-tobuild">Directory overview of what we are going to build</h2>

<p>먼저, 디렉토리 구조를 이해하는 것이 조금 더 명확한 큰 그림을 이해하는데 도움이 됩니다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(tensorflow) ubuntu@Himanshu:~/Desktop/Medium/keras-and-tensorflow-serving$ tree -c
└── keras-and-tensorflow-serving
    ├── README.md
    ├── my_image_classifier
    │   └── 1
    │       ├── saved_model.pb
    │       └── variables
    │           ├── variables.data-00000-of-00001
    │           └── variables.index
    ├── test_images
    │   ├── car.jpg
    │   └── car.png
    ├── flask_server
    │   ├── app.py
    │   ├── flask_sample_request.py
    └── scripts
        ├── download_inceptionv3_model.py
        ├── inception.h5
        ├── auto_cmd.py
        ├── export_saved_model.py
        ├── imagenet_class_index.json
        └── serving_sample_request.py
6 directories, 15 files
</code></pre></div></div>

<p>모든 파일들은 <a href="https://github.com/himanshurawlani/keras-and-tensorflow-serving">이 깃허브 레포지토리</a>에서 다운로드할수 있습니다.</p>

<p><code class="highlighter-rouge">https://github.com/himanshurawlani/keras-and-tensorflow-serving</code></p>

<h2 id="exporting-keras-model-for-tensorflow-serving">Exporting Keras model for Tensorflow Serving</h2>

<p>이 튜토리얼에서는 InceptionV3 모델을 다운로드하여 h5파일로 저장하여 이용합니다. download_inceptionv3_model.py를 이용하세요. Karas.application 라이브러리(<a href="https://github.com/keras-team/keras-applications">here</a>)에 있는 다른 모델들도 모두 가능합니다. 또는 학습한 커스텀 모델(.h5)이 있다면 이 단계는 건너뛰어도 됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras.applications.inception_v3</span> <span class="kn">import</span> <span class="n">InceptionV3</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>

<span class="n">inception_model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s">'imagenet'</span><span class="p">,</span> <span class="n">input_tensor</span><span class="o">=</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">inception_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'inception.h5'</span><span class="p">)</span>
</code></pre></div></div>

<p>위의 스크립트를 실행한 후에는 다음과 같은 결과가 화면에 출력됩니다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python download_inceptionv3_model.py
Using TensorFlow backend.
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5
96116736/96112376 [==============================] - 161s 2us/step
</code></pre></div></div>

<p>이제 케라스 모델 형태로 저장된 CNN 모델이 로컬 파일에 있습니다. 우리는 텐서플로우 서버가 처리할수 있도록 이 모델을 내보내야합니다. 이 작업은 export_saved_model.py 스크립트를 이용하면 됩니다.</p>

<p>TensorFlow는 SavedModel 형식을 모델 내보내기 위한 범용 형식으로 사용합니다. Keras 모델은 TensorFlow 객체의 관점에서 완벽하게 호환되기 때문에 Tensorflow 메서드를 사용하여 아무 문제없이 잘 내보낼 수 있습니다. TensorFlow의 tf.saved_model.simple_save() 함수를 이용하면 되고, 대부분의 사용 사례에서 잘 작동합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c"># The export path contains the name and the version of the model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_learning_phase</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c"># Ignore dropout at inference</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">'./inception.h5'</span><span class="p">)</span>
<span class="n">export_path</span> <span class="o">=</span> <span class="s">'../my_image_classifier/1'</span>

<span class="c"># Fetch the Keras session and save the model</span>
<span class="c"># The signature definition is defined by the input and output tensors</span>
<span class="c"># And stored with the default serving key</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">simple_save</span><span class="p">(</span>
        <span class="n">sess</span><span class="p">,</span>
        <span class="n">export_path</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s">'input_image'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="nb">input</span><span class="p">},</span>
        <span class="n">outputs</span><span class="o">=</span><span class="p">{</span><span class="n">t</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">})</span>
</code></pre></div></div>

<p>결과 :</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python export_saved_model.py
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
</code></pre></div></div>

<p>WARNING 메세지를 볼수 있지만, 여기서는 인퍼런스에서만 모델을 사용할 것이기 때문에 무시하시면 됩니다. 나중에 모델을 학습하기 위해서는 모델을 로딩한 후 compile() 함수를 실행해주어야 합니다. 스크립트를 성공적으로 실행시키면, 다음과 같은 파일들이 my_image_classifier 디렉토리에 저장될 것입니다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── my_image_classifier
   └── 1
       ├── saved_model.pb
       └── variables
           ├── variables.data-00000-of-00001
           └── variables.index
2 directories, 3 files
</code></pre></div></div>

<p>만약 나중에 모델을 업데이트한다고 하면(학습데이터를 더 수집하거나, 업데이트된 데이터셋으로 모델을 학습하는 상황), 아래와 같이 수행할수 있습니다.</p>

<ol>
  <li>새로운 케라스 모델에 대해서 동일한 스크립트를 수행합니다.</li>
  <li>단, export_path=‘../my_image_classifier/1’를 export_path=‘../my_image_classifier/2’로 변경합니다.</li>
</ol>

<p>TensorFlow Serving은 자동으로 my_image_classifier 디렉토리 내에서 새로운 버전의 모델을 감지하여, 서버에서 업데이트할 것입니다.</p>

<h3 id="starting-tensorflow-servingserver---서빙-시작하기">Starting TensorFlow Serving server - 서빙 시작하기</h3>

<p>로컬환경에서 서빙 서버를 시작하기 위해서 다음과 같은 커멘드를 실행하세요.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tensorflow_model_server \
 --model_base_path=/keras-and-tensorflow-serving/my_image_classifier \
 --rest_api_port=9000 --model_name=ImageClassifier
</code></pre></div></div>

<ul>
  <li>
    <p>–model_base_path : 절대경로를 사용해야합니다. 그렇지 않으면 다음과 같은 에러 메세지가 나타납니다.<br />
<code class="highlighter-rouge">Failed to start server. Error: Invalid argument: Expected model ImageClassifier to have an absolute path or URI; got base_path()=./my_image_classifier</code></p>
  </li>
  <li>
    <p>–rest_api_port : Tensorflow Serving은 gRPC ModelServer를 포트 8500에서 시작하고 REST API는 포트 9000에서 사용할 수 있습니다.</p>
  </li>
  <li>
    <p>–model_name : POST 리퀘스트를 보내게 될 서빙 서버의 이름입니다. 원하는 이름을 적으면 됩니다.</p>
  </li>
</ul>

<blockquote>
  <p>도커를 이용하는 경우 다음 명령어를 사용하세요. (도커에서는 forcast-lstm 디렉토리 내에 seq2seq모델인 lstm 모델을 저장하였습니다.)</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run -p 8501:8501 \
--mount type=bind,source=/your-path/forcast-lstm,\
target=/models/lstm \
 -e MODEL_NAME=lstm -t tensorflow/serving
</code></pre></div>  </div>
  <p><strong>type=bind부터 source,target까지 띄어쓰기가 없도록 주의하세요.</strong></p>
</blockquote>

<h3 id="testing-our-tensorflow-servingserver---서빙-테스트하기">Testing our TensorFlow Serving server - 서빙 테스트하기</h3>
<p><img src="/assets/img/2018-12-26/fig2.jpeg" />
<small>raw data에서 production model까지</small></p>

<p>serving_sample_request.py 스크립트는 Tensorflow Serving server에 POST 리퀘스트를 생성합니다. 입력 이미지는 커멘드라인의 인자로 전달됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">inception_v3</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>

<span class="c"># Argument parser for giving input image_path from command line</span>
<span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-i"</span><span class="p">,</span> <span class="s">"--image"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">help</span><span class="o">=</span><span class="s">"path of the image"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="n">image_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">'image'</span><span class="p">]</span>
<span class="c"># Preprocessing our input image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)))</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="c"># this line is added because of a bug in tf_serving(1.10.0-dev)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float16'</span><span class="p">)</span>

<span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"instances"</span><span class="p">:</span> <span class="p">[{</span><span class="s">'input_image'</span><span class="p">:</span> <span class="n">img</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}]</span>
<span class="p">}</span>

<span class="c"># sending post request to TensorFlow Serving server</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">'http://localhost:9000/v1/models/ImageClassifier:predict'</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

<span class="c"># Decoding the response</span>
<span class="c"># decode_predictions(preds, top=5) by default gives top 5 results</span>
<span class="c"># You can pass "top=10" to get top 10 predicitons</span>
<span class="k">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">inception_v3</span><span class="o">.</span><span class="n">decode_predictions</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>
<p>결과 :</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python serving_sample_request.py -i ../test_images/car.png
Using TensorFlow backend.
[["n04285008", "sports_car", 0.998414], ["n04037443", "racer", 0.00140099], ["n03459775", "grille", 0.000160794], ["n02974003", "car_wheel", 9.57862e-06], ["n03100240", "convertible", 6.01581e-06]]
</code></pre></div></div>

<p>TensorFlow Serving server의 첫번째 리퀘스트는 이후 리퀘스트에 비해서 다소 시간이 좀 더 걸릴 수 있습니다.</p>

<blockquote>
  <p>간단히 터미널에서도 테스트를 해볼수 있습니다.</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ curl -d '{"instances": 'your-input-data'}' -X POST \
http://localhost:8501/v1/models/lstm:predict
</code></pre></div>  </div>
  <p>결과 :</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "predictions": [[0.208057, 0.199001, 0.195517, 0.197754, 0.203455, 0.211004]
    ]
}
</code></pre></div>  </div>
</blockquote>

<h3 id="why-do-we-need-a-flaskserver---flask는-왜-필요한가">Why do we need a Flask server? - Flask는 왜 필요한가</h3>

<p>serving_sample_request.py(프로트엔드 콜러)에서는 이미지 전처리 부분을 포함합니다. 다음과 같은 이유 때문에 TensorFlow serving server 상위단에서 Flask server를 사용해야합니다.</p>

<ul>
  <li>프론트엔드팀에 API 엔드 포인트를 제공할때 전처리 과정의 부담을 주지 않습니다.</li>
  <li>우리는 항상 Python 백엔드 서버 (예 : Node.js 서버)를 가지고 있지 않을 수도 있습니다. 따라서 전처리를 위해 numpy 및 keras 라이브러리를 사용하는 것이 어려울 수 있습니다.</li>
  <li>여러 모델을 제공하려는 경우 여러 개의 TensorFlow Serving 서버를 만들어야하며 프론트 엔드 코드에 새 URL을 추가해야합니다. 그러나 Flask 서버는 도메인 URL을 동일하게 유지하며 새로운 경로 (함수) 만 추가하면됩니다.</li>
  <li>Flask 앱에서 서브스크립션 기반 액세스, 예외 처리 및 기타 작업을 수행 할 수 있습니다.</li>
</ul>

<p>즉 우리는 TensorFlow Serving servers와 Frontend사이의 타이트한 커플링을 제거하기 위해 Flask를 백엔드 서버로 사용하고자 하는 것입니다.</p>

<p><img src="/assets/img/2018-12-26/fig3.png" /><br />
<small>Flask server 뒤에 여러개의 TensorFlow Serving server를 숨길수 있음</small></p>

<p>이 튜토리얼에서는 TensorFlow Serving 이 설치된 동일한 머신의 가상환경 내에 Flask server를 생성하고 이미 설치된 라이브러리를 그대로 사용하고자 합니다. 이상적으로는 이 둘은 서로 분리된 머신에서 동작해야해야합니다. 리퀘스트의 수가 많아질수록 이미지 전처리를 수행하는 Flask server의 속도가 느려지기 때문입니다. 또한, 리퀘스트가 급격히 증가할 경우, 1대의 Flask server로는 충분하지 못할수 있습니다. 다중 프로트엔드 콜러를 사용할 경우, 큐잉시스템(queing system)을 사용해야할수도 있습니다. 그럼에도 불구하고, 이 튜토리얼에서 사용하는 방법이 Proof of concept으로는 충분할 것이라 생각됩니다.</p>

<h3 id="creating-a-flaskserver---flask-server-만들기">Creating a Flask server - Flask server 만들기</h3>

<p>사전 준비 : 여기를 참고하여 파이썬 가상 환경에 Flask를 설치하세요.</p>

<p>Flask server를 만들기위해서는 app.py라는 파일 한개만 있으면 됩니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">jsonify</span>
<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">inception_v3</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>

<span class="c"># from flask_cors import CORS</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>


<span class="c"># Uncomment this line if you are making a Cross domain request</span>
<span class="c"># CORS(app)</span>

<span class="c"># Testing URL</span>
<span class="nd">@app.route</span><span class="p">(</span><span class="s">'/hello/'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'GET'</span><span class="p">,</span> <span class="s">'POST'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">hello_world</span><span class="p">():</span>
    <span class="k">return</span> <span class="s">'Hello, World!'</span>


<span class="nd">@app.route</span><span class="p">(</span><span class="s">'/imageclassifier/predict/'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'POST'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">image_classifier</span><span class="p">():</span>
    <span class="c"># Decoding and pre-processing base64 image</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">form</span><span class="p">[</span><span class="s">'b64'</span><span class="p">])),</span>
                                            <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)))</span> <span class="o">/</span> <span class="mf">255.</span>

    <span class="c"># this line is added because of a bug in tf_serving(1.10.0-dev)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float16'</span><span class="p">)</span>

    <span class="c"># Creating payload for TensorFlow serving request</span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"instances"</span><span class="p">:</span> <span class="p">[{</span><span class="s">'input_image'</span><span class="p">:</span> <span class="n">img</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}]</span>
    <span class="p">}</span>

    <span class="c"># Making POST request</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">'http://localhost:9000/v1/models/ImageClassifier:predict'</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>

    <span class="c"># Decoding results from TensorFlow Serving server</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

    <span class="c"># Returning JSON response to the frontend</span>
    <span class="k">return</span> <span class="n">jsonify</span><span class="p">(</span><span class="n">inception_v3</span><span class="o">.</span><span class="n">decode_predictions</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">]))[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>app.py 파일이 있는 경로에서 Flask server를 실행시키세요.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ export FLASK_ENV=development &amp;&amp; flask run --host=0.0.0.0
</code></pre></div></div>

<ul>
  <li>FLASK_ENV=development : debug mode로 에러 로그를 제공합니다. 상용 환경에서는 사용하지 마세요.</li>
  <li>flask run 커멘드는 자동으로 현재경로에서 app.py 실행시킵니다.</li>
  <li>–host=0.0.0.0: 다른 머신에서 Flask server로 리퀘스트를 생성할수 있도록 합니다. 다른 머신으로부터 리퀘스트를 만들기 위해서는 localhost가 아닌, Flask server가 실행되고 있는 머신의 IP주소로 접근해야합니다.</li>
</ul>

<p>결과 :</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
* Restarting with stat
* Debugger is active!
* Debugger PIN: 1xx-xxx-xx4
Using TensorFlow backend.
</code></pre></div></div>

<p>이제 TensorFlow Serving 서버를 시작하세요.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tensorflow_model_server --model_base_path=/home/ubuntu/Desktop/Medium/keras-and-tensorflow-serving/my_image_classifier --rest_api_port=9000 --model_name=ImageClassifier
</code></pre></div></div>

<p>수동으로 두 서버를 시작하는 것 대신에 auto_cmd.py를 이용해 서버 시작과 중단을 자동화 할 수 있습니다. 스크립트를 조금만 수정하면 2개 이상의 서버 동작을 처리할 수도 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">signal</span>
<span class="kn">import</span> <span class="nn">subprocess</span>

<span class="c"># Making sure to use virtual environment libraries</span>
<span class="n">activate_this</span> <span class="o">=</span> <span class="s">"/home/ubuntu/tensorflow/bin/activate_this.py"</span>
<span class="k">exec</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">activate_this</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">__file__</span><span class="o">=</span><span class="n">activate_this</span><span class="p">))</span>

<span class="c"># Change directory to where your Flask's app.py is present</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s">"/home/ubuntu/Desktop/Medium/keras-and-tensorflow-serving/flask_server"</span><span class="p">)</span>
<span class="n">tf_ic_server</span> <span class="o">=</span> <span class="s">""</span>
<span class="n">flask_server</span> <span class="o">=</span> <span class="s">""</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">tf_ic_server</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s">"tensorflow_model_server "</span>
                                     <span class="s">"--model_base_path=/home/ubuntu/Desktop/Medium/keras-and-tensorflow-serving/my_image_classifier "</span>
                                     <span class="s">"--rest_api_port=9000 --model_name=ImageClassifier"</span><span class="p">],</span>
                                    <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">DEVNULL</span><span class="p">,</span>
                                    <span class="n">shell</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">preexec_fn</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">setsid</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Started TensorFlow Serving ImageClassifier server!"</span><span class="p">)</span>

    <span class="n">flask_server</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s">"export FLASK_ENV=development &amp;&amp; flask run --host=0.0.0.0"</span><span class="p">],</span>
                                    <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">DEVNULL</span><span class="p">,</span>
                                    <span class="n">shell</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">preexec_fn</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">setsid</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Started Flask server!"</span><span class="p">)</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Type 'exit' and press 'enter' OR press CTRL+C to quit: "</span><span class="p">)</span>
        <span class="n">in_str</span> <span class="o">=</span> <span class="nb">input</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">in_str</span> <span class="o">==</span> <span class="s">'q'</span> <span class="ow">or</span> <span class="n">in_str</span> <span class="o">==</span> <span class="s">'exit'</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Shutting down all servers...'</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">killpg</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpgid</span><span class="p">(</span><span class="n">tf_ic_server</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">killpg</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpgid</span><span class="p">(</span><span class="n">flask_server</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Servers successfully shutdown!'</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">continue</span>
<span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Shutting down all servers...'</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">killpg</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpgid</span><span class="p">(</span><span class="n">tf_ic_server</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">killpg</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpgid</span><span class="p">(</span><span class="n">flask_server</span><span class="o">.</span><span class="n">pid</span><span class="p">),</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Servers successfully shutdown!'</span><span class="p">)</span>
</code></pre></div></div>

<p>auto_cmd.py의 10번째 줄 경로가 app.py의 경로가 되도록 수정하세요. 또한 6번째 줄이 가상환경의 bin을 가르키도록 하세요. 그리고 나서 다음의 커멘드를 실행하세요(아무 경로나 상관없이 실행가능합니다)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python auto_cmd.py
</code></pre></div></div>

<h3 id="testing-our-flask-server-and-tensorflow-servingserver---테스트하기">Testing our Flask server and TensorFlow Serving server - 테스트하기</h3>

<p>flask_sample_request.py 스크립트를 사용해서 간단한 리퀘스트를 만들 수 있습니다. 스크립트는 프로트엔드의 리퀘스트를 모방합니다.</p>

<ol>
  <li>인풋 이미지를 받아서, base64 포멧으로 인코딩 후, POST request를 사용하여 Flask server로 전달합니다.</li>
  <li>Flask server는 base64 이미지를 디코딩한 후 TensorFlow serving server에 전달하기 위해서 전처리를 수행합니다.</li>
  <li>Flask server는 TensorFlow serving server에  POST request를 만들고, 반환된 결과값을 디코딩합니다.</li>
  <li>디코딩된 결과값은 포멧팅되어 프로트엔드로 전달됩니다.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># importing the requests library</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">base64</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="c"># defining the api-endpoint</span>
<span class="n">API_ENDPOINT</span> <span class="o">=</span> <span class="s">"http://localhost:5000/imageclassifier/predict/"</span>

<span class="c"># taking input image via command line</span>
<span class="n">ap</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">ap</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"-i"</span><span class="p">,</span> <span class="s">"--image"</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">help</span><span class="o">=</span><span class="s">"path of the image"</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ap</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>

<span class="n">image_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s">'image'</span><span class="p">]</span>
<span class="n">b64_image</span> <span class="o">=</span> <span class="s">""</span>
<span class="c"># Encoding the JPG,PNG,etc. image to base64 format</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">imageFile</span><span class="p">:</span>
    <span class="n">b64_image</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">imageFile</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

<span class="c"># data to be sent to api</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">'b64'</span><span class="p">:</span> <span class="n">b64_image</span><span class="p">}</span>

<span class="c"># sending post request and saving response as response object</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">API_ENDPOINT</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

<span class="c"># extracting the response</span>
<span class="k">print</span><span class="p">(</span><span class="s">"{}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">))</span>
</code></pre></div></div>

<p>결과 :</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python flask_sample_request.py -i ../test_images/car.png
[
  [
    "n04285008", 
    "sports_car", 
    0.998414
  ], 
  [
    "n04037443", 
    "racer", 
    0.00140099
  ], 
  [
    "n03459775", 
    "grille", 
    0.000160794
  ], 
  [
    "n02974003", 
    "car_wheel", 
    9.57862e-06
  ], 
  [
    "n03100240", 
    "convertible", 
    6.01581e-06
  ]
]
</code></pre></div></div>

<p>이튜토리얼의 Flask server는 1개의 Tensorflow serving server를 처리할수 있도록 1개의 싱글 라우터만 존재합니다. app.py에 라우터를 추가하고, 모델에 따라 올바른 전처리가 수행될수 있도록 수정하면 여러개의 Tensorflow servign server를 만들어서 여러개의 모델을 같은 머신에서 동시에 서빙할수도 있습니다. 이렇게 작성된 라우터들을 프론트엔드팀에 전달하여 필요한 모델을 불러 사용하도록 할 수 있습니다.</p>

<h3 id="handling-cross-origin-httprequest">Handling Cross-Origin HTTP request</h3>

<p>Angular를 사용하여 POST 요청을하는 시나리오를 생각해보십시오. 다음과 같은 이유 때문에 Flask 서버는 POST가 아닌 OPTIONS 헤더를 받습니다.</p>

<ul>
  <li>웹 어플리케이션은 기존 출처와 다른 출처 (도메인, 프로토콜 및 포트)를 가진 리소스를 요청할 때 cross-origin HTTP 요청을 만듭니다.</li>
  <li>CORS (Cross Origin Resource Sharing)는 추가 HTTP 헤더를 사용하여 브라우저에 한 원점 (도메인)에서 실행중인 웹 응용 프로그램을 알리는 메커니즘입니다. CORS에 대한 자세한 내용은 여기를 참조하십시오.</li>
</ul>

<p>따라서 Angular는 Flask 서버에서 어떤 응답도 받지 못하게 됩니다. 이 문제를 해결하기 위해서는 app.py에서 Flask-CORS를 활성화해야합니다. 더 자세한 사항은 <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">여기</a>를 참고하세요.</p>

<blockquote>
  <h3 id="django-버전의-api-만들기">Django 버전의 api 만들기</h3>
  <p>python 기반의 웹 프레임워크는 flask 이외에 django가 있습니다. 아마도 여러분의 어플리케이션이 이미 django로 작성되어 있다면, tf-servering에 리퀘스트를 보내는 역할을 django에서 수행할수 있습니다. 
장고 프로젝트를 설치한후 새로운 앱을 생성합니다. 장고에 대한 자세한 내용은 이 포스팅의 범위를 넘어서기 때문에 자세한 부분은 <a href="https://docs.djangoproject.com/en/2.1/intro/tutorial01/">여기</a>를 참
고하세요.</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python manage.py startapp dashboard
</code></pre></div>  </div>
  <p>생성된 앱의 디렉토리 구조는 아래와 같습니다. 여기서는 <code class="highlighter-rouge">model.py</code>, <code class="highlighter-rouge">views.py</code>, <code class="highlighter-rouge">predict.html</code>, <code class="highlighter-rouge">urls.py</code>만 수정합니다.</p>
  <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dashboard/
    templates
       dashboard
            predict.html
    __init__.py
    admin.py
    apps.py
    migrations/
        __init__.py
    models.py
    tests.py
    views.py
    urls.py
</code></pre></div>  </div>
</blockquote>

<blockquote>
  <p><code class="highlighter-rouge">model.py</code><br />
AirKoreaStation(측정소)와 AirKoreaData(측정데이터)로 두가지 모델이 있습니다. 여기서는 측정소를 지정하면 해당 측정소에서 측정된 초미세먼지 데이터(pm25value)를 이용해 미래값을 예측하는 것을 수행하고자 합니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">django.db</span> <span class="kn">import</span> <span class="n">models</span>

<span class="k">class</span> <span class="nc">AirKoreaStations</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">AutoField</span><span class="p">(</span><span class="n">db_column</span><span class="o">=</span><span class="s">'ID'</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">null</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">stationname</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">TextField</span><span class="p">(</span><span class="n">db_column</span><span class="o">=</span><span class="s">'stationName'</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">null</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
    <span class="c">#...(생략)... </span>

<span class="k">class</span> <span class="nc">AirKoreaData</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">AutoField</span><span class="p">(</span><span class="n">db_column</span><span class="o">=</span><span class="s">'ID'</span><span class="p">,</span> <span class="n">primary_key</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">null</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  
    <span class="n">stnfk</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ForeignKey</span><span class="p">(</span><span class="n">AirKoreaStations</span><span class="p">,</span> <span class="n">on_delete</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">CASCADE</span><span class="p">)</span>
    <span class="n">pm10value</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">IntegerField</span><span class="p">(</span><span class="n">db_column</span><span class="o">=</span><span class="s">'pm10Value'</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">null</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
    <span class="n">pm25value</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">IntegerField</span><span class="p">(</span><span class="n">db_column</span><span class="o">=</span><span class="s">'pm25Value'</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">null</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
    <span class="c">#...(생략)... </span>
</code></pre></div></div>

<blockquote>
  <p><code class="highlighter-rouge">view.py</code><br />
AirKoreaData의 pm25value 입력값으로 전처리를 수행하고, 이를 tensorflow serving server에 전달하여 reponse값을 받습니다. 전달받은 predictions값을 template에 ‘forcast’ 인자로 넘겨줍니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">django.shortcuts</span> <span class="kn">import</span> <span class="n">render</span>
<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">AirKoreaData</span>
<span class="kn">import</span> <span class="nn">datetime</span> <span class="k">as</span> <span class="n">dt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="n">station_name</span><span class="p">):</span>
    <span class="n">yesterday</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">microsecond</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">second</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">minute</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hour</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">recent_data</span> <span class="o">=</span> <span class="n">AirKoreaData</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">stnfk__stationname</span><span class="o">=</span><span class="n">station_name</span><span class="p">)</span><span class="o">.</span>\
        <span class="nb">filter</span><span class="p">(</span><span class="n">datatime__range</span><span class="o">=</span><span class="p">(</span><span class="n">yesterday</span> <span class="o">-</span> <span class="n">dt</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">yesterday</span><span class="p">))</span><span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="s">'datatime'</span><span class="p">)</span>
    
    <span class="c">## 전처리</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">recent_data</span><span class="o">.</span><span class="n">values_list</span><span class="p">(</span><span class="s">'pm25value'</span><span class="p">,</span> <span class="n">flat</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">24</span><span class="p">:])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">interpolate</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c">## tensorflow serving server에 request </span>
    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span><span class="s">"instances"</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">'http://localhost:8501/v1/models/lstm:predict'</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[</span><span class="s">'predictions'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">200</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">render</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="s">"predict.html"</span><span class="p">,</span> <span class="p">{</span><span class="s">'forecast'</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>
</code></pre></div></div>
<blockquote>
  <p><code class="highlighter-rouge">predict.html</code><br />
전달받은 forecast값을 화면에 표시해줍니다.</p>
</blockquote>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"en"</span><span class="nt">&gt;</span>
<span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"UTF-8"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;title&gt;</span>Title<span class="nt">&lt;/title&gt;</span>
<span class="nt">&lt;/head&gt;</span>
<span class="nt">&lt;body&gt;</span>
{ % for data in forecast %} { { data }}{ % endfor %}
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</code></pre></div></div>

<blockquote>
  <p><code class="highlighter-rouge">urls.py</code><br />
urls.py를 생성하여 http://localhost:8000/predict에 접속하면 view.predict가 실행되도록 해줍니다.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">django.urls</span> <span class="kn">import</span> <span class="n">path</span>
<span class="kn">import</span> <span class="nn">dashboard.views</span> <span class="k">as</span> <span class="n">views</span>

<span class="n">urlpatterns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">path</span><span class="p">(</span><span class="s">'predict/&lt;str:station_name&gt;/'</span><span class="p">,</span> <span class="n">views</span><span class="o">.</span><span class="n">predict</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'predict'</span><span class="p">),</span>
<span class="p">]</span>
</code></pre></div></div>

<blockquote>
  <p>자, 이제 tensorflow serving server를 실행시킵니다. 그리고 django app도 실행시킵니다.</p>
</blockquote>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ docker run -p 8501:8501 --mount type=bind,source=/Users/jyj0729/PycharmProjects/mysite/forcast_model,target=/models/lstm -e MODEL_NAME=lstm -t tensorflow/serving
 $ python manage.py runserver
</code></pre></div></div>

<blockquote>
  <p>이제 <code class="highlighter-rouge">http://localhost:8000/predict/별양동/</code>으로 접속하면 모델 결과값이 출력되는 것을 볼 수 있습니다.
<img src="/assets/img/2018-12-26/django-api.png" /><br /></p>
</blockquote>

<h3 id="conclusion---결론">Conclusion - 결론</h3>

<p>여기까지 머신러닝 모델을 배포하는 과정을 알아보았습니다. TensorFlow Serving은 머신러닝을 웹사이트나 다른 어플리케이션과 통합되도록 도와줍니다. 잘 학습된 다양한 케라스 모델을 사용하여 머신러닝에 대한 최소 지식으로도 유용한 어플리케이션 개발이 가능합니다.</p>


        
      </section>

      <footer class="page__meta">
        
        


  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#tensorflow" class="page__taxonomy-item" rel="tag">Tensorflow</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2018-12-26T00:00:00+09:00">December 26, 2018</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Deploying+Keras+models+using+TensorFlow+Serving+and%C2%A0Flask%20http%3A%2F%2Flocalhost%3A4000%2Ftensorflow%2Ftensorflow-serving%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Ftensorflow%2Ftensorflow-serving%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http%3A%2F%2Flocalhost%3A4000%2Ftensorflow%2Ftensorflow-serving%2F" class="btn btn--google-plus" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Google Plus"><i class="fab fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Ftensorflow%2Ftensorflow-serving%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/spatio-temporal%20data/time-series/time-series-part2/" class="pagination--pager" title="시계열 분석 part2 - practical example
">Previous</a>
    
    
      <a href="/spatio-temporal%20data/time-series/time-series-part3/" class="pagination--pager" title="시계열 분석 part3 - Non-stationary
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 yjucho. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>







    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/tensorflow/tensorflow-serving/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/tensorflow/tensorflow-serving"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://yjucho.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



  </body>
</html>