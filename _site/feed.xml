<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-05-01T21:02:38+09:00</updated><id>http://localhost:4000/</id><title type="html">yjucho’s blog</title><subtitle>DATA, Deep Learning, AI</subtitle><author><name>yjucho</name></author><entry><title type="html">Dynamic Time Warping(DTW)</title><link href="http://localhost:4000/time-series/dtw/" rel="alternate" type="text/html" title="Dynamic Time Warping(DTW)" /><published>2019-05-01T00:00:00+09:00</published><updated>2019-05-01T00:00:00+09:00</updated><id>http://localhost:4000/time-series/dtw</id><content type="html" xml:base="http://localhost:4000/time-series/dtw/">&lt;p&gt;두 시계열 데이터간의 유사도를 어떻게 계산할 수 있을까? 두 시계열이 동일한 길이의 시퀀스라면 단순히 상관계수를 구하는 것이 가능하지만, 현실 세계의 시계열 데이터는 그렇지 않은 경우가 많습니다. 예를 들어 아래와 같은 두 시계열 데이터를 살펴보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig1.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;육안으로 보기엔 두 시계열 모두 두 개의 peak를 가지고 있고 전체적으로 우상향하는 모습이 매우 유사해보입니다. 두 시계열 간의 상관계수를 구해보도록 하겠습니다. 어랏, 두 데이터의 길이가 다르기 때문에 바로 계산되지 않네요.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## ValueError: all the input array dimensions except for the concatenation axis must match exactly&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;유사도를 측정하기 위한 가장 간단한 방법은 상대적으로 길이가 짧은 시계열1 데이터를 &lt;code class=&quot;highlighter-rouge&quot;&gt;interpolation&lt;/code&gt;하여 길이를 동일하게 맞춘 후, &lt;code class=&quot;highlighter-rouge&quot;&gt;np.corrcoef&lt;/code&gt;를 사용하여 상관계수를 계산하는 것입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;len_ts1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len_ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interp_ind&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interp_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Comparison : ts1_interp vs. ts2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1 - interpolation'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## correlation coefficent&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#### output&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# array([[ 1.        ,  0.85206492],&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#        [ 0.85206492,  1.        ]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig2.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;단순히 &lt;code class=&quot;highlighter-rouge&quot;&gt;선형 보간(linear interpolation)&lt;/code&gt; 방법은 기존의 시계열 데이터1이 가지고 있는 모습을 꽤 왜곡시킨는 결과를 낳습니다. 2개의 spike형태의 peak가 사라진 것을 볼 수 있습니다. 실제로 단순히 데이터 포인트를 늘려서 대응방식으로 비교하는 것은 합리적이지 못한 경우가 많습니다.&lt;/p&gt;

&lt;p&gt;이렇게 길이가 서로 다른 두 시계열의 유사도를 계산하는 방법으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;DTW(Dynamic Time Warping)&lt;/code&gt;를 사용할 수 있습니다. DTW는 시퀀스의 길이를 고려하지 않기 때문에 서로 다른 길이의 시퀀스의 유사도를 바로 계산할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Dynamic_time_warping.png/440px-Dynamic_time_warping.png&quot; width=&quot;200&quot; /&gt; &lt;br /&gt; &lt;small&gt;In time series analysis, dynamic time warping (DTW) is one of the algorithms for measuring similarity between two temporal sequences, &lt;u&gt;which may vary in speed&lt;/u&gt;. For instance, similarities in walking could be detected using DTW, even if one person was walking faster than the other, or if there were accelerations and decelerations during the course of an observation. DTW has been applied to temporal sequences of video, audio, and graphics data — indeed, any data that can be turned into a linear sequence can be analyzed with DTW. A well known application has been automatic speech recognition, to cope with different speaking speeds. Other applications include speaker recognition and online signature recognition. Also it is seen that it can be used in partial shape matching application. &lt;i&gt;- &lt;a href=&quot;https://en.wikipedia.org/wiki/Dynamic_time_warping&quot;&gt;위키피디아&lt;/a&gt;&lt;/i&gt; &lt;/small&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;** 아래는 DTW의 개념을 소개하기 위해 &lt;a href=&quot;https://jsideas.net/bitcoin_dtw/&quot;&gt;jsideas님의 포스팅&lt;/a&gt;를 인용하였습니다.&lt;/p&gt;

&lt;p&gt;n개의 데이터포인트가 있는 시퀀스 X와 m개의 데이터포인트가 있는 시퀀스 Y가 있다고 하겠습니다. 이 두 시퀀스를 각 각 x축과 y축에 늘어놓고 데이터 포인트간의 거리(예를 들어 유클리디언 거리)를 구하면, 그 값둘은 m&lt;script type=&quot;math/tex&quot;&gt;\times&lt;/script&gt;n의 매트릭스 형태가 됩니다. 이 매트릭스를 cost matrix라고 하도록 하겠습니다. cost matrix를 heatmap형식으로 표현하면 아래 그림처럼, 두 데이터 포인트간 거리가 짧은 곳은 어둡게, 거리가 먼 곳은 흰색으로 표현됩니다. DTW알고리즘은 저 cost matrix 상의 좌하단에서 우상단까지 가는 최적의 경로를 찾는 문제를 푸는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig5.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이 최적화문제의 목적식은 좌하단(0,0)에서 우상단(m, n)을 이동하는데 드는 비용을 최소화하는 것이고, 이때 3가지 제약조건이 존재하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig6.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;두 시퀀스의 처음과 끝은 같아야 합니다. 즉 무조건 좌하단에서 시작해서 우하단에서 끝나야합니다.&lt;/li&gt;
  &lt;li&gt;x나 y축, 혹은 그 두 축에서 음의 방향으로 이동하지 않습니다.&lt;/li&gt;
  &lt;li&gt;이동할때 정해진 스텝사이즈 (예를 들어 오른쪽과 위쪽 한칸씩만 이동가능하다던지..(0,1) or (1,0) or (1,1))만큼 이동가능합니다. 가능한 스텝사이즈를 늘릴수록 더 많은 경우 수를 검색하기 때문에 최적에 가까운 경로를 얻을 수 있지만, 그만큼 계산속도가 느려지게 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DTW는 결국 X와 Y를 늘어놓고 X의 특정 데이터포인트가 Y의 어떤 데이터포인트에 가장 적합한지를 판정하는 로직이므로, X와 Y의 길이가 늘어나면 늘어날수록 검색 비용이 늘어나는 단점이 있습니다.&lt;/p&gt;

&lt;p&gt;또한 앞서 언급했듯이 최적값을 찾기 위해 검색가능한 스텝사이즈를 늘리면 계산 속도가 느려지게 되고, 반대로 스텝사이즈를 줄이면 전후 경로만 보고 기계적으로 두 시퀀스를 정렬시켜버리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;pathological alignment&lt;/code&gt; 문제가 발생할 수 있습니다. 일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;pathological alignment&lt;/code&gt;문제를 피하기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;Sakoe-Chiba Band&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Itakura Parallelogram&lt;/code&gt;방법 등을 사용하기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig7.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;python에서의-dtw&quot;&gt;python에서의 DTW&lt;/h3&gt;
&lt;p&gt;파이썬에서는 pip 패키지인 &lt;code class=&quot;highlighter-rouge&quot;&gt;dtw&lt;/code&gt;를 통해서 별도의 구현없이 DTW알고리즘을 쉽게 이용할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;https://pypi.org/project/dtw/ &lt;br /&gt;&lt;br /&gt;
&lt;b&gt;github description&lt;/b&gt; : https://github.com/pierre-rouanet/dtw&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;패키지를 설치한 후 아래와 같이 사용할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dtw&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtw&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;euclidean_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc_cost_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclidean_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc_cost_matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lower'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gray'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nearest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig3.png&quot; width=&quot;150&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;cost matrix와 최적 path는 위 이미지에 표시된것과 같고, 이를 다시 시계열 차트에서 비교하면 아래와 같습니다. dtw를 통해 warping된 시계열데이터1과 시계열데이터2의 상관계수를 구한 결과, 약 0.92로 단순 선형 보간에 의한 상관계수 0.85보다 더 높은 값이 계산되는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Comparison : ts1_dtw vs. ts2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1 - Warping'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#### output&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# array([[ 1.        ,  0.92247328],&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#        [ 0.92247328,  1.        ]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;긴 글을 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">두 시계열 데이터간의 유사도를 어떻게 계산할 수 있을까? 두 시계열이 동일한 길이의 시퀀스라면 단순히 상관계수를 구하는 것이 가능하지만, 현실 세계의 시계열 데이터는 그렇지 않은 경우가 많습니다. 예를 들어 아래와 같은 두 시계열 데이터를 살펴보겠습니다.</summary></entry><entry><title type="html">Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding</title><link href="http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding/" rel="alternate" type="text/html" title="Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding" /><published>2019-03-15T00:00:00+09:00</published><updated>2019-03-15T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding/">&lt;p&gt;&lt;b&gt;Kyle Hundman et al (2018 KDD, NASA)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Implementation : &lt;a href=&quot;https://github.com/khundman/telemanom&quot;&gt;https://github.com/khundman/telemanom&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;NASA의 우주선은 많은 양의 원격 데이터를 송신합니다. NASA 연구원들은 우주선이 보내는 데이터들을 이용해 엔지니어의 모니터링 부담과 운영 비용을 줄이기 위해서 어노말리 디텍션 시스템을 구축/개선하고 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문은 우주선 데이터에 적용가능한 어노말리 디텍션 알고리즘을 제안합니다. expert-labeled 어노말리 데이터가 포함된 Soil Moiture Active Passive(SMAP) satelite와 Mars Science Laboratory(MSL) rover 데이터에 LSTM 모델을 적용한 새로운 어노말리 디텍션 방법을 제안하였습니다.&lt;/li&gt;
  &lt;li&gt;이 방식은 지도학습에 의한 모델 학습이 아니라 unsupervised and nonparametric anomaly thresholding approach에 해당하며, 후반부에는 false positive를 줄이기 위한 방법들을 추가적으로 논의하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;우주선에서는 온도, 방사선, 전력, 소프트웨어의 계산량 등 복잡하고 방대한 양의 데이터들이 수집되며 각 데이터들의 어노말리 디텍션은 매우 중요한 문제입니다.&lt;/li&gt;
  &lt;li&gt;기존의 어노말리 디텍션 방법들은 사전에 정의된 제한값을 벗어나면 발생하는 알람 형식이거나 수작업이 포함된 시각화 방법과 채널별 통계 분석을 이용합니다. 이러한 방식은 적지않은 전문가적 지식을 요구하며 각 규칙을 정의하거나 노말 범위를 업데이트하는데 수기 작업이 필요합니다. 특히 하루에 85테라바이트의 데이터가 생성되는 방대한 양의 데이터를 처리하는 빅데이터 시스템에서는 더욱 문제가 악화됩니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;다변량 시계열 데이터의 어려운 이슈이 우주선 데이터를 분석하는데 여전히 유효하고, 라벨링 부족한 상황에서 비지도학습방식이나 세미지도학습방법의 필요성 역시 존재합니다. 또한 대부분의 실제 시계열 데이터가 그러하듯이 non-stationary한 특징과 현재 컨텍스에 매우 종속된 특징을 갖는 것들도 어려운 점입니다. 또한 엔지니어에게 인사이트를 줄수 있도록 interpretability도 필요한 요소입니다. 마지막으로 false positive와 false negative를 최소화하면서 적절한 발런스를 찾는 것 역시 중요합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt; Contributions &lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;이 논문은 LSTM을 이용하여 높은 예측력을 얻고, 각 채널별 예측모델을 구축하여 전체 시스템의 interpretability를 유지하였습니다.&lt;/li&gt;
      &lt;li&gt;일단 모델의 예측값을 이용해 실제 값과의 오차(residual)을 이용해 어노말리인지 판단하게 됩니다. 이때 nonparametric, dynamic, and unsupervised thresholding approach를 사용합니다. 이 방식을 이용해 신호의 다양성, 비정상성과 노이즈에 대해서 논의하고 이후 사용자 피드백과 과거 데이터를 이용해 시스템을 향상시키는 방법도 함께 논의하였습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;background-and-related-work&quot;&gt;Background and Related Work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;일반적으로 3가지 종류의 어노말리가 존재합니다.
    &lt;ul&gt;
      &lt;li&gt;point anomaly : low density regions에 해당하는 싱글 포인트가 발생하는 것을 의미합니다.&lt;/li&gt;
      &lt;li&gt;contextual anomaly : low density region은 아니지만 로컬 값들과 비교했을때는 비정상적인 싱글 포인트가 발생하는 경우입니다.&lt;/li&gt;
      &lt;li&gt;collective anomaly : 여러개의 시퀀스값들이 비정상적일 때를 의미합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;가장 기본적인 어노말리 디텍션은 out-of-limit(OOL)입니다.
    &lt;ul&gt;
      &lt;li&gt;그 외 clustering based approaches, nearest neighbors approaches, expert systems, dimensionality reduction approaches 등이 있지만, parameter specification, interpretability, generalizability, or computational expense 등의 단점이 존재합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;기존에도 우주선에 적용가능한 어노말리 디텍션 방법들이 다수 연구되었습니다. ISACS-DOC, IMSE, ELMER, Deep Space One spacecrash 등과 같은 프로젝트들이 있었습니다만, 여전히 직관적인 결과를 얻을수 있고 관리가 쉬운 OOL 방식이 사용되고 있습니다.&lt;/li&gt;
  &lt;li&gt;최근 딥러닝이 발전하면서 seq-to-seq 학습에서도 큰 성과를 얻고 있습니다. LSTM과 RNN계열의 모델을 이용해 과거값을 이용해 예측값을 학습할수 있습니다. 정상데이터로 학습된 LSTM을 이용하여 정상적인 상태에서의 시스템을 모니터링할수 있습니다. LSTM은 차원축소를 하지 않아도 다변량 시계열 데이터에 적용가능하고, 특별한 도메인 날리지를 요구하지 않기 때문에 다른 우주선에 일반적으로 적용가능합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;telemetry-value-prediction-with-lstms&quot;&gt;Telemetry Value Prediction with LSTMs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;single channel models&lt;/b&gt; : 여기서는 각 채널별로 모델을 생성합니다. 싱글 모델의 장점은
    &lt;ul&gt;
      &lt;li&gt;채널 레벨로 추정가능하다는 것&lt;/li&gt;
      &lt;li&gt;로우 레벨의 어노말리를 그룹핑하여 서브시스템 형태로 통합할수 있습니다. 이로인해서 더 세분화된 시스템 관리가 가능합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt;predicting values for a channel &lt;/b&gt;: 주어진 시계열은 &lt;script type=&quot;math/tex&quot;&gt;X=\left\{ x^{(1)}, x^{(2)}, ..., x^{(n)} \right\}&lt;/script&gt; 이고, &lt;script type=&quot;math/tex&quot;&gt;x^{(t)}&lt;/script&gt;는 m차원의 벡터를 나타내고 각 element가 채널의 입력값을 나타냅니다.  &lt;script type=&quot;math/tex&quot;&gt;l_s&lt;/script&gt;는 모델 입력으로 사용한 시퀀스의 길이를 의미합니다. &lt;script type=&quot;math/tex&quot;&gt;l_p&lt;/script&gt;는 예측할 시퀀스의 길이를 나타내며 이 논문에서는 계산 속도를 위해서 1을 사용하였습니다. 또한 각 채널별 예측을 수행하기 때문에 예측값의 차원 d=1로 설정하였습니다. &lt;script type=&quot;math/tex&quot;&gt;x^{(t)}&lt;/script&gt; 는 각 채널의 이전 값과 함께 우주선에 전송된 encoded command information이 포함됩니다. 커멘드를 생성한 것과 커멘드를 수신한 정보가 one-hot encoded되어 입력으로 사용됩니다. (Fig3 참고)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-error-thresholds&quot;&gt;Dynamic Error Thresholds&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;수천개의 원격 데이터를 자동으로 모니터링하기 위해서는 계산속도가 빠르고, 예측값이 어노말리인지 판단하는 과정이 비지도 학습방식이어야합니다. 이를 위한 일방적인 방식은 과거의 스무딩된 에러들을 가우시안 분포로 가정하여 새로운 에러값과 이전 값들의 compact representation간의 빠른 비교가 되도록 하는 것입니다. 하지만 이 방식은 가우시안 분포라는 가정이 맞지 않을때는 문제가 되기때문에 여기서는 어떠한 가정없이 extreme values를 찾아내는 방식을 제안합니다. distance-based method가 비슷하지만 기존의 distance based method는 각 포인트들을 인근의 k개와 비교하기 때문에 계산량이 많다는 단점이 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Errors and Smoothing&lt;/b&gt; : 우선 예측값과 실제값 사이의 에러를 계산합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e^{(t)} = \left\vert y^{(t)} - \hat{y}^{(t)} \right\vert \\
\boldsymbol{e}=[e^{(t-h)}, ..,e^{(t-1)}, e^{(t)}]&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;이때 각 에러값들은 스무딩(smoothed)된 값들을 사용합니다. 정상적인 상태라도 값이 급변하여 완벽하게 예측이 되지 않아 스파이크 형태의 에러값이 생기는 경우가 종종 있기 때문입니다. 여기서는 Exponentially-weighted average(EWMA)를 사용하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{e_s}=[e_s^{(t-h)}, ..,e_s^{(t-1)}, e_s^{(t)}]&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;값들이 정상인지 판단하기 위해서는 threshold를 설정하여 사용하였습니다. threshold보다 큰 값은 anomalies로 분류됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;Threshold Calculation and Anomaly Scoring &lt;/b&gt; : 일반적으로 threshold를 결정하기 위해서 지도학습방식으로 학습을 합니다. 하지만 이 방식은 라벨링된 데이터가 필요하기 때문에 여기서는 비지도학습 형태로 threshold를 결정하는 방법을 제안하였습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\epsilon} = \mu(\boldsymbol{e_s}) + z\sigma(\boldsymbol{e_s})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Where &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt; is determined by:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon = argmax(\boldsymbol{\epsilon}) = \frac{\triangle\mu(\boldsymbol{e_s})/\mu(\boldsymbol{e_s}) + \triangle\sigma(\boldsymbol{e_s})/\sigma(\boldsymbol{e_s})}{\left\vert \boldsymbol{e_a} \right\vert + \left\vert \boldsymbol{E_{seq}} \right\vert^2}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;such that:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangle\mu(\boldsymbol{e_s}) = \mu(\boldsymbol{e_s}) - \mu(\left\{ e_s \in \boldsymbol{e_s} \vert e_s \lt \epsilon \right\}) \\
\triangle\sigma(\boldsymbol{e_s}) = \sigma(\boldsymbol{e_s}) - \sigma(\left\{ e_s \in \boldsymbol{e_s} \vert e_s \lt \epsilon \right\}) \\
\boldsymbol{e_a} = \left\{ e_s \in \boldsymbol{e_s} \vert e_s \gt \epsilon \right\} \\
\boldsymbol{E_{seq}} = \mbox{continuous sequences of }e_a \in \boldsymbol{e_a}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;anomaly score&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{(i)} = \frac{max(e^{(i)}_{seq})-argmax({\epsilon})}{\mu(\boldsymbol{e_s}) + \sigma( \boldsymbol{e_s})}&lt;/script&gt;

&lt;h3 id=&quot;mitigating-false-positives&quot;&gt;Mitigating False Positives&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;Pruning Anomalies&lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;prediction-based 방식은 과거데이터의 갯수(h)에 영향을 많이 받습니다.&lt;/li&gt;
      &lt;li&gt;너무 많은 과거 데이터를 이용할 경우, 실시간 모니터링 시나리오에서 계산 비용이 너무 크게 됩니다. 너무 적은 과거 데이터를 이용할 경우, 좁은 컨텍스트만 고려하여 판단하기 때문에 false positive가 많아지게 됩니다. 그렇다고 false positive를 너무 줄이다보면 감지되지 못한 어노말리를 찾기위해서 휴먼 인스펙션 부담이 커지게 됩니다. 따라서 false positives를 약화시키기 위해서 pruning procedure를 도입하였습니다.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{e_{max}}&lt;/script&gt; is created containing &lt;script type=&quot;math/tex&quot;&gt;max(\boldsymbol{e_{seq}})&lt;/script&gt; for all &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{e_{seq}}&lt;/script&gt; sorted in descending order. we also add the maximum smoothed error that isn’t anomalous, &lt;script type=&quot;math/tex&quot;&gt;max(\left\{ e_s \in \boldsymbol{e_s} \in \boldsymbol{E_{seq}} \vert e_s \ni \boldsymbol{e_a} \right\} )&lt;/script&gt;, to the end of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{e_{max}}&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;The sequence is then stepped through incrementally and the the percent decrease &lt;script type=&quot;math/tex&quot;&gt;d^{(i)} = ( e_{max}^{(i-1)} - e_{max}^{(i)}) / e_{max}^{(i-1)}&lt;/script&gt; at each step &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is calculated where &lt;script type=&quot;math/tex&quot;&gt;i \in \left\{1, 2, ..., (\left\vert \boldsymbol{E_{seq}} \right\vert + 1)\right\}&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;If at some step &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; a minimum percentage decrease p is exceeded by &lt;script type=&quot;math/tex&quot;&gt;d^{(i)}&lt;/script&gt;, all &lt;script type=&quot;math/tex&quot;&gt;e_{max}^{(j)} \in \boldsymbol{e_{max}} \vert j \lt i&lt;/script&gt; and their corresponding anomaly sequences remain anomalies.&lt;/li&gt;
      &lt;li&gt;If the minimum decrease p in not met by &lt;script type=&quot;math/tex&quot;&gt;d^{(i)}&lt;/script&gt; and for all subsequent errors &lt;script type=&quot;math/tex&quot;&gt;d^{(i)}, d^{(i+1)}, ..., d^{(i+\left\vert \boldsymbol{E_{seq}} \right\vert + 1)}&lt;/script&gt; those smoothed error sequences are reclassified as nominal.&lt;/li&gt;
      &lt;li&gt;이와 같은 pruning 과정은 정상적인 흐름에서의 노이즈가 어노말리로 판단되는 것을 방지합니다. 또한 단순히 값과 값을 여러번 비교하여 판단하는 것보다 잠재가능성이 있는 비정상적인 시퀀스 중에 맥시멈 에러갓을 비교하는 것이 더 효율적이라는 장점이 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Learning from History&lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;false postive를 감소시키는 두번째 전략은 적은양이더라도 과거의 비정상 값들 또는 라벨링된 데이터를 적용시키는 것입니다. 각 채널 데이터에서 일정 비율 이상 수집된 값들을 어노말리로 판단하여 미니멈 값 &lt;script type=&quot;math/tex&quot;&gt;s_{min}&lt;/script&gt;로 설정합니다. 이후 새로운 값들 중 &lt;script type=&quot;math/tex&quot;&gt;s \lt s_{min}&lt;/script&gt;조건을 만족하는 경우 정상값으로 분류합니다.  &lt;script type=&quot;math/tex&quot;&gt;s_{min}&lt;/script&gt;는 precision과 recall사이의 적절한 밸러스가 되도록 설정할수 있습니다.&lt;/li&gt;
      &lt;li&gt;또는 유저가 제공하는 라벨링 정보를 이용하여 &lt;script type=&quot;math/tex&quot;&gt;s_{min}&lt;/script&gt;를 설정할수도 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-03-15/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">Kyle Hundman et al (2018 KDD, NASA)</summary></entry><entry><title type="html">RobustSTL : A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series</title><link href="http://localhost:4000/deep%20learning%20paper/time-series/robustSTL/" rel="alternate" type="text/html" title="RobustSTL : A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series" /><published>2019-02-24T00:00:00+09:00</published><updated>2019-02-24T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/time-series/robustSTL</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/time-series/robustSTL/">&lt;p&gt;&lt;b&gt;Qingsong Wen et al (2018, Alibaba Group)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Implementation : &lt;a href=&quot;https://github.com/LeeDoYup/RobustSTL&quot;&gt;https://github.com/LeeDoYup/RobustSTL&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;시계열데이터를 trend, seasonality, and remainder components로 분해하는 것은 어노말리 디텍션이나 예측 모델을 만드는데 중요한 역할을 합니다.&lt;/li&gt;
  &lt;li&gt;기존의 여러가지 성분분해 방식들은
    &lt;ul&gt;
      &lt;li&gt;1) 주기성이 변하거나 이동하는 것, 트렌드나 나머지성분의 갑작스러운 변화를 잘 처리하지 못하며(seasonality fluctuation and shift, and abrupt change in trend and reminder)&lt;/li&gt;
      &lt;li&gt;2) 어노말리 데이터에 대해서 로버스트하지 못하거나&lt;/li&gt;
      &lt;li&gt;3) 주기가 긴 시계열 데이터에 대해서 적용하기 어려운 문제가 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;본 논문에서는 위와 같은 문제점을 해결할 수 있는 새로운 성분 분해 방식을 제안합니다.
    &lt;ul&gt;
      &lt;li&gt;먼저 sparse regularization와 least absolute deviation loss를 이용해 트렌드를 뽑고&lt;/li&gt;
      &lt;li&gt;Non-local seasonal filter를 사용하여 seasonality 성분을 얻습니다.&lt;/li&gt;
      &lt;li&gt;이 과정을 정확한 디컴포지션을 얻을때까지 반복합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;실험데이터와 실제 시계열데이터에 대해서 기존 방법들 대비 더 좋은 성능을 보임을 확인하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;디컴포지션 방법으로 널리 사용되는 방법은 STL(seasonal trend decomposition using Loess), X-13-ARIMA-SEATS, X-11-ARIMA, X-12-ARIMA 등이 있습니다. 하지만 seasonality shift나 fluctuation이 존재할 경우 정확하지 않거나, 빅데이터에 존재하는 long seasonality에는 적합하지 않습니다.
    &lt;ul&gt;
      &lt;li&gt;seasonality fluctuation and shift - 하루가 주기인 시계열 데이터가 있다고 했을때, 오늘 1시에서의 seasonality component는 어제의 12시 30분에 대응되고, 그제의 1시 30분에 대응될수 있음&lt;/li&gt;
      &lt;li&gt;Abrupt change of trend and remainder - local anomaly could be a spike during an idle period (busy day의 높은 값보다는 낮아서 정확히 디텍션하기 어려움&lt;/li&gt;
      &lt;li&gt;Long seasonality - 보통은 quarterly or monthly data임. T 주기의 시즈널리티를 찾기 위해서는 T-1개의 데이터가 필요함. 하루 주기에 1분 간격 데이터의 경우 T=1440개고 이와 같은 long seasonality는 기존 방법들로는 풀기어려움&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이 논문에서 제안한 방법은 Long seasonality period and high noises 더라도 시즈널리티를 비교적 정확하게 디컴포지션할수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;robust-stl-decomposition&quot;&gt;Robust STL Decomposition&lt;/h2&gt;
&lt;h3 id=&quot;model-overview&quot;&gt;Model Overview&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
y_t &amp; = \tau_t + s_t + r_t, &amp; t = 1, 2, …, N \\
r_t &amp; = a_t + n_t \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;a_t&lt;/script&gt; denotes spike or dip, and &lt;script type=&quot;math/tex&quot;&gt;n_t&lt;/script&gt; denotes the white noise.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;시계열 모델은 트렌드(&lt;script type=&quot;math/tex&quot;&gt;\tau_t&lt;/script&gt;), 시즈널리티(&lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt;), 리마인더(&lt;script type=&quot;math/tex&quot;&gt;r_t&lt;/script&gt;)로 구성되어 있고, 리마인더는 스파크 또는 딥과 같은 어노말리(&lt;script type=&quot;math/tex&quot;&gt;a_t&lt;/script&gt;)와 화이트 노이즈(&lt;script type=&quot;math/tex&quot;&gt;n_t&lt;/script&gt;)로 이루어집니다.&lt;/li&gt;
  &lt;li&gt;제안하는 알고리즘은 크게 4-steps 으로 각 성분을 분해합니다.
    &lt;ul&gt;
      &lt;li&gt;Denoise time series by applying bilateral filtering&lt;/li&gt;
      &lt;li&gt;Extract trend robustly by solving a LAD regression with sparse regularization&lt;/li&gt;
      &lt;li&gt;Calculate the seasonality component by applying a non-local seasonal filtering to overcome seasonality fluctuation and shift&lt;/li&gt;
      &lt;li&gt;Adjust extracted components&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;noise-removal&quot;&gt;Noise Removal&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
y^\prime_t &amp; = \sum_{j \in J} w_j^t y_t, &amp; J = t, t \pm 1, …, t \pm H \\
w_j^t &amp; = \frac{1}{z} e^{-\frac{\left\vert j- t \right\vert ^2}{2\delta_d^2}} e^{-\frac{\left\vert y_j - y_t \right\vert ^2}{2\delta_i^2}}
\end{align} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;J는 필터의 윈도우를 의미하며, 윈도우 사이즈는 2H+1 입니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;필터의 가중치는 두개의 가우시안 함수로 구성됩니다. bilateral filter는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Bilateral_filter&quot;&gt;여기&lt;/a&gt;를 참고하세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;After denoising,&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
y^\prime_t &amp; = \tau_t + s_t + r^\prime_t, &amp; t = 1, 2, …, N \\
r^\prime_t &amp; = a_t + (n_t - \hat{n}_t \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Where the &lt;script type=&quot;math/tex&quot;&gt;\hat{n}_t = y_t - y^\prime_t&lt;/script&gt; is the filtered noise.&lt;/p&gt;

&lt;h3 id=&quot;trend-extraction&quot;&gt;Trend Extraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;시즈널 디퍼런스 오퍼레이터는 같은 주기의 값을 차분하는 것으로 아래와 같이 정의할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
g_t &amp; = \nabla_T y^\prime_t = y^\prime_t - y^\prime_{t-T} \\
&amp; = \nabla_T \tau_t + \nabla_T s_t + \nabla_T r^\prime_t \\
&amp; = \sum_{I=0}^{T-1} \nabla \tau_{t-i} + ( \nabla_T s_t + \nabla_T r^\prime_t )
\end{align} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;마지막 줄의 수식에서 첫번째 항이 &lt;script type=&quot;math/tex&quot;&gt;g_t&lt;/script&gt;에 가장 많은 기여를 합니다. &lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;r^\prime_t&lt;/script&gt;에 시즈널 디퍼런스 오퍼레이터를 적용하면 값이 매우 작아진다고 가정하기 때문입니다.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;g_t&lt;/script&gt;에서 트렌드의 first order differece(&lt;script type=&quot;math/tex&quot;&gt;\nabla \tau_t&lt;/script&gt;)를 구하기 위해서 다음과 같은 최적화 식을 사용합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Minimize \ \sum_{t=T+1}^N \left\vert g_t - \sum_{I=0}^{T-1} \nabla \tau_{t-i} \right\vert + \lambda_1 \sum_{t=2}^N \left\vert \nabla \tau_t \right\vert + \lambda_2 \sum_{t=3}^N \left\vert \nabla^2 \tau_t \right\vert&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;첫번째 항은 LAD를 사용한 emprical error를 의미합니다. sum-of-squares 보다 아웃라이어에 대해서 더 로버스트하기 때문에 LAD를 사용하였습니다.&lt;/li&gt;
  &lt;li&gt;두번째와 세번째 항은 각 각 트렌드에 대한 first-order 와 second-order difference operator 입니다.&lt;/li&gt;
  &lt;li&gt;두번째 항은 트렌드 디퍼런스 &lt;script type=&quot;math/tex&quot;&gt;\nabla \tau_t&lt;/script&gt; 가 천천히 변화하지만 종종 갑작스러운 레벨 쉬프트(abrupt level shift)가 있다는 것을 의미합니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;세번째 항은 트렌드가 smooth하고 piecewise linear such that &lt;script type=&quot;math/tex&quot;&gt;\nabla^2 x_t = \nabla(\nabla x_t)) = x_t -2 x_{t-1} + x_{t-2}&lt;/script&gt; are sparse&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;이를 매트릭스 형태로 표현하면 다음과 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Vert P \nabla \tau - q \Vert _1&lt;/script&gt;

&lt;p&gt;where the matrix P and vector q are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P = \begin{bmatrix}
M_{(N-T) \times (N-1)} \\
\lambda_1 I_{(N-1) \times (N-1)} \\
\lambda_2 D_{(N-2) \times (N-1)} \\
\end{bmatrix}, 
q = \begin{bmatrix}
g_{(N-T) \times 1} \\
0_{(2N-3) \times 1} \\
\end{bmatrix}&lt;/script&gt;

&lt;p&gt;M and D are Toeplitz matrix (refer to the paper for details)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위의 최적화식을 통해서 &lt;script type=&quot;math/tex&quot;&gt;\tau_1&lt;/script&gt;에 대한 상대적인 트렌드(relative trend, &lt;script type=&quot;math/tex&quot;&gt;\tilde{\tau}_t^r&lt;/script&gt;)를 구할수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\tilde{\tau}_t^r = \tilde{\tau}_t - \tau_1 = 
\begin{cases}
0, &amp; t=1 \\
\sum_{I=2}^t \nabla \tilde{\tau}_i, &amp; t \ge 2
\end{cases} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;그리고 나서, 디컴포지션 모델은 아래와 같이 업데이트 됩니다. 
&lt;script type=&quot;math/tex&quot;&gt;y_t'' = y_t' - \tilde{\tau}_t^r = s_t + \tau_1 + r_t'' \\
r_t’’ = a_t + (n_t - \hat{n}_t) +  (\tau_t - \tilde{\tau}_t)&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;seasonality-extraction&quot;&gt;Seasonality Extraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;relative trend component를 분리한 후에는, &lt;script type=&quot;math/tex&quot;&gt;y’’_t&lt;/script&gt;는 시즈널리티로 오염되어 있다고 생각할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;기존의 시즈널리티 분해 방법들은 주기가 &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;인 &lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt;’를 구하기 위해서는 K개의 연속적인 값 &lt;script type=&quot;math/tex&quot;&gt;y_{t-KT}, y_{t-(K-1)T}, …, y_{t-T}&lt;/script&gt; 만 고려하였습니다. 하지만, 이 방식은 시즈널리 쉬프트 현상을 설명할수 없다는 단점이 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;여기서는  &lt;script type=&quot;math/tex&quot;&gt;y’’_{t-KT}&lt;/script&gt;를 중심으로 인접한 값들을 고려합니다.  &lt;script type=&quot;math/tex&quot;&gt;y’’_{t-KT}&lt;/script&gt;를 계산할때는 그 값을 중심으로 2H+1개의 인접값들 &lt;script type=&quot;math/tex&quot;&gt;y’’_{t-KT-H}, y’’_{t-KT-H+1}, …, y’’_{t-KT}, y’’_{t-KT+1}…, y’’_{t-KT+H}&lt;/script&gt;를 사용합니다.&lt;/li&gt;
  &lt;li&gt;시즈널 컴포넌트 &lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt; 는 아래와 같이 of &lt;script type=&quot;math/tex&quot;&gt;y’’_t&lt;/script&gt;의 가중합으로 표현됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{s}_t = \sum_{(t’, j) \in \Omega} w^t_{(t’,j’)}y’’_j&lt;/script&gt;

&lt;p&gt;Where the &lt;script type=&quot;math/tex&quot;&gt;w^t_{(t’,j’)}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\Omega&lt;/script&gt; are defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^t_{(t’,j’)} = \frac{1}{z}e^{-\frac{\left\vert j- t \right\vert ^2}{2\delta_d^2}} e^{-\frac{\left\vert y’’_j - y’’_{t’} \right\vert ^2}{2\delta_i^2}} \\
\Omega = \{(t’,j) \vert (t’=t-k \times T, j= t’ \pm h )\} \\
k=1, 2, …, K; \ h=0, 1, …, H&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;시즈널티리를 분리한 후에는, 리마이더 시그널은 아래와 같이 표현됩니다. 
&lt;script type=&quot;math/tex&quot;&gt;r’’’_t = y’’_t - \tilde{s}_t = a_t + (n_t - \hat{n}_t) + (\tau_t - \tilde{\tau}_t) + (s_t - \tilde{s}_t)&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;final-adjustment&quot;&gt;Final Adjustment&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;시즈널리티 컴포넌트의 합계는 0으로 조정되어야합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{I=j}^{I=j+T-1}s_i = 0&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;따라서 평균값(트렌드 &lt;script type=&quot;math/tex&quot;&gt;\tau_1&lt;/script&gt;에 대응되는 값)을 빼줌으로서 시즈널리트를 조정합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\tau}_1 = \frac{1}{T\lfloor N/T \rfloor} \sum_{t=1}^{T\lfloor N/T \rfloor} \tilde{s}_t \\
\hat{s}_t = \tilde{s}_t - \hat{\tau}_1 \\
\hat{\tau}_t = \tilde{\tau}^r_t + \hat{\tau}_1 \\
\hat{r}_t = y_t - \hat{s}_t + \hat{\tau}_t&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;리마인더 시그널 &lt;script type=&quot;math/tex&quot;&gt;\hat{r}_t&lt;/script&gt; 가 수렴할 때까지 위 과정을 반복합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/algorithm1.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/table2.png&quot; width=&quot;450&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">Qingsong Wen et al (2018, Alibaba Group)</summary></entry><entry><title type="html">How does batch normalization help optimization?</title><link href="http://localhost:4000/deep%20learning%20paper/batchnorm/" rel="alternate" type="text/html" title="How does batch normalization help optimization?" /><published>2019-02-12T00:00:00+09:00</published><updated>2019-02-12T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/batchnorm</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/batchnorm/">&lt;p&gt;&lt;b&gt;Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas et al. (2018, MIT) &lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;BatchNorm은 딥러닝의 안정적이고 학습속도를 빠르게 하는데 도움을 주는 기법으로 널리 활용되고 있습니다.&lt;/li&gt;
  &lt;li&gt;하지만 그 활용성에 비해서 왜 BatchNorm이 효과적인지에 대한 실질적인 고찰은 거의 없었으며, 대부분은 internal covariance shift를 줄이는 효과를 줄이기 때문이라고 믿고 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문에서는 internal covariance shift라는 것이 실제로는 BatchNorm과 거의 상관없다는 것을 실험적으로 확인하였습니다. BatchNorm기법이 최적화 함수를 훨씬 smoother하게 만들어주기 때문이라는 것을 이론적, 실험적으로 확인하였으며, 이 영향으로 인해 그래디언트가 더 안정적으로 움직여 빠른 학습이 가능하다는 것을 주장합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;지난 몇년간 딥러닝이 컴퓨터비전, 스피치 인식 등과 같은 풀기어려운 문제를 해결하는데 성공하였으며, 이러한 성공에는 BatchNorm이 큰 기여를 하고 있습니다.&lt;/li&gt;
  &lt;li&gt;BatchNorm의 실용성은 논란의 여기가 없지만, 그러한 효과가 왜 발생하느지에 대한 명확한 이유는 아직 밝혀지지 않았습니다.&lt;/li&gt;
  &lt;li&gt;BatchNorm이 처음 제안되었을 때는 internal covariance shift(ICS)를 최소화하기 위한 방안으로 설명되었지만, 이 연구에서는 ICS와의 연관성을 말해주는 상세한 증거를 찾지 못하였습니다,&lt;/li&gt;
  &lt;li&gt;Constribution
    &lt;ul&gt;
      &lt;li&gt;BatchNorm과 ICS는 아무런 관련이 없다는 것을 설명하며&lt;/li&gt;
      &lt;li&gt;BatchNorm이 효과적인 이유는 최적화 함수를 더 smooth하게 만들어 learning rate가 더 크더라도 안정적인 그래디언트를 보장하여 더 빠른 학습을 가능하게 하기 때문임을 확인하였습니다.&lt;/li&gt;
      &lt;li&gt;이러한 내용을 실험적인 확인 이외에 loss함수와 그 gradient의 Lipschitzness 를 이용해 이론적으로 설명하였습니다.&lt;/li&gt;
      &lt;li&gt;이 고찰을 통해서 BatchNorm과 동일한 효과를 가져오는 다른 기법들이 존재할수 있는 가능성을 제시하였습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;batch-normalization-and-internal-covariance-shift&quot;&gt;Batch normalization and internal covariance shift&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;처음에 Ioffe and Szegedy의 BatchNorm은 모델이 학습될때는 파라미터가 바뀌기때문에 각 레이어의 입력값들의 분포가 달라지는 현상(internal covariate shift)를 줄이기 위해 제안되었습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;BatchNorm이란 각 레이어의 액티베이션값을 평균과 분산을 각 각 0과 1로 정규화시킨 후, 모델의 설명력을 유지하기 위해 다시 scaled and shifted를 해주는 과정으로 이루집니다. 이 과정은 이전 레이어의 non-linearity전에 이루어집니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Does BatchNorm’s performance stem form controlling internal covariate shift?
    &lt;ul&gt;
      &lt;li&gt;BatchNorm 논문에서는 각 레이어의 인풋 분포의 평균과 분산을 제한하는 것이 학습성능에 직접적인 영향을 준다고 주장하였습니다. 이 것을 입증하기 위해 한가지 실험을 수행하였습니다.&lt;/li&gt;
      &lt;li&gt;배치놈 이후에 랜덤한 노이즈를 일부러 주입하여 네트워크를 학습시켜 보았습니다. 노이즈는 평균이 0이 아니고, 분산도 1이 아닌 분포에서 추출하여 각 레이어의 액티베이션에 더해주었습니다. 이 때, 각 스텝마다 노이즈의 분포가 달라지도록 하여 꽤 심한 covariate shift를 만들어보았습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-12/fig2.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fig2는 standard, standard + batchnorm, standard + noisy batchnorm 세가지 네트워크의 학습 성능(좌)을 나타냅니다. 또한 시간에 따른 레이어의 액티베이션의 분포들(우)을 함께 표시하였습니다. 그림에서 볼수 있듯이, 학습데이터셋을 기준으로 batchnorm과 noisy batchnorm의 성능차이는 거의 없는 것을 확인하였습니다. 두가지 모두 standard 보다 높은 성능을 보였습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;i&gt;Noisy batchnorm의 액티베이션 분포들은 불안정하지만, 학습 성능은 좋다는 실험 결과는 batchnorm의 효과가 레이어의 인풋 분포를 안정시키기 때문이다는 주장을 반박하는 결과입니다.&lt;/i&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Is BatchNorm reducing internal covariate shift?
    &lt;ul&gt;
      &lt;li&gt;그렇다면 더 광의적인 측면의 internal covariate shift가 batchnorm의 높은 학습성능과 직접적으로 연관된 것은 아닐까?&lt;/li&gt;
      &lt;li&gt;네트워크의 각각 레이어는 주어진 인풋에 대해서 리스크 최적화 문제를 푸는 것으로 생각할수 있고, 파라미터가 업데이트될 때마다 인풋을 바꾸고, 결과적으로 최적화 문제 자체를 바꾸게 됩니다. Ioffe and Szegedy는 이 현상을 internal covariate shift라고 불렀고, 각 레이어의 인풋 분포 관점에서 설명하려고 했습니다. 하지만 이 관점은 batchnorm의 성공적인 성능을 설명해주지 못한다는 것을 앞서 실험을 통해 살펴보았습니다.&lt;/li&gt;
      &lt;li&gt;인풋 분포가 아니라 전체 최적화 관점에서 각 레이어의 그래디어트 변화를 살펴보도록 하겠습니다.&lt;/li&gt;
      &lt;li&gt;이를 위해서 어떤 레이어의 전(before)/후(after) 그래디언트 변화를 다음과 같이 정의하도록 하겠습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mbox{We define internal covariate shift(ICS) of activation i at time t  to be the difference } \lVert G_{t, i} - G’_{t, I} \rVert_2  \mbox{ where} \\
G_{t,i} = \nabla_{W_i^{(t)}} \mathcal{L}(W_1^{(t)}, …, W_k^{(t)} ; x^{(t)}, y^{(t)}) \\
G^\prime_{t,i}  = \nabla_{W_i^{(t)}} \mathcal{L}(W_1^{(t+1)}, …, W_{i-1}^{(t+1)}, W_i^{(t)}, W_{i+1}^{(t)}, …, W_k^{(t)} ; x^{(t)}, y^{(t)})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G_{t, i}&lt;/script&gt;는 모든 레이어가 동시에 업데이트되는 가정에서의 그래디언트(as is typical)이고, &lt;script type=&quot;math/tex&quot;&gt;G’_{t, I}&lt;/script&gt;는 i번째 레이어 이전의 레이어들이 새로운 값으로 업데이트된 후의 그래디언트입니다. 따라서 G와 G’의 차이는 i번째 레이어의 인풋이 변함에 따라 그 파라미터(&lt;script type=&quot;math/tex&quot;&gt;W_i&lt;/script&gt;)의 optimization landscape가 얼마나 변화하는지를 나타냅니다.&lt;/li&gt;
  &lt;li&gt;정의된 지표를 internal covariate shift 정도로 사용하고, batchnorm을 사용했을때와 사용하지 않았을때를 비교했습니다. &lt;i&gt;기존의 Batchnorm 논문의 주장대로라면 batchnorm을 사용하는 경우, G와 G’간의 상관관계가 높아지기 때문에 ICS는 낮아져야합니다.&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-12/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실험결과, BatchNorm을 사용한 네트워크의 ICS가 오히려 증가하는 것으로 나타났습니다. - fig3&lt;/li&gt;
  &lt;li&gt;(Fig3) Standard + batchNorm가 standard 보다 더 빠르게 학습되지만 (첫번째 컬럼, 정확도와 로쓰 차트),  Standard + batchNorm와 standard의 ICS 변화는 거의 비슷하거나, Standard + batchNorm의 ICS가 standard보다 높은 것으로 나타났습니다. (두번째 &amp;amp; 세번째 컬럼)&lt;/li&gt;
  &lt;li&gt;&lt;i&gt;이 실험결과는 batchNorm 사용하더라도 G와 G’가 서로 uncorrelated하다는 것을 의미합니다. 즉 batchnorm을 사용하여 인풋 분포를 조절하는게 internal covariate shift를 줄이지 못한다는 것입니다.&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-does-batchnorm-work&quot;&gt;Why does BatchNorm work?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The smoothing effect of BatchNorm
    &lt;ul&gt;
      &lt;li&gt;그렇다면 왜 BatchNorm이 효과적일까?&lt;/li&gt;
      &lt;li&gt;결론부터 말하면, BatchNorm이 우리가 풀어야할 최적화문제의 landscape를 smooth하게 만들어주기 때문입니다. loss function의 Lipschitzness를 높여줘, 더 효과적인 &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt;-smoothness를 갖도록 합니다. loss가 작은 비율로 변화하면 gradient의 변화량도 작아집니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mbox{f is L-Lipschitz, If} \left\vert f(x_1) - f(x_2) \right\vert \le L \lVert x_1 - x_2 \rVert, \mbox{for all} x_1 \ and \ x_2 \\
\mbox{f is } \beta-smooth \mbox{, If its gradients are } \beta-Lipschitz \mbox{i.e, if} \left\vert \nabla f(x_1) - \nabla f(x_2) \right\vert \le \beta \lVert x_1 - x_2 \rVert, \mbox{for all } x_1 \ and \ x_2&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Non-BatchNorm 네트워크의 loss function은 non-convex하고 flat regions 또는 sharp local minima를 갖고 있고 있어 gradient가 갑자기 사라지거나(flat region), 갑자기 폭발하기도(sharp local minima)하죠. 반면 BatchNorm에 의해 smooth된 loss function은 gradient가 이러한 위험에 빠질 가능성이 더 낮아 더 안정적이고 예측가능한 학습을 할수 있게 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Exploration of the optimization landscape
&lt;img src=&quot;/assets/img/2019-02-12/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;우선 Loss function의 Lipschitzness를 실험적으로 살펴보았습니다.&lt;/li&gt;
      &lt;li&gt;(Fig4)(a)는 학습시간에 따라 그래디언트에 따라서 움직였을때, loss값이 얼마나 바뀌었는지를 나타냅니다. BatchNorm을 사용한지 않은 바닐라 네트워크에서는 값의 변동폭이 큰 것을 볼수 있습니다. (b)현재 그래디언트 방향과 이전 그래디언트 방향간의 l2 distance를 나타납니다. 마찬가지로 바닐라 네트워크는 그래디언트 간의 거리가 상대적으로 멀고 이는 predictiveness of the gradient가 낮다는 것을 의미합니다. (c)는 effective &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt;-smoothness를 나타냅니다. effective라는 것은 그래디언트 방향으로 움직였을때 그래디언트가 얼마나 바뀌는지를 나타내며, 낮을수록 effective하다고 생각합니다. 이 결과도 앞서와 마찬가지로 BatchNorm을 사용한 경우가 더 effective하다고 나타납니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Is BatchNorm the best (only?) way to smoothen the landscape?
    &lt;ul&gt;
      &lt;li&gt;loss function의 landscape을 smooth하게 만드는 것이 BatchNorm방식이 유일한 것일까?&lt;/li&gt;
      &lt;li&gt;실험을 위해서 여기서는 first momentum(평균)은 batchnorm처럼 고정하고 normalizes를 &lt;script type=&quot;math/tex&quot;&gt;l_p&lt;/script&gt;-norm으로 normalizes해보았습니다. (이렇게 정규화된 값들은 더이상 가우시안 분포가 아니고 안정적인 분포를 보장하진 않지만, Fig5에서 나타나듯 BatchNorm과 동일한 성능을 보입니다.&lt;/li&gt;
      &lt;li&gt;논문에서는 Appendix 결과들을 통해서 &lt;script type=&quot;math/tex&quot;&gt;l_p&lt;/script&gt;-normalization 기법들이 covariate shift를 더 많이 일으키지만, Batchnorm과 마찬가지로 standard 네트워크보다 성능이 좋고 landscape의 smoothness를 개선시킨다는 결과를 말해주고 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;theoretical-analysis&quot;&gt;Theoretical Analysis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;TBU&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문에서는 batchnorm의 효과성이 어디에서 오는지 근본적인 원인을 살펴보았습니다.&lt;/li&gt;
  &lt;li&gt;batchnorm은 internal covariate shift와 거의 상관이 없으며, batchnorm이 오히려 internal covariate shift를 증가시키는 것으로 나타났습니다.&lt;/li&gt;
  &lt;li&gt;대신에 batchnorm은 최적화문제의 landscape를 부드럽게 해주는 효과를 가져오고, 이로 인해서 그래디언트가 예측가능하고, 잘 움직이게 합니다. 이로 인해서 하이퍼파라미터에 로버스트하고, 그래디언트가 사라지거나 폭발하는 현상이 줄어들게 됩니다. 또한 이러한 효과는 batchnorm이 유일하지 않고, 다른 노말리제이션방법들도 동일한 결과를 얻을수 있음을 확인하였습니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>yjucho</name></author><summary type="html">Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas et al. (2018, MIT)</summary></entry><entry><title type="html">Self-Supervised Generative Adversarial Networks</title><link href="http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan/" rel="alternate" type="text/html" title="Self-Supervised Generative Adversarial Networks" /><published>2019-02-08T00:00:00+09:00</published><updated>2019-02-08T00:00:00+09:00</updated><id>http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan</id><content type="html" xml:base="http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan/">&lt;p&gt;&lt;b&gt; Ting Chen et al. (Google Brain, 2018)&lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Conditional GAN은 이미지 생성에서 탁월한 성능을 보이지만, 많은 양의 라벨링 데이터를 필요로 한다는 단점이 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문은 self-supervision learning과 adversarial training 기법을 적용하여 별도의 라벨링 없이도 image representations을 학습하고 좋은 품질의 이미지를 생성할 수 있음을 보였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;GAN의 학습은 고차원의 파라미터 공간에서 non-convex 게임의 내쉬 이퀼리브리움을 찾는 것이기때문에 매우 불안정한다는 단점은 잘 알려져있습니다.&lt;/li&gt;
  &lt;li&gt;학습이 불안정한 현상을 보이는 이유는 generator와 discrimator가 non-stationary environment 에서 학습되기 때문입니다. 특히 discriminator는 fake class의 분포가 계속 변하게 되어 학습에 어려움을 겪습니다. Non-stationary 환경에서는 뉴럴넷은 이전에 학습 정보를 잊어버리고, 만약 discriminator가 이전의 분류 바운더리를 잊어버리면 학습 과정이 불안정(unstable)해지거나 주기적(cyclic)인 현상이 나타납니다.&lt;/li&gt;
  &lt;li&gt;이 현상을 극복하기 위해서 이전 연구들은 주로 conditioning 기법을 사용하였습니다. Supervised information(클래스 라벨)을 이용해 discriminator를 학습시키면 학습이 더 안정되고 catastrophic forgetting같은 현상이 경감됩니다.&lt;/li&gt;
  &lt;li&gt;하지만 기존 방식은 많은 양의 라벨링 데이터가 필요합니다. 또한 라벨링데이터가 있다하더라도 굉장히 sparse하기 때문에 고차원의 추상화된 공간을 모두 커버하기에는 한계가 존재합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Contribution&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문은 라벨링된 데이터 없이 conditioning기법의 장점을 이용하고자 기존 GAN에 self-supervised loss를 더한 Self supervised GAN(SSGAN)을 제안하였습니다.&lt;/li&gt;
  &lt;li&gt;실험을 통해서 self-supervised GAN(SSGAN)이 동일한 실험 조건에서는 unconditional GAN보다 더 좋은 성능을 보임을 확인하였습니다.&lt;/li&gt;
  &lt;li&gt;SSGAN은 향후  high quality, fully unsupervised, natural image synthesis의 새로운 가능성을 제시하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-key-issue--discriminator-forgetting&quot;&gt;A key Issue : discriminator forgetting&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig2.png&quot; width=&quot;400&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fig2 : 학습이 진행될동안 discriminator의 분류 정확도를 관찰한 결과, unconditional GAN은 500k iterations 이후에는 학습된 정보를 잃어버리고 성능이 낮아지는 현상이 일어났습니다. 반면 SSGAN은 학습이 지속됨에 따라 분류 성능도 점차 향상하는 것을 볼 수 있었습니다. (이미지넷 데이터)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig3.png&quot; width=&quot;450&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fig3 : cifar10 데이터에 대해서 각 클래스마다 1k iterations을 학습시키고 10개 클래스에 대해서 10k iterations이 지나면, 다시 처음 클래스를 학습하는 실험을 하였습니다. (a)는 바닐라 클래시파이어로 10k 이후에도 클래스가 바뀔때마다 학습성능이 떨어졌다가 올라가는 모습이 나타나지만, (b)self-supervised loss가 추가된 클래시파이어는 이전 정보를 잃어버리는 현상이 완화된 것을 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-self-supervised-gan&quot;&gt;The Self-Supervised GAN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig1.png&quot; width=&quot;700&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Fig1 : SSGAN의 구조는 discriminator가 generator의 학습성능과 상관없이 의미있는 representation을 학습하도록 되어있습니다. 이를 위해서 이미지를 회전시킨 후 회전된 각도를 예측하도록 하는 self-supervision task을 사용하였습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;회전각도를 예측하는 것을 포함한 loss function은 다음과 같습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_G = -V(G,D) - \alpha \mathbb{E}_{x \sim P_G}  \mathbb{E}_{r \sim R} [log Q_D (R = r \vert x^r )], \\
L_D = V(G,D) - \beta \mathbb{E}_{x \sim P_{data}}  \mathbb{E}_{r \sim R} [log Q_D (R = r \vert x^r )]&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;V(G,D)&lt;/script&gt;은 GAN의 loss function이고, &lt;script type=&quot;math/tex&quot;&gt;r \in R&lt;/script&gt;은 회전각입니다. 이 논문에서는 &lt;script type=&quot;math/tex&quot;&gt;R={0도, 90도, 180도, 270도}&lt;/script&gt;을 사용하였습니다. 이미지 x가 r degree만큼 회전한 것을 &lt;script type=&quot;math/tex&quot;&gt;x^r&lt;/script&gt;이라고 나타냈으며, &lt;script type=&quot;math/tex&quot;&gt;Q(R \vert x^r)&lt;/script&gt;은 주어진 샘플에 대해서 discriminator의 회전각 예측 분포를 의미합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt; Collaborative Adversarial Training&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;SSGAN에서는 기존 GAN과 마찬가지로 true vs. fake prediction에서는 적대적인 학습을 합니다. 하지만 rotation task에서는 discriminator와 generator가 서로 협력적인 (collaborative) 학습을 하게 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;먼저 generator가 실제 이미지와 유사하게 이미지를 생성하여 회전시킨 후 discriminator에게 전달하면, discriminator는 회전된 각도를 감지하게 됩니다. 여기서 generator는 조건부 정보(rotation)을 사용하지 않으므로 항상 회전되지 않은 unright 이미지를 생성합니다.&lt;/li&gt;
  &lt;li&gt;discriminator는 실제 데이터에 대해서만 rotation 을 얼마나 정확하게 예측했는지를 기준으로 학습됩니다. 즉 실제 데이터에 대한 rotation loss만 반영하여 파라미터가 업데이트 됩니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;generator는 회전을 쉽게 감지할수 있도록 이미지를 생성하여 discriminator가 회전을 잘 감지할수있도록 도와줍니다. (discriminator는 실제 이미지의 로테이션을 잘 감지하도록 학습되었기때문에)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Fig1은 학습과정의 파이프라인을 나타냅니다.
    &lt;ul&gt;
      &lt;li&gt;discriminator의 목적은 1) non-rotated img에 대해서 true or fake를 잘 맞추는 것 2) rotated real img에 대해서 rotation angle을 잘 찾는 것 입니다.&lt;/li&gt;
      &lt;li&gt;generator의 목적은 실제 데이터와 유사하게 이미지를 생성하는 것인데, discrimator가 실제 데이터의 로테이션을 잘 감지되도록 학습했기때문에 generator도 회전을 쉽게 감지할수 있는 이미지를 생성하게 됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;실험을 통해서 1) self-supervision이 baseline GAN과 비교하여 representation의 품질을 향상시킴 2) 동일한 학습 조건에서 conditional GAN과 비교가능 수준으로 conditional generation을 향상시킴 을 보였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experimental-settings&quot;&gt;Experimental settings&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;dataset : IMAGENET, CIFAR10, LSUN-BEDROOM, CELEBA-HQ&lt;/li&gt;
  &lt;li&gt;Models :
    &lt;ul&gt;
      &lt;li&gt;baseline models
        &lt;ul&gt;
          &lt;li&gt;unconditional GAN with spectral normalization (Uncond-GAN)&lt;/li&gt;
          &lt;li&gt;conditional GAN using the label-conditioning strategy (Cond-GAN)&lt;/li&gt;
          &lt;li&gt;label-conditional batch normalization in Cond-GAN&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;ResNet architectures for the genertor and discriminator&lt;/li&gt;
      &lt;li&gt;self-modulated batch normalization in SS-GAN(sBN)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig4.png&quot; width=&quot;700&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig5.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/tab1.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/tab2.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">Ting Chen et al. (Google Brain, 2018)</summary></entry><entry><title type="html">시계열 분석 part6 - Spectral analysis</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6/" rel="alternate" type="text/html" title="시계열 분석 part6 - Spectral analysis" /><published>2019-01-23T00:00:00+09:00</published><updated>2019-01-23T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6/">&lt;p&gt;지금까지 우리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;time domain&lt;/code&gt;에서의 여러가지 시계열 모델을 살펴보았습니다. 이번 포스팅은 주어진 시계열 데이터를 &lt;code class=&quot;highlighter-rouge&quot;&gt;frequency domain&lt;/code&gt;에서 분석하는 방법에 대해서 설명하도록 하겠습니다. 수학적으로 다소 복잡해보이지만, 실제로는 numpy 등을 통해서 쉽게 활용할수 있는 방법입니다. 여기서는 이론적인 내용을 통해서 주파수 도메인에서의 개념을 직관적으로 이해하고, 실제 데이터를 통해서 결과값을 이해하고 활용할 수 있는 것을 목표로 합니다. 주파수 분석은 주어진 시계열 데이터의 주기성을 확인하거나, 노이즈를 제거하는 등에 활용될 수 있습니다.&lt;/p&gt;

&lt;p&gt;What we can do with spectral analysis is&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Frequency detection&lt;/li&gt;
  &lt;li&gt;Noise removal&lt;/li&gt;
  &lt;li&gt;Model detection&lt;/li&gt;
  &lt;li&gt;Lag detection (lagged regression)&lt;/li&gt;
  &lt;li&gt;Feature detection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Time domain에서의 시계열 데이터는 특정 시점의 데이터가 과거 시점의 데이터와 어떤 관계가 있는지를 알아보기 위해서 auto covariance function(ACF)을 이용하였습니다. 먼저, Time domain에서의 ACF가 frequency domain에서의 spectral density &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;로 변형될수 있음(interchangeable)을 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;spectral-density&quot;&gt;spectral density&lt;/h2&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Suppose that &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is a zero-mean stationary time series with auto covariance function &lt;script type=&quot;math/tex&quot;&gt;\gamma(\cdot)&lt;/script&gt; satisfying &lt;script type=&quot;math/tex&quot;&gt;\sum_{h=-\infty}^\infty \left\vert \gamma(h) \right\vert \lt \infty&lt;/script&gt;. The spectral density of &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is the function &lt;script type=&quot;math/tex&quot;&gt;f(\cdot)&lt;/script&gt; defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\lambda) = \frac{1}{2\pi} \sum_{h=-\infty}^\infty e^{-ih\lambda} \gamma(h), \ \ \ \ -\infty \lt \lambda \lt \infty&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;e^{ i\lambda} = cos(\lambda) + i sin(\lambda)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i = \sqrt{-1}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\left\vert \gamma(\cdot) \right\vert&lt;/script&gt;의 summability로 인해 &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; 역시 절대적으로 수렴하며, cos와 sin의 주기가 &lt;script type=&quot;math/tex&quot;&gt;2\pi&lt;/script&gt;이기때문에 &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;의 주기도 &lt;script type=&quot;math/tex&quot;&gt;2\pi&lt;/script&gt;가 됩니다. 또한 앞으로의 수식에서는 &lt;script type=&quot;math/tex&quot;&gt;(-\pi, \pi]&lt;/script&gt; 구간에서의 &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;의 값만 고려하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Basic Properties of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;(a) &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is even, i.e., &lt;script type=&quot;math/tex&quot;&gt;f(\lambda) = f(-\lambda)&lt;/script&gt; &lt;br /&gt;
(b) &lt;script type=&quot;math/tex&quot;&gt;f(\lambda) \ge 0&lt;/script&gt; for all &lt;script type=&quot;math/tex&quot;&gt;\lambda \in (-\pi, \pi]&lt;/script&gt;, &lt;br /&gt;
and &lt;br /&gt;
(c) &lt;script type=&quot;math/tex&quot;&gt;\gamma(k) =\int_{-\pi}^\pi e^{ik\lambda} f(\lambda) d\lambda = \int_{-\pi}^\pi cos(k\lambda) f(\lambda) d\lambda&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;f(\lambda)&lt;/script&gt;는 대칭성을 가지고 있고, &lt;script type=&quot;math/tex&quot;&gt;(-\pi, \pi]&lt;/script&gt;에서 항상 양수값을 갖습니다. 그리고 spectral density를 (c)와 같이 적분하여 타임 도메인의 auto covariance function으로 변환할 수 있습니다.&lt;/p&gt;

&lt;p&gt;즉, &lt;script type=&quot;math/tex&quot;&gt;\gamma_X&lt;/script&gt;가 가진 정보와 &lt;script type=&quot;math/tex&quot;&gt;f_X(\lambda)&lt;/script&gt;가 가진 정보가 완전히 동일합니다. 또한 spectral densities는 essentially unique하기 때문에 &lt;script type=&quot;math/tex&quot;&gt;\gamma(\cdot)&lt;/script&gt;에 대응되는 Spectral densities &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt;가 있다면, 이 둘은 &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt;는 서로 동일한 Fourier coefficients를 갖게 되어, 서로 동일한 함수라고 할수 있습니다.&lt;/p&gt;

&lt;p&gt;다음은 우리가 알고 있는 몇개의 stationary time series의 sepectral density를 구하는 예제를 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;White noise&lt;/b&gt; :
If &lt;script type=&quot;math/tex&quot;&gt;\{X_t\} \sim WN(0, \sigma^2)&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;\gamma(0)=\sigma^2&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\gamma(h)=0&lt;/script&gt; for all &lt;script type=&quot;math/tex&quot;&gt;\left\vert h \right\vert \gt 0&lt;/script&gt;. This process has a flat spectral density&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\lambda) = \frac{\sigma^2}{2\pi}, \ \ \ \ \ \ -\pi \gt \lambda \gt \pi&lt;/script&gt;

&lt;p&gt;Each Frequency in the spectrum contributes equally to the variance of the process.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;AR(1)&lt;/b&gt;:
If 
&lt;script type=&quot;math/tex&quot;&gt;X_t = \phi X_{t-1} + Z_t&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\} \sim WN(0, \sigma^2)&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; has spectral density&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
f(\lambda) &amp; = \frac{\sigma^2}{2\pi(1-\phi^2)} (1 + \sum_{h=1}^\infty \phi^h (e^{-ih\lambda} + e^{ih\lambda})) \\
&amp; = \frac{\sigma^2}{2\pi(1-\phi^2)} (1 + \frac{\phi e^{i\lambda}}{1- \phi e^{i\lambda}} + \frac{\phi e^{-i\lambda}}{1- \phi e^{-i\lambda}}) \\
&amp; = \frac{\sigma^2}{2\pi} (1 -2\phi cos \lambda + \phi^2)^{-1}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;b&gt;MA(1)&lt;/b&gt;:
If 
&lt;script type=&quot;math/tex&quot;&gt;X_t = Z_t + \theta Z_{t-1}&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\} \sim WN(0, \sigma^2)&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; has spectral density&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
f(\lambda) &amp; = \frac{\sigma^2}{2\pi} (1 + \theta^2 + \theta(e^{-i\lambda} + e^ {i\lambda})) \\
&amp; = \frac{\sigma^2}{2\pi} (1 + 2\theta cos \lambda + \theta^2)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;b&gt;ARMA(p, q)&lt;/b&gt; :
If &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is a causal ARMA(p, q) process satisfying &lt;script type=&quot;math/tex&quot;&gt;\phi(B)X_t = \theta(B)Z_t&lt;/script&gt;, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_X(\lambda) = \frac{\sigma^2}{2\pi} \frac{\left\vert \theta(e^{-i\lambda})\right\vert ^2}{\left\vert \phi(e^{-i\lambda})\right\vert ^2}&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig1.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;
&lt;small&gt;출처 : &lt;a href=&quot;http://contents.kocw.or.kr/contents4/document/lec/2013/Hanyang/Lee%20Kichun/11.pdf&quot;&gt;Time Series Analysis Lecture Note&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;여기까지 주어진 시계열데이터의 타임 도메인에서의 auto-covariance function이 주파수 도메인의 spectral density function으로 변환가능함을 살펴보았습니다. 앞서 우리는 시계열 데이터의 샘플들로부터 sample ACF를 추정하는 방법을 알아보았습니다. 마찬가지로 주어진 샘플데이터로부터 spectral density function을 추정하는 것은 어떻게 할까요? 이제 시계열 데이터의 spectral density function의 estimate인 &lt;code class=&quot;highlighter-rouge&quot;&gt;periodogram&lt;/code&gt;에 대해서 알아보도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;periodogram&quot;&gt;Periodogram&lt;/h2&gt;

&lt;p&gt;먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;periodogram&lt;/code&gt;을 설명하기 위해 복소수 벡터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;를 생각해보도록 하겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} \in \mathbb{C^n}&lt;/script&gt;

&lt;p&gt;여기서 &lt;script type=&quot;math/tex&quot;&gt;\mathbb{C^n}&lt;/script&gt;는 복소수를 포함한 가능한 모든 컬럼벡터의 집합을 의미합니다. 이제 &lt;script type=&quot;math/tex&quot;&gt;w_k = 2 \pi k/n&lt;/script&gt;라고 표기하고, 여기서 &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; 는  -(n-1)/2와  n/2 사이의 (inclusive) 자연수라고 하겠습니다. 즉,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_k = \frac{2\pi k}{n},  \ \ \ k = -[\frac{n-1}{2}], \cdots, [\frac{n}{2}],&lt;/script&gt;

&lt;p&gt;[y]라는 표기는 y보다 작거나 같은 가장 큰 자연수를 나타냅니다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w_k&lt;/script&gt;와 같은 값들의 집합 &lt;script type=&quot;math/tex&quot;&gt;F_n&lt;/script&gt;를 샘플사이즈가 n인 &lt;b&gt;Fourier frequencies&lt;/b&gt; 라고 합니다. 이때, &lt;script type=&quot;math/tex&quot;&gt;F_n&lt;/script&gt; 는 &lt;script type=&quot;math/tex&quot;&gt;(-\pi, \pi]&lt;/script&gt; 구간의 부분집합으로 표현됩니다.&lt;/p&gt;

&lt;p&gt;마찬가지로 아래와 같은 n개의 벡터를 생각해보도록 하겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_k = \frac{1}{\sqrt{n}} \begin{bmatrix} e^{iw_k} \\ e^{2iw_k} \\ \vdots \\ e^{niw_k}  \end{bmatrix}, \ \ \ \ \  k = -[\frac{n-1}{2}], \cdots, [\frac{n}{2}].&lt;/script&gt;

&lt;p&gt;여기서 &lt;script type=&quot;math/tex&quot;&gt;e_1, \cdots, e_n&lt;/script&gt; 는 아래와 같은 관계를 만족시키는 서로 수직(&lt;b&gt;orthonormal&lt;/b&gt;)인 벡터들입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
e_j * e_k = \begin{cases}
1, &amp; \mbox{if } j =k  \\
0, &amp; \mbox{if } j \ne k
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;e_j *&lt;/script&gt;는 &lt;script type=&quot;math/tex&quot;&gt;e_j&lt;/script&gt;의 k번째 컴포넌트를 복소수 컨주게이트값으로 바꾼 행벡터를 타나냅니다.  row vector whose &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;th component is the complex conjugate of the &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;th component of &lt;script type=&quot;math/tex&quot;&gt;e_j&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;이는 곧 &lt;script type=&quot;math/tex&quot;&gt;\{e_1, \cdots, e_n\}&lt;/script&gt; 가 &lt;script type=&quot;math/tex&quot;&gt;\mathbb{C^n}&lt;/script&gt; 집합의 basis인 것을 의미하고, 따라서, &lt;script type=&quot;math/tex&quot;&gt;\mathbb{C^n}&lt;/script&gt; 에 속하는 임의의 벡터 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;는 이 basis의 선형 조합으로 표현될 수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x = \sum_{k = -[\frac{n-1}{2}]}^{[\frac{n}{2}]} a_k e_k  \ \ \ \ \mbox{(eq.1)}&lt;/script&gt;

&lt;p&gt;이 때, coefficients &lt;script type=&quot;math/tex&quot;&gt;a_k&lt;/script&gt;는 다음과 같이 구할수 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_k = e_k * x = \frac{1}{\sqrt{n}} \sum_{t=1}^n x_t e^{-itw_k}&lt;/script&gt;

&lt;p&gt;여기서 {&lt;script type=&quot;math/tex&quot;&gt;a_k&lt;/script&gt;} 시퀀스를 &lt;script type=&quot;math/tex&quot;&gt;\{x_1, \cdots, x_n\}&lt;/script&gt;의 &lt;b&gt;discrete Fourier transform&lt;/b&gt; 라고 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The periodogram of &lt;script type=&quot;math/tex&quot;&gt;\{x_1, \cdots, x_n\}&lt;/script&gt; is the function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_n(\lambda) = \frac{1}{n} \left\vert \sum_{t=1} ^{n} x_t e^{-it \lambda} \right\vert ^2&lt;/script&gt;

&lt;p&gt;다음의 proposition은 &lt;script type=&quot;math/tex&quot;&gt;I_n(\lambda)&lt;/script&gt;가 &lt;script type=&quot;math/tex&quot;&gt;2\pi f(\lambda)&lt;/script&gt;의 샘플 추정값으로 간주될수 있음을 보입니다. 먼저 sepectral density &lt;script type=&quot;math/tex&quot;&gt;f(\lambda)&lt;/script&gt;의 정의가 다음과 같다는 것을 상기하도록 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2\pi f(\lambda) = \sum_{h=-\infty}^\infty \gamma(h)e^{-ih\lambda}, \ \ \ \ \ \lambda \in (-\pi, \pi]
 \ \ \ \ \ \ \ \mbox{(eq.2)}&lt;/script&gt;

&lt;p&gt;&lt;b&gt;proposition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;If &lt;script type=&quot;math/tex&quot;&gt;x_1, \cdots, x_n&lt;/script&gt; are any real numbers and &lt;script type=&quot;math/tex&quot;&gt;w_k&lt;/script&gt; is any of the nonzero Fourier frequencies &lt;script type=&quot;math/tex&quot;&gt;2\pi k/n&lt;/script&gt; in &lt;script type=&quot;math/tex&quot;&gt;(-\pi, \pi]&lt;/script&gt;, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_n(w_k) = \sum_{\left\vert h \right\vert \lt n} \hat{\gamma}(h)e^{-ihw_k},  \ \ \ \ \ \ \ \mbox{(eq.3)}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\hat{\gamma}(h)&lt;/script&gt; is the sample ACVF of &lt;script type=&quot;math/tex&quot;&gt;x_1, \cdots, x_n&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;(eq.2)와 (eq.3)을 비교하면 두 식이 비슷한 것을 볼수 있고, 자연스럽게 &lt;script type=&quot;math/tex&quot;&gt;I_n(w_k)&lt;/script&gt;이 &lt;script type=&quot;math/tex&quot;&gt;f(\lambda)&lt;/script&gt;의 estimator로 사용할 수 있다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;이제 실제 시계열 데이터에서 spectral analysis를 수행해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 북창원의 기상 데이터(온도)&lt;/li&gt;
  &lt;li&gt;기간 : 2018-11-01 ~ 2018-12-1 (1개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;먼저 Fourier transform통해서 데이터의 주기를 파악해보도록 하겠습니다. Discrete Fourier transform는 numpy 패키지를 통해 쉽게 이용할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'지점'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'stn'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'일시'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'기온(°C)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'temp'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'풍속(m/s)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ws'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'풍향(16방위)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'wd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'습도(&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hm'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Y-&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;m-&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;H:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;## 온도 데이터&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;### fft 수행 &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fftfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;### 주파수 시퀀스&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'frequency(Hz)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'amplitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig2.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;주파수 도메인으로 변환된 그래프를 살펴보면 2개의 peak가 있는 것을 볼 수 있습니다. 해당 주파수 대역을 좀더 확대해서 보면 다음과 같이 약 0.041 과 0.083 에서 peak가 발생한 것으로 보입니다. 따라서 주어진 온도 데이터는 주파수가 0.041인 시그널1과 주파수가 0.083인 시그널2의 합쳐진 것으로 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;주기 = 1/주파수 이기때문에 주어진 온도 데이터의 주기는 1/0.041 = 24로 구해집니다. 해당 데이터의 시간 단위가 1시간이고 주기가 24라는 것을 통해 온도 데이터가 24시간의 주기를 가지고 있다는 사실을 확인할 수 있습니다. 하루동안의 온도 패턴이 반복적인 것을 생각하면 매우 직관적인 결과입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig3.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이제 주파수 값들에서 노이즈에 해당하는 값들을 0으로 바꾼 후 다시 타임 도메인으로 변경해보도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;## fourier[60]과 fourier[120]의 값을 제외하고 모두 0으로 변경&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;61&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## inverse fourier transform &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;denoise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denoise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'frequency(Hz)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'amplitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig4.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;디노이즈 작업은 주파수 도메인에서 강한 값으로 보인 부분(fourier[60]과 fourier[120])을 제외한 나머지 값들은 모두 0으로 변경하는 방식을 사용하였습니다. 그 후 다시 타임 도에인으로 바꿔 시그널의 패턴을 확인하였습니다. 변환된 시계열 데이터는 24시간을 주기로 매우 반복적인 패턴을 보이는 시그널로 변경된 것을 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;위와 같은 주파수 도메인에서의 분석은 음향이나 설비의 진동 등의 신호처리에 많이 사용되고 있으니 알아두시면 매우 유용할 것같습니다.&lt;/p&gt;

&lt;p&gt;그동안 시계열 분석 포스팅을 읽어주셔서 감사합니다. 시계열 분석 포스팅은 이 포스팅을 마지막으로 마무리짓고자 합니다.
이후에는 딥러닝 논문 리뷰, 모델 구현 등의 포스팅으로 찾아뵙도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;앞으로도 같이 즐겁고 재미나게 공부합시다!&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.fft.html#module-numpy.fft&quot;&gt;numpy - Discrete Fourier Transform&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">지금까지 우리는 time domain에서의 여러가지 시계열 모델을 살펴보았습니다. 이번 포스팅은 주어진 시계열 데이터를 frequency domain에서 분석하는 방법에 대해서 설명하도록 하겠습니다. 수학적으로 다소 복잡해보이지만, 실제로는 numpy 등을 통해서 쉽게 활용할수 있는 방법입니다. 여기서는 이론적인 내용을 통해서 주파수 도메인에서의 개념을 직관적으로 이해하고, 실제 데이터를 통해서 결과값을 이해하고 활용할 수 있는 것을 목표로 합니다. 주파수 분석은 주어진 시계열 데이터의 주기성을 확인하거나, 노이즈를 제거하는 등에 활용될 수 있습니다.</summary></entry><entry><title type="html">django - AWS 배포하기</title><link href="http://localhost:4000/django/django-deploy-aws/" rel="alternate" type="text/html" title="django - AWS 배포하기" /><published>2019-01-17T00:00:00+09:00</published><updated>2019-01-17T00:00:00+09:00</updated><id>http://localhost:4000/django/django-deploy-aws</id><content type="html" xml:base="http://localhost:4000/django/django-deploy-aws/">&lt;p&gt;django application을 Amazon Web Service(AWS)에 배포하는 과정을 요약한 포스팅입니다. &lt;a href=&quot;https://nachwon.github.io/django-deploy-1-aws/&quot;&gt;이 블로그&lt;/a&gt;를 주로 참고하였고, 수행 중 발생하는 문제에 대한 trouble shooting 과정을 기억하기 위해 작성하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;aws-가입-후-ec2-서버-셋팅&quot;&gt;AWS 가입 후 EC2 서버 셋팅&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;계정 가입 후 콘솔 로그인
    &lt;ul&gt;
      &lt;li&gt;서비스 검색에 IAM(Identity and Access Management)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/1.png&quot; width=&quot;400&quot; /&gt;
&lt;img src=&quot;/assets/img/2019-01-17/2.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;사용자 탭에 사용자 추가
    &lt;ul&gt;
      &lt;li&gt;엑세스 유형 : 프로그래밍 방식 액세스&lt;/li&gt;
      &lt;li&gt;기존 정책 직접 연결 : AmazonEC2FullAccess&lt;/li&gt;
      &lt;li&gt;완료 창의 Access key ID 와 Secret access key는 꼭 저장해두어야 합니다. “download.csv”를 눌러 저장합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;EC2 서비스로 이동&lt;/li&gt;
  &lt;li&gt;키페어 생성 - pem 파일 다운로드
    &lt;ul&gt;
      &lt;li&gt;다운로드한 pem 파일은 ~/.ssh 폴더에 보관합니다.&lt;/li&gt;
      &lt;li&gt;chmod 400 pem파일 로 권한을 변경합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;인스턴스 생성
    &lt;ul&gt;
      &lt;li&gt;Ubuntu Server 16.04&lt;/li&gt;
      &lt;li&gt;보안 그룹 이름 및 설명 입력&lt;/li&gt;
      &lt;li&gt;검토 후 시작 클릭 후 생성한 키페어 선택합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;생성된 인스턴스에 sss 접속
    &lt;ul&gt;
      &lt;li&gt;ssh -i 키페어경로 유저명@EC2퍼블릭DNS주소&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;서버 환경 설정
    &lt;ul&gt;
      &lt;li&gt;locale 설정&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vi /etc/default/locale

LC_CTYPE=&quot;en_US.UTF-8&quot;
LC_ALL=&quot;en_US.UTF-8&quot;
LANG=&quot;en_US.UTF-8&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get dist-upgrade
sudo apt-get install python-pip
sudo apt-get install zsh
sudo curl -L http://install.ohmyz.sh | sh
sudo chsh ubuntu -s /usr/bin/zsh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;pyenv 설치
    &lt;ul&gt;
      &lt;li&gt;먼저 Ubuntu에서 Build 할 때 공통적으로 발생하는 문제를 방지하기 위해 필요한 패키지들을 설치해준다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev \
libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \
xz-utils tk-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;git clone 후 설치해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git clone https://github.com/pyenv/pyenv.git ~/.pyenv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;~/.zshrc 의 pyenv 환경변수 설정을 해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export PATH=&quot;/home/ubuntu/.pyenv/bin:$PATH&quot;
eval &quot;$(pyenv init -)&quot;
eval &quot;$(pyenv virtualenv-init -)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Python 설치
    &lt;ul&gt;
      &lt;li&gt;pyenv를 통해서 Python을 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv install 3.6.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;Pillow를 위한 Python 라이브러리 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install python-dev python-setuptools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scp를 사용하여 django 프로젝트 파일 업로드하기
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   scp -i 키페어경로 -r 보낼폴더경로 유저명@퍼블릭DNS:받을폴더경로
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;서버에서 Python 가상환경 설치하기
    &lt;ul&gt;
      &lt;li&gt;AWS 서버에 로컬 서버에서 생성했던 pyenv 가상환경 이름과 동일한 이름으로 가상환경을 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pyenv virtualenv 3.6.7 mysite
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;다음의 명령어를 입력하여 requirements.txt 에 기재되어있는 패키지들을 설치해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;만약 pip 버전이 최신버전이 아니라는 에러가 날 경우 아래 명령어를 입력해준 다음 다시 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보안 그룹에 포트 추가하기
    &lt;ul&gt;
      &lt;li&gt;EC2 관리 화면으로 접속한 뒤, 보안 그룹 화면으로 이동합니다.&lt;/li&gt;
      &lt;li&gt;보안 그룹 목록에서 생성한 보안 그룹을 체크하고 인바운드 탭의 편집 버튼을 누릅니다.&lt;/li&gt;
      &lt;li&gt;규칙 추가 버튼을 누른 다음, 포트 범위에 8080 을 입력하고 저장을 누릅니다. &lt;br /&gt;
   &lt;img src=&quot;/assets/img/2019-01-17/3.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;runserver 실행하기
    &lt;ul&gt;
      &lt;li&gt;srv 폴더안의 프로젝트 폴더로 이동하여 runserver 를 포트 8080에 실행합니다.&lt;br /&gt;
   ./manage.py runserver 0:8080&lt;/li&gt;
      &lt;li&gt;위의 모든 과정이 올바르게 수행되었다면 django application 화면이 보일 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;wsgi와-nginx&quot;&gt;WSGI와 NGINX&lt;/h2&gt;

&lt;p&gt;웹 서버 게이트웨이 인터페이스(&lt;code class=&quot;highlighter-rouge&quot;&gt;WSGI&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Web Server Gateway Interface&lt;/code&gt;)는 웹서버와 웹 애플리케이션의 인터페이스를 위한 파이선 프레임워크입니다. runserver 는 개발용이므로 실제 서비스를 운영하는데 부적합하기 때문에 실제로 어플리케이션을 서비스할 때는 웹서버를 사용하게 됩니다. 또한 웹서버가 직접적으로 Python으로 된 장고와 통신할 수 없기 때문에 그 사이에서 WSGI Server(middleware) 가 실행되어 웹서버와 장고를 연결해주는 역할을 합니다.  웹서버가 전달받은 사용자의 요청을 WSGI Server에서 처리하여 Django로 넘겨주고, 다시 Django가 넘겨준 응답을 WSGI Server가 받아서 웹서버에 전달하게 됩니다. WSGI Server에는 여러 가지 종류가 있는데, 그 중 기능이 강력하고 확장성이 뛰어난 &lt;code class=&quot;highlighter-rouge&quot;&gt;uWSGI&lt;/code&gt; 를 사용하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;웹 서버(&lt;code class=&quot;highlighter-rouge&quot;&gt;Web Server&lt;/code&gt;)는 HTTP를 통해 웹 브라우저에서 요청하는 HTML 문서나 오브젝트(이미지 파일 등)을 전송해주는 서비스 프로그램을 말합니다. 웹 서버의 주된 기능은 웹 페이지를 클라이언트로 전달하는 것입니다. 주로 그림, CSS, 자바스크립트를 포함한 HTML 문서가 클라이언트로 전달됩니다. 주된 기능은 콘텐츠를 제공하는 것이지만 클라이언트로부터 콘텐츠를 전달 받는 것도 웹 서버의 기능에 속하고, 클라이언트에서 제출한 웹 폼을 수신하는 것이 그 예에 해당합니다. 여기서는 성능에 중점을 둔 차세대 웹 서버 소프트웨어인 &lt;code class=&quot;highlighter-rouge&quot;&gt;Nginx&lt;/code&gt;를 사용하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-2-wsgi/&quot;&gt;referece&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;uWSGI 설치
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ssh&lt;/code&gt;로 접속 후 배포에 사용할 유저 &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 를 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo adduser deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;uWSGI를 설치할 별도의 python 가상환경을 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv virtualenv 3.6.7 uwsgi-env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이 가상환경을 지금 현재의 가상 컴퓨터 셸에만 일시적으로 적용하도록 설정해줍니다. 서버 전체에서 하나의 uwsgi를 사용하게 하기 위함입니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv shell uwsgi-env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이제 가상환경에 uwsgi 를 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;uWSGI로 서버 열어보기
    &lt;ul&gt;
      &lt;li&gt;uWSGI를 실행하려면 pyenv shell uwsgi-env 를 입력해 uwsgi-env를 적용한 다음, 아래와 같이 입력합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi \
--http :[포트번호] \
--home [virtualenv 경로] \
--chdir [장고프로젝트폴더 경로] \
-w [wsgi 모듈명].wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi \
--http :8080 \
--home /home/ubuntu/.pyenv/versions/mysite \
--chdir /srv/air-pollution/mysite \
-w  mysite.wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ini 파일로 uWSGI 실행하기
    &lt;ul&gt;
      &lt;li&gt;매번 uWSGI를 실행할 때마다 위의 복잡한 명령을 입력하기 번거로우므로, 미리 옵션을 파일로 만들어 저장해놓고 실행할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;로컬에서 장고 프로젝트 폴더에 .config 라는 폴더를 하나 새로 생성하고 그 안에 다시 uwsgi 폴더를 생성하고, uwsgi 폴더 안에 &lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; 파일을 만들어 줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   └── uwsgi
│       ├── mysite.ini
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; :&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[uwsgi]
chdir = /srv/air-pollution/mysite
module = mysite.wsgi:application
home = /home/ubuntu/.pyenv/versions/mysite

uid = deploy
gid = deploy

http = :8080

enable-threads = true
master = true
vacuum = true
pidfile = /tmp/mysite.pid
logto = /var/log/uwsgi/mysite/@(exec://date +%%Y-%%m-%%d).log
log-reopen = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;uWSGI를 실행하기 전에 mysite.ini 파일에 설정해주었던 &lt;code class=&quot;highlighter-rouge&quot;&gt;logto&lt;/code&gt; 옵션의 디렉토리를 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo mkdir -p /var/log/uwsgi/mysite
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;그 다음 아래의 명령을 실행해 ini 파일로 uWSGI를 실행합니다. sudo 권한으로 실행해야 하기 때문에, uwsgi-env 가상환경 폴더 안에 있는 uwsgi를 직접 실행해주어야 합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo /home/ubuntu/.pyenv/versions/uwsgi-env/bin/uwsgi -i /srv/air-pollution/.config/uwsgi/mysite.ini 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Nginx 설치
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# PPA 추가를 위한 필요 패키지
sudo apt-get install software-properties-common python-software-properties

# nginx 안정화 최신버전 PPA 추가
sudo add-apt-repository ppa:nginx/stable

# PPA 저장소 업데이트
sudo apt-get update

# nginx 설치
sudo apt-get install nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;유저 설정
배포에 관한 작업은 &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 유저가 담당하므로 Nginx 의 유저를 &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 로 바꿔줍니다.
Nginx 관련 설정은 /etc/nginx/nginx.conf 에서 관리합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vi /etc/nginx/nginx.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;파일의 첫 줄 user www-data; 를 user deploy; 로 수정해줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;user deploy;
worker_processes auto;
pid /run/nginx.pid;
include /etc/nginx/modules-enabled/*.conf;

events {
        worker_connections 768;
        # multi_accept on;
}

http {
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;Nginx 설정 파일 생성 및 연결
이제 로컬 서버로 빠져나가서 장고 프로젝트 폴더로 이동합니다. 
uWSGI 설정을 저장했던 .config 폴더에 nginx 폴더를 새로 만들고 그 아래에 &lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; 파일을 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   ├── nginx
│   │   └── mysite.conf
│   └── uwsgi
│       ├── mysite.ini
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; :&lt;/p&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;server {
  listen 80;
  server_name *.compute.amazonaws.com;
  charset utf-8;
  client_max_body_size 128M;

  location / {
      uwsgi_pass  unix:///tmp/mysite.sock;
      include     uwsgi_params;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;장고 프로젝트 폴더 내의 &lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/nginx/sites-available/&lt;/code&gt; 경로에 복사해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo cp -f /srv/air-pollution/.config/nginx/mysite.conf /etc/nginx/sites-available/mysite.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이제 다음 명령을 입력하여 sites-available 에 있는 설정파일을 sites-enabled 폴더에 링크해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ln -sf /etc/nginx/sites-available/mysite.conf /etc/nginx/sites-enabled/mysite.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;sites-enabled 폴더의 default 링크는 삭제해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo rm /etc/nginx/sites-enabled/default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;uWSGI 설정
    &lt;ul&gt;
      &lt;li&gt;이제 uWSGI를 Nginx와 통신하도록 설정해줍니다.&lt;/li&gt;
      &lt;li&gt;리눅스에서 관리하는 service 파일을 만들어 서버가 실행될 때 자동으로 uWSGI를 백그라운드에 실행시켜주도록 해야합니다.&lt;/li&gt;
      &lt;li&gt;/장고 프로젝트 폴더/.config/uwsgi/ 에 uwsgi.service 파일을 생성합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   ├── nginx
│   │   └── mysite.conf
│   └── uwsgi
│       ├── mysite.ini
│       └── uwsgi.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;uwsgi.service 파일안에 아래와 같이 작성합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=uWSGI service
After=syslog.target

[Service]
ExecStart=/home/ubuntu/.pyenv/versions/uwsgi-env/bin/uwsgi -i /srv/air-pollution/.config/uwsgi/mysite.ini

Restart=always
KillSignal=SIGQUIT
Type=notify
StandardError=syslog
NotifyAccess=all

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;AWS 서버에 접속해서 uwsgi.service 파일을 /etc/systemd/system/ 에 하드링크를 걸어줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ln -f /srv/air-pollution/.config/uwsgi/uwsgi.service /etc/systemd/system/uwsgi.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;파일을 연결해준 뒤 아래 명령을 실행해서 데몬을 리로드 해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl daemon-reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;그 다음 아래 명령어로 uwsgi 데몬을 활성화 해줍니다. 이제 서버에 접속하기만 해도 uwsgi와 Nginx가 백그라운드에서 실행됩니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl enable uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;소켓 통신 설정 : &lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; 파일을 열어 http = :8080 을 삭제하고 그 부분에 아래와 같이 추가합니다. uWSGI가 http 요청을 받는 대신, /tmp/mysite.sock 파일을 통해 요청을 받도록 소켓 통신을 설정해주는 것입니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt;&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[uwsgi]
chdir = /srv/air-pollution/mysite
module = mysite.wsgi:application
home = /home/ubuntu/.pyenv/versions/mysite

uid = deploy
gid = deploy

socket = /tmp/mysite.sock
chmod-socket = 666
chown-socket = deploy:deploy

enable-threads = true
master = true
vacuum = true
pidfile = /tmp/mysite.pid
logto = /var/log/uwsgi/mysite/@(exec://date +%%Y-%%m-%%d).log
log-reopen = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;데몬 리로드로 다시 불러와주고, Nginx와 uWSGI를 재부팅해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl daemon-reload
sudo systemctl restart nginx uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS 서버 설정
    &lt;ul&gt;
      &lt;li&gt;mysite.conf 파일을 보면 &lt;code class=&quot;highlighter-rouge&quot;&gt;listen 80&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;server_name *.compute.amazonaws.com&lt;/code&gt;부문이 있습니다. listen 80 은 요청을 80번 포트를 통해 받도록 설정하는 것이고, server_name 의 *.compute.amazonaws.com 는 서버의 URL 주소입니다.&lt;/li&gt;
      &lt;li&gt;80번 포트는 웹 브라우저에서 기본적으로 요청을 보내는 포트인데, 아직 AWS 서버의 보안 그룹에 등록되어 있지 않기 때문에 80번 포트를 등록시켜주어야합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/4.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;설정이 끝났으므로 브라우저에서 접속해보면 django app 모습이 나타납니다.&lt;/li&gt;
      &lt;li&gt;만약 에러가 난다면 아래의 명령으로 에러 로그를 확인해서 문제점을 찾을 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Nginx 에러 로그
cat /var/log/nginx/error.log

# uWSGI 로그
cat /var/log/uwsgi/mysite/로그작성날짜.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;static-files을-s3에-저장하기&quot;&gt;static files을 S3에 저장하기&lt;/h2&gt;

&lt;p&gt;Amazon S3 는 아마존 웹 서비스(AWS)에서 제공하는 클라우드 스토리지 서비스입니다. 여기서는 장고 프로젝트에 필요한 스태틱 파일 및 미디어 파일들을 Amazon S3라는 별도의 저장소에 저장하여 관리하는 방법을 정리하였습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;django-storages&lt;/code&gt; 패키지 설치
    &lt;ul&gt;
      &lt;li&gt;터미널에서 아래 명령을 입력하여 django_storages 패키지를 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install django_storages
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;INSTALLED_APPS&lt;/code&gt;에 storages를 추가해줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;INSTALLED_APPS = [
'django.contrib.admin',
...
'storages',
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;boto3&lt;/code&gt; 설치하기
    &lt;blockquote&gt;
      &lt;p&gt;Boto is the Amazon Web Services (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2. Boto provides an easy to use, object-oriented API as well as low-level direct service access. &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&quot;&gt;출처&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;django_storages 패키지는 &lt;code class=&quot;highlighter-rouge&quot;&gt;boto3&lt;/code&gt; 라는 패키지를 사용하여 S3와 통신하도록 구성되어있습니다.&lt;/li&gt;
      &lt;li&gt;터미널에서 아래 명령을 입력하여 boto3 패키지를 설치합니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS에서 S3 시작하기
    &lt;ul&gt;
      &lt;li&gt;먼저, S3는 EC2와 별개의 서비스이므로 &lt;code class=&quot;highlighter-rouge&quot;&gt;IAM&lt;/code&gt;으로 생성했던 유저에게 S3 사용 권한을 추가해주어야 합니다.&lt;/li&gt;
      &lt;li&gt;AWS 콘솔로 접속한 다음 &lt;code class=&quot;highlighter-rouge&quot;&gt;IAM&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;User&lt;/code&gt;탬을 눌러 사용자 관리 화면으로 갑니다.&lt;/li&gt;
      &lt;li&gt;생성되어 있는 사용자 이름을 클릭하여 수정화면으로 들어갑니다.&lt;/li&gt;
      &lt;li&gt;Permissions 탭에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Add permissions&lt;/code&gt; 버튼을 클릭합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/5.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;버킷(bucket) 생성하기
    &lt;ul&gt;
      &lt;li&gt;S3 서비스는 &lt;code class=&quot;highlighter-rouge&quot;&gt;버킷(bucket)&lt;/code&gt;이라는 단위로 저장소를 제공합니다.&lt;/li&gt;
      &lt;li&gt;AWS의 S3콘솔로 이동하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;버킷 만들기&lt;/code&gt;를 눌러 새로운 버킷을 생성합니다.&lt;/li&gt;
      &lt;li&gt;생성한 버킷을 선택하여 Permissions에서 아래와 같이 설정합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/6.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;django 설정
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에서 아래와 같은 변수들을 추가해줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_ACCESS_KEY_ID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_ACCESS_KEY_ID&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_SECRET_ACCESS_KEY&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-BUCKET_NAME&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_DEFAULT_ACL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'public-read'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ap-northeast-2'&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;### When AWS region is 'SEOUL' &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_CUSTOM_DOMAIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s.s3.&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s.amazonaws.com'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_OBJECT_PARAMETERS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'CacheControl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'max-age=86400'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;이제 모든 설정이 끝났습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;S3에 Static 파일 모으기
    &lt;ul&gt;
      &lt;li&gt;S3에 잘 저장이 되는지 확인해보기위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;static&lt;/code&gt; 폴더를 생성한후 test.txt 파일을 생성합니다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에 &lt;code class=&quot;highlighter-rouge&quot;&gt;STATICFILES_DIRS&lt;/code&gt;에 경로를 추가하여 최종적으로는 아래와 같아야합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;STATIC_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'/static/'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_ACCESS_KEY_ID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_ACCESS_KEY_ID&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_SECRET_ACCESS_KEY&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-BUCKET_NAME&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_DEFAULT_ACL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'public-read'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ap-northeast-2'&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;### When AWS region is 'SEOUL' &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_CUSTOM_DOMAIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s.s3.&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s.amazonaws.com'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_OBJECT_PARAMETERS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'CacheControl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'max-age=86400'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATIC_DIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'static'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_DIRS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;STATIC_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;모든 세팅이 끝나면 &lt;code class=&quot;highlighter-rouge&quot;&gt;collectstatic&lt;/code&gt; 명령으로 모든 정적 파일들을 모아줍니다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python manage.py collectstatic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;실행이 완료되면 S3 콘솔로 가서 생성했던 버킷으로 들어가 저장된 파일을 확인합니다.&lt;/li&gt;
      &lt;li&gt;테스트로 추가한 test.txt도 추가된 것을 볼 수 있을 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;외부도메인-연결을-위해-route-53-사용하기&quot;&gt;외부도메인 연결을 위해 Route 53 사용하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;도메인 구입하기
    &lt;ul&gt;
      &lt;li&gt;도메인을 구매하는 사이트는 많으나, 여기서는 cafe24를 이용하였습니다. 
https://www.cafe24.com/?controller=domain_main&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;고정IP 부여받기
    &lt;ul&gt;
      &lt;li&gt;EC2는 기본적으로 유동IP를 가집니다. 그때문에 인스턴스를 stoping 후 다시 시작을 하는 경우, IP가 변경됩니다.&lt;/li&gt;
      &lt;li&gt;유동IP를 사용할 경우 인스턴스를 재시작할때마다 DNS 연결설정을 다시 해주어야하는 번거로움이 생기기 때문에 우선 elastic IP 할당(고정IP 할당)후 도메인을 연결하도록 하겠습니다.&lt;/li&gt;
      &lt;li&gt;EC2 서비스에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;탄력적 IP(Elastic IP)&lt;/code&gt;를 클릭합니다.&lt;/li&gt;
      &lt;li&gt;‘새주소 할당’ -&amp;gt; ‘할당’&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;할당된 IP에 ‘작업’ -&amp;gt; ‘주소 연결’
&lt;img src=&quot;/assets/img/2019-01-17/7.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;아래와 같이 EC2 인스턴스를 연결합니다. 
&lt;img src=&quot;/assets/img/2019-01-17/8.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS의 Route53 설정
    &lt;ul&gt;
      &lt;li&gt;Amazon &lt;code class=&quot;highlighter-rouge&quot;&gt;Route 53&lt;/code&gt;은 가용성과 확장성이 우수한 DNS(도메인 이름 시스템) 웹 서비스입니다.&lt;/li&gt;
      &lt;li&gt;https://console.aws.amazon.com/route53/home?#&lt;/li&gt;
      &lt;li&gt;Create Hosted Zone 을 클릭합니다.
        &lt;ul&gt;
          &lt;li&gt;도메인 이름에 구매한 외부 도메인 주소를 적고 create를 클릭합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;아래와 같은 레코드 셋이 생성된 것을 볼 수 있습니다.&lt;/li&gt;
      &lt;li&gt;create record set을 클릭하여 A type 레코드를 생성합니다.
        &lt;ul&gt;
          &lt;li&gt;value 에 인스턴스에 할당된 고정IP를 적어줍니다. 
&lt;img src=&quot;/assets/img/2019-01-17/9.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;외부도메인에 Name Server 연결하기
    &lt;ul&gt;
      &lt;li&gt;cafe24의 도메인 관리 페이지에 들어가서 &lt;code class=&quot;highlighter-rouge&quot;&gt;네임서버 변경&lt;/code&gt;을 클릭합니다.&lt;/li&gt;
      &lt;li&gt;네임서버를 &lt;code class=&quot;highlighter-rouge&quot;&gt;Route 53&lt;/code&gt;의 &lt;code class=&quot;highlighter-rouge&quot;&gt;NS 레코드값&lt;/code&gt;들로 변경해줍니다. 
&lt;img src=&quot;/assets/img/2019-01-17/10.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모든 것이 완료되었고, 구입한 도메인으로 연결이 성공할때까지 약 30분 정도 소요 시간이 걸릴 수 있습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;trouble-shooting&quot;&gt;trouble shooting&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;b&gt;어드민 로그인 시 “attempt to write a readonly database” 에러 발생&lt;/b&gt;&lt;br /&gt;
db.sqlite3의 권한 문제로 아래 명령어를 이용해 권한 부여를 해주어야합니다. 이때 db.sqlite3가 위치한 부모 디렉토리에도 권한이 부여되여있어야하니 주의하셔야합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo chgrp [deploy를 수행하는 유저그룹] [path-to-db.sqlite3]
sudo chown [deploy를 수행하는 유저] [path-to-db.sqlite3]
sudo chown [deploy를 수행하는 유저] [path-to-parent-directory-of-db.sqlite3]
sudo chgrp [deploy를 수행하는 유저그룹] [path-to-parent-directory-of-db.sqlite3]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-1-aws/&quot;&gt;https://nachwon.github.io/django-deploy-1-aws/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-2-wsgi/&quot;&gt;https://nachwon.github.io/django-deploy-2-wsgi/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-3-nginx/&quot;&gt;https://nachwon.github.io/django-deploy-3-nginx/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-7-s3/&quot;&gt;https://nachwon.github.io/django-deploy-7-s3/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>yjucho</name></author><summary type="html">django application을 Amazon Web Service(AWS)에 배포하는 과정을 요약한 포스팅입니다. 이 블로그를 주로 참고하였고, 수행 중 발생하는 문제에 대한 trouble shooting 과정을 기억하기 위해 작성하였습니다.</summary></entry><entry><title type="html">시계열 분석 part5 - ARMAX, ARFIMA, ARCH, GARCH</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5/" rel="alternate" type="text/html" title="시계열 분석 part5 - ARMAX, ARFIMA, ARCH, GARCH" /><published>2019-01-15T00:00:00+09:00</published><updated>2019-01-15T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5/">&lt;p&gt;지금까지 우리는 시계열 데이터를 설명하기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARMA&lt;/code&gt;모델을 살펴보고, non-stationary 시그널의 경우 differecing을 통해서 stationary 시그널을 얻은 후, ARMA를 적용하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt; 모델을 공부하였습니다. 또한 여러개의 시그널을 동시에 모델링하도록
&lt;code class=&quot;highlighter-rouge&quot;&gt;Vector AR&lt;/code&gt; 모델도 알아보았습니다.&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 1) ARMA 모델에 exogenous(외적 요인) 입력이 추가된 형태인 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt; 모델과 2) 자연수 형태였던 difference order를 유리수로 확장하여 long-term memory를 모델링한 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt; 모델, 3) non-linear 모형의 대표적인 예인 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARCH&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;에 대해서 설명드리고자 합니다. 각 각의 모델들은 ARIMA 모델들의 확장판으로 기존 모델과의 차이점을 이해하는 것을 목표로 합니다.&lt;/p&gt;

&lt;h2 id=&quot;armax---arma-with-exogenous-inputs&quot;&gt;ARMAX - ARMA with exogenous inputs&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt;는 일반적인 ARMA(p, q) process에 시간따라 변하는 외적 요인(&lt;code class=&quot;highlighter-rouge&quot;&gt;exogenous inputs&lt;/code&gt;, &lt;script type=&quot;math/tex&quot;&gt;d_t&lt;/script&gt;)을 추가하여 고려하는 모델입니다. ARMA 모델에 과거 b개의 외적 요인 &lt;script type=&quot;math/tex&quot;&gt;\{d_t\}&lt;/script&gt;의 선형 조합이 포함되며, 이에 따라 &lt;script type=&quot;math/tex&quot;&gt;\eta_1, ..., \eta_k&lt;/script&gt;가 모델 파라미터로 추가됩니다.&lt;/p&gt;

&lt;p&gt;ARMA(p, q) : &lt;script type=&quot;math/tex&quot;&gt;X_t = Z_t + \sum_{i=1}^p \phi_i X_{t-i} + \sum_{j=1}^q \theta_j Z_{t-j}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;
ARMAX(p, q, b) :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t = Z_t + \sum_{i=1}^p \phi_i X_{t-i} + \sum_{j=1}^q \theta_j Z_{t-j} + \sum_{k=1}^b \eta_k d_{t-k}&lt;/script&gt;

&lt;p&gt;statsmodels의 시계열 모형 클래스 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARMA&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SARIMAX&lt;/code&gt; 등은 모두 외부 시계열의 영향을 포함하기 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;exog&lt;/code&gt; 라는 인자를 가지고 있습니다. 이 인자에 외부요인에 해당하는 데이터를 지정해주면 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt; 모델이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 경남 창원시 의창구 원이대로 450(시설관리공단 실내수영장 앞)에서 측정된 초미세먼지(PM2.5)와 인근 북창원의 기상 데이터(온도, 습도)&lt;/li&gt;
  &lt;li&gt;기간 : 	2018-11-01 ~ 2018-12-1 (1개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;미세먼지 측정 농도는 온도와 습도에 영향을 받습니다. 측정방식에 따른 한게점이기도 하고, 미세먼지 발생량 자체가 온도, 습도 기상 상태에 따라 달라질 수 있기 때문입니다. 따라서 초미세먼지 농도를 예측함에 있어서 해당 시간대의 기상 데이터를 외부 요인으로 사용하여 모델을 추정해보았습니다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;df = df[['pm25Value', 'temp','hm']]
df = np.array(df)

arma_mod30 = sm.tsa.ARMA(df[:,0], (3,0)).fit(disp=False)
predict_pm25 = arma_mod30.predict(dynamic=True)
print(&quot;AR(3) model's RMSE: &quot;, mean_forecast_err(df[3:,0], predict_pm25))

armax_mod30 = sm.tsa.ARMA(df[:,0], (3,0), exog=df[:,1:]).fit(disp=False)
predict_pm25 = armax_mod30.predict(dynamic=True)
print(&quot;ARX(3) model's RMSE: &quot;, mean_forecast_err(df[3:,0], predict_pm25))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AR(3) model's RMSE:  8.036039331569588
ARX(3) model's RMSE:  7.710071937116329
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;추정결과, 예측정확도를 평가하는 RMSE가 0.3 줄어든 것을 볼수 있습니다. 외부 요인을 도입함으로서 예측 성능을 높일 수 있다는 것을 보여주는 결과입니다.&lt;/p&gt;

&lt;h2 id=&quot;arfima---autoregressive-fractionally-integrated-moving-average&quot;&gt;ARFIMA - Autoregressive fractionally integrated moving average&lt;/h2&gt;

&lt;p&gt;일반적인 ARMA(p, q)모델은 ACF가 빠르게 감소하는 모습을 띕니다. 이러한 형태를 &lt;code class=&quot;highlighter-rouge&quot;&gt;short-term memory process&lt;/code&gt;라고 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rho(h) \to 0 \ as \ h \to \infty&lt;/script&gt;

&lt;p&gt;하지만 실제 사례에서의 시그널의 ACF는 이상적인 것처럼 빠르게 감소하지 않습니다. 이 경우, &lt;a href=&quot;/spatio-temporal%20data/time-series/time-series-part3/&quot;&gt;Part3&lt;/a&gt;에서 알아본 것처럼 differencing 등을 통해서 이상적인 성질(fast dacaying ACF)을 갖는 새로운 시그널로 변환하여 모델링한다고 설명하였지만, differencing을 반복적으로 수행하더라도 여전히 ACF가 long tail 형태를 띄는 경우가 있습니다. 이를 &lt;code class=&quot;highlighter-rouge&quot;&gt;long-term memory process&lt;/code&gt;라고 하며, &lt;code class=&quot;highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt; 모델을 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(1-B)^d X_t = Z_t, \ \ \ \ \ 0 \lt d \lt \frac{1}{2}&lt;/script&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt;의 &lt;script type=&quot;math/tex&quot;&gt;(1-B)^d&lt;/script&gt; 부분은 d가 양수로 몇번의 differencing을 수행할것인지를 의미했습니다. 하지만 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt;모델에서는 d가 0과 1/2 사이의 유리수라는 점이 다릅니다. 여기서 &lt;script type=&quot;math/tex&quot;&gt;(1-B)^d&lt;/script&gt;는 “fractionally differenced”된 &lt;script type=&quot;math/tex&quot;&gt;\Phi(B)&lt;/script&gt; 라고 부릅니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t = (1-B)^{-d} Z_t
= \sum_{j=0}^\infty \Theta_j B^j Z_t&lt;/script&gt;

&lt;p&gt;ACF of &lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rho(h) = \frac{\Gamma(h+d)\Gamma(1-d)}{\Gamma(h-d+1)\Gamma(d)} \sim h^{2d-1} \ for \ large \ h&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{h=-\infty}^{\infty} |\rho(h)| = \infty&lt;/script&gt;

&lt;p&gt;위와 같이 모든 lag에 대한 ACF를 모두 더하면 &lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;가 되기 때문에, 이를 &lt;code class=&quot;highlighter-rouge&quot;&gt;long-term memory process&lt;/code&gt;를 설명할 수 있습니다. 추정해야할 모델 파라미터는 &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;가 되며, 일반적인 ARFIMA(p, d, q)는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi(B)(1-B)^d X_t = \Theta(B) Z_t&lt;/script&gt;

&lt;p&gt;&lt;small&gt;statsmodels에는 ARFIMA 기능이 지원되지 않아, 분석 사례는 생략하도록 하겠습니다.&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;arch&quot;&gt;ARCH&lt;/h2&gt;

&lt;p&gt;앞서 살펴본 모델들은 {X_t}가 이전 값 혹은 white noise 등 과의 선형(linear) 조합으로 설명되는 경우였습니다. 지금부터는 non-linear 모델의 대표적인 예인 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARCH&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;를 소개하도록 하겠습니다. 먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;ARCH(autoregressive conditional heteroskedasticity)&lt;/code&gt; 모델은 다음과 같이 정의됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
X_t &amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp; = \alpha_0 + \sum_{I=1}^p \alpha_i x_{t-i}^2
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;ARCH(p)를 이해하기 위해서 평균과 분산을 살펴보겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
E[X_t \vert  X_{t-1}, X_{t-2}, …] &amp; = E[\sigma_t * Z_t \vert  X_{t-1}, X_{t-2}, …] \\
&amp; = \sigma_t E[ Z_t \vert  X_{t-1}, X_{t-2}, …]  \\
&amp; = 0 \\ 
\\
E[X_t] &amp; = E_{X_{t-1}, X_{t-2}, …}[E_{X_t \vert  X_{t-1}, X_{t-2}, …} [X_t] ] \\
&amp;= 0\\
\\
Var[X_t \vert  X_{t-1}, X_{t-2}, …] &amp; = E[X_t^2 \vert  X_{t-1}, X_{t-2}, …] \\
&amp; = E[ \sigma_t^2Z_t^2 \vert  X_{t-1}, X_{t-2}, …] \\ 
&amp; = \sigma_t^2 E[ Z_t^2 \vert  X_{t-1}, X_{t-2}, …] \\
&amp; = \sigma_t^2 \\ 
\\
Cov[X_{t+h}, X_t] &amp; = E[X_{t+h} X_t] \\
&amp; = E_{X_{t+h-1}, X_{t+h-2}, …}[X_t E_{X_{t+h} \vert  X_{t+h-1}, X_{t+h-2}, …} [X_{t+h}] ]\\
&amp; =0
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;의 평균은 0이고, lag=h인 관측값간의 공분산은 0입니다. 즉 시간에 따라 변하지 않는 성질을 가지고 있습니다. (&lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;가 white noise라는 것을 의미합니다) 하지만 &lt;script type=&quot;math/tex&quot;&gt;Var[X_t]=\sigma_t^2&lt;/script&gt;이기때문에, nonstationary합니다.  &lt;script type=&quot;math/tex&quot;&gt;\sigma_t^2&lt;/script&gt;를 volatility 라고 부르기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;ARCH(1) : 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\left\{
\begin{align}
X_t &amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp; = \alpha_0 + \alpha_1 X_{t-1}^2 \\
\end{align}
\right. %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;첫번째 식을 제곱한 후, 두 식을 빼면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
X_t^2 &amp; = \sigma_t^2 * Z_t^2 \\
\alpha_0 + \alpha_1 X_{t-1}^2  &amp; = \sigma_t^2 \\
X_t^2 - (\alpha_0 + \alpha_1 X_{t-1}^2) &amp; = \sigma_t^2(Z_t^2 - 1) \\
X_t^2 &amp; = \alpha_0 + \alpha_1 X_{t-1}^2 + \sigma_t^2(Z_t^2 - 1)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;마지막 수식을 살펴보면 &lt;script type=&quot;math/tex&quot;&gt;\{X_t^2\}&lt;/script&gt; 가 직전 값인 &lt;script type=&quot;math/tex&quot;&gt;\{X_{t-1}^2\}&lt;/script&gt;에 영향을 받는 auto-regressive 형태로 설명됩니다. 즉, ARCH(1) 모델은 &lt;script type=&quot;math/tex&quot;&gt;\{X_t^2\}&lt;/script&gt;가 AR(1)인 프로세스와 동일한 것을 알 수 있습니다. 다만 AR(1)의 noise가 non-Gaussian인 것은 주의해야합니다.&lt;/p&gt;

&lt;p&gt;ARCH(p) 모델에서 추정해야하는 모델 파라미터는 &lt;script type=&quot;math/tex&quot;&gt;\alpha_0, \alpha_1&lt;/script&gt;으로 Maximum Likelihood Estimation(MLE)를 이용해 추정합니다.&lt;/p&gt;

&lt;p&gt;ARCH(p) 모델을 앞서 살펴본 linear 모델들과 합친 joint ARCH model도 생각해볼수 있습니다. 예를 들어, AR(1)-ARCH(1) 모델은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;AR(1)-ARCH(1) : &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;는 AR(1) process이고, &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\}&lt;/script&gt;가 ARCH인 모델&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left\{
\begin{align}
X_t &amp; = \phi X_{t-1} + Z_t \\
\sigma_t^2 &amp; = \alpha_0 + \alpha_1 Z_{t-1}^2 \\
\end{align}
\right. %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;generalized-archgarch&quot;&gt;Generalized ARCH(GARCH)&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;는 ARCH 모델의 &lt;script type=&quot;math/tex&quot;&gt;\sigma_t^2&lt;/script&gt;에 auto-regressive한 성질을 추가한 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;GARCH(1, 1) : 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\left\{
\begin{align}
X_t &amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp; = \alpha_0 + \alpha_1 X_{t-1}^2 + \beta_1 \sigma_{t-1}^2 \\
\end{align}
\right. %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;일반적인 GARCH(p, q) 모델은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
X_t &amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp; = \alpha_0 + \sum_{i=1}^p \alpha_i X_{t-i}^2 + \sum_{j=1}^q \beta_j \sigma_{t-j}^2
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;가 ARCH(p) 모델일 경우, &lt;script type=&quot;math/tex&quot;&gt;\{X_t^2\}&lt;/script&gt;는 AR(p)모델이 된다는 것을 앞서 설명드렸습니다. 마찬가지로,  &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;가 GARCH(p, q) 모델일 경우, &lt;script type=&quot;math/tex&quot;&gt;\{X_t^2\}&lt;/script&gt;는 ARMA(p, q)모델이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;ARCH 계열의 모델에 적합한 시계열 데이터은 그 자체로는 auto-correlation 관계가 없지만, 데이터의 제곱값간의 auto-correlation이 존재하는 경우입니다. 주가의 수익률이 대표적인 ARCH모델에 설명되는 시계열 데이터입니다.&lt;/p&gt;

&lt;p&gt;여기서는 ARCH모델을 이용해 주가의 수익률을 예측해보았습니다.&lt;a href=&quot;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&quot;&gt;이 분석 사례&lt;/a&gt;를 참고하여 작성하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas_datareader.data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1990&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;en&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_data_yahoo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^GSPC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;en&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Adj Close'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pct_change&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;수익률 그 자체로는 자기 상관관계가 없지만, 수익률의 제곱값은 자기 상관관계를 갖고 있는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig4.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2019-01-15/fig5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ARCH모델은 파이썬의 &lt;code class=&quot;highlighter-rouge&quot;&gt;arch&lt;/code&gt;패키지를 통해서 사용할 수 있습니다. ARCH(1)모델로 추정해보도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;arch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arch_model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;am1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arch_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;am1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Iteration:      1,   Func. Count:      5,   Neg. LLF: 10051.187042085134
Iteration:      2,   Func. Count:     14,   Neg. LLF: 10047.115662777182
Iteration:      3,   Func. Count:     23,   Neg. LLF: 9820.333972115874
Iteration:      4,   Func. Count:     29,   Neg. LLF: 9810.75544390718
Iteration:      5,   Func. Count:     35,   Neg. LLF: 9804.073095175208
Iteration:      6,   Func. Count:     40,   Neg. LLF: 9801.645677600663
Iteration:      7,   Func. Count:     45,   Neg. LLF: 9801.613667614067
Iteration:      8,   Func. Count:     50,   Neg. LLF: 9801.613523562157
Iteration:      9,   Func. Count:     55,   Neg. LLF: 9801.613520460578
Optimization terminated successfully.    (Exit mode 0)
            Current function value: 9801.613520460529
            Iterations: 9
            Function evaluations: 55
            Gradient evaluations: 9
                      Constant Mean - ARCH Model Results                      
==============================================================================
Dep. Variable:              Adj Close   R-squared:                      -0.000
Mean Model:             Constant Mean   Adj. R-squared:                 -0.000
Vol Model:                       ARCH   Log-Likelihood:               -9801.61
Distribution:                  Normal   AIC:                           19609.2
Method:            Maximum Likelihood   BIC:                           19629.6
                                        No. Observations:                 6552
Date:                Sat, Jan 19 2019   Df Residuals:                     6549
Time:                        17:13:45   Df Model:                            3
                                 Mean Model                                 
============================================================================
                 coef    std err          t      P&amp;gt;|t|      95.0% Conf. Int.
----------------------------------------------------------------------------
mu             0.0482  1.487e-02      3.239  1.202e-03 [1.902e-02,7.732e-02]
                            Volatility Model                            
========================================================================
                 coef    std err          t      P&amp;gt;|t|  95.0% Conf. Int.
------------------------------------------------------------------------
omega          0.9115  4.354e-02     20.935  2.568e-97 [  0.826,  0.997]
alpha[1]       0.3147  4.866e-02      6.467  9.971e-11 [  0.219,  0.410]
========================================================================

Covariance estimator: robust
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.statsmodels.org/dev/index.html&quot;&gt;Statsmodel’s Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4]  &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model#ARMAX&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model#ARMAX&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[7] &lt;a href=&quot;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&quot;&gt;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">지금까지 우리는 시계열 데이터를 설명하기 위해 ARMA모델을 살펴보고, non-stationary 시그널의 경우 differecing을 통해서 stationary 시그널을 얻은 후, ARMA를 적용하는 ARIMA 모델을 공부하였습니다. 또한 여러개의 시그널을 동시에 모델링하도록 Vector AR 모델도 알아보았습니다.</summary></entry><entry><title type="html">시계열 분석 part4 - VAR</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part4/" rel="alternate" type="text/html" title="시계열 분석 part4 - VAR" /><published>2019-01-07T00:00:00+09:00</published><updated>2019-01-07T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part4</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part4/">&lt;p&gt;지금까지는 시계열 데이터가 univariate일 경우를 모델링하는 방법을 알아보았습니다. 이번 포스팅에서는 여러개의 시계열 데이터가 존재할 경우, 즉 multivariate 모델인 Vector AutoRegression (VAR) Model을 알아보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;Bivariate time series에 대해서 알아보도록 하겠습니다. Bivariate time series는 2차원의 벡터 시리즈로 표현됩니다. &lt;script type=&quot;math/tex&quot;&gt;(X_{t1}, X_{t2})’&lt;/script&gt; at time t ( t= 1, 2, 3, …) 와 같이 표현하도록 하겠습니다. 두 컴포넌트 &lt;script type=&quot;math/tex&quot;&gt;\{X_{t1}\}&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\{X_{t2}\}&lt;/script&gt;를 각 각 독립적인 univariate time series로 분석할 수 있지만, 만약 두 컴포넌트사이에 dependency가 존재할 경우 이를 고려해서 모델링하는 것이 더 바람직합니다.&lt;/p&gt;

&lt;p&gt;랜덤 벡터 &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X_t} =(X_{t1}, X_{t2})&lt;/script&gt;’에 대해서 평균벡터와 공분산 메트릭스는 &lt;script type=&quot;math/tex&quot;&gt;\mu_t&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\Gamma(t+h, t)&lt;/script&gt;와 같이 정의됩니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_t := EX_t = \begin{bmatrix} EX_{t1} \\ EX_{t2} \end{bmatrix}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\Gamma(t+h, t) := Cov(\mathbf{X_{t+h}, X_t}) = \begin{bmatrix} Cov(X_{t+h,1}, X_{t1}) &amp; Cov(X_{t+h,1}, X_{t2}) \\ Cov(X_{t+h,2}, X_{t1}) &amp; Cov(X_{t+h,2}, X_{t2}) \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;또한 univariate와 마찬가지로 &lt;script type=&quot;math/tex&quot;&gt;\mu_t&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\Gamma(t+h, t)&lt;/script&gt;가 모두 t와 독립적일 때, (weakly) stationary하다고 정의합니다. 이 때의 공분산 메트릭스는 &lt;script type=&quot;math/tex&quot;&gt;\Gamma(h)&lt;/script&gt;로 표기하고, 메트릭스의 diagonal은 각 각 univariate series인 &lt;script type=&quot;math/tex&quot;&gt;\{X_{t1}\}&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\{X_{t2}\}&lt;/script&gt;의 Auto-Covariance Function와 같습니다. 반면 off-diagonal elements는 &lt;script type=&quot;math/tex&quot;&gt;X_{t+h, i}&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;X_{t, i}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;i \ne j&lt;/script&gt;의 covariances를 나타냅니다. 이 때, &lt;script type=&quot;math/tex&quot;&gt;\gamma_{12}(h) = \gamma_{21}(-h)&lt;/script&gt;	의 특성이 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\Gamma(h) := Cov(\mathbf{X_{t+h}, X_t}) = \begin{bmatrix} \gamma_{11}(h) &amp; \gamma_{12}(h) \\ \gamma_{21}(h) &amp; \gamma_{22}(h) \end{bmatrix} \\ %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; vector와 &lt;script type=&quot;math/tex&quot;&gt;\Gamma(h)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\rho_{ij}(h)&lt;/script&gt;의 estimator는 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{\mathbf{X_n}} = \frac{1}{n} \sum_{t=1}^n\mathbf{X_t}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\hat\Gamma(h) &amp; = n^{-1} \sum_{t=1}^{n-h} \left( \mathbf{X_{t+h}} - \bar{\mathbf{X_n}} \right) \left( \mathbf{X_{t}} - \bar{\mathbf{X_n}} \right) \ \ \ \ \ \ \ &amp; for \ 0 \le h \le n-1 \\
&amp; = \hat\Gamma(-h)'\ \ \ \ \ \ \  &amp; for \ -n+1 \le h \le 0 \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;correlation between &lt;script type=&quot;math/tex&quot;&gt;X_{t+h,i}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;X_{t,j}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\rho_{ij}}(h) = \hat{\gamma_{ij}}(h) (\hat{\gamma_{ii}}(0)\hat{\gamma_{jj}}(0))^{-1/2}&lt;/script&gt;

&lt;p&gt;이를 m개의 다변량 시계열 데이터로 확대하면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{X_t} :=\begin{bmatrix} X_{t1} \\ \vdots \\ X_{tm} \end{bmatrix}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_t := EX_t = \begin{bmatrix} \mu_{t1} \\ \vdots \\ \mu_{tm} \end{bmatrix}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\Gamma(t+h, t) := \begin{bmatrix} \gamma_{11}(t+h, t) &amp; \cdots &amp; \gamma_{1m}(t+h, t) \\ 
\vdots &amp; \vdots &amp; \vdots \\
\gamma_{m1}(t+h, t) &amp; \cdots &amp; \gamma_{mm}(t+h, t) \end{bmatrix} \\
where \ \gamma_{ij}(t+h, t):=Cov(X_{t+h, i}, X_{t, j}) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;br /&gt;
The m-variate series &lt;script type=&quot;math/tex&quot;&gt;\{\mathbf{X_t}\}&lt;/script&gt; is (weakly) stationary if &lt;br /&gt;
(1) &lt;script type=&quot;math/tex&quot;&gt;\mu_X(t)&lt;/script&gt; is independent of t, and &lt;br /&gt;
(2) &lt;script type=&quot;math/tex&quot;&gt;\Gamma_X(t+h, t)&lt;/script&gt; is independent of t for each h.&lt;/p&gt;

&lt;p&gt;이 때 &lt;script type=&quot;math/tex&quot;&gt;\gamma_{ij}(\cdot)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;i \ne j&lt;/script&gt; 는 서로 다른 두 시리즈 &lt;script type=&quot;math/tex&quot;&gt;\{X_{ti}\}&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\{X_{tj}\}&lt;/script&gt; 의 cross-covariance라고 부릅니다. 일반적으로 &lt;script type=&quot;math/tex&quot;&gt;\gamma_{ij}(\cdot)&lt;/script&gt;는 &lt;script type=&quot;math/tex&quot;&gt;\gamma_{ji}(\cdot)&lt;/script&gt;와 같지 않기 때문에 주의하셔야합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Basic Properties of &lt;script type=&quot;math/tex&quot;&gt;\Gamma(\cdot)&lt;/script&gt;:&lt;/b&gt;&lt;br /&gt;
(1) &lt;script type=&quot;math/tex&quot;&gt;\Gamma(h) = \Gamma'(h)&lt;/script&gt; \   &lt;br /&gt;
(2) &lt;script type=&quot;math/tex&quot;&gt;\left\vert\gamma_{ij}(h)\right\vert \le [\gamma_{ii}(0)\gamma_{jj}(0)]^{1/2}&lt;/script&gt;, i,j=1,…,m &lt;br /&gt;
(3) &lt;script type=&quot;math/tex&quot;&gt;\gamma_{ii}(\cdot)&lt;/script&gt; is an autocovariance function, i = 1,…,m &lt;br /&gt;
(4) &lt;script type=&quot;math/tex&quot;&gt;\rho_{ii}(0) = 1&lt;/script&gt; for all i&lt;/p&gt;

&lt;p&gt;Univariate에서 살펴본 white noise 역시 아래와 같이 다변량 정규분포를 따르는 벡터로 정의됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt; &lt;br /&gt;
The m-variate series &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\}&lt;/script&gt; is called white noise with mean 0 and covariance matrix &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;, written
&lt;script type=&quot;math/tex&quot;&gt;\{Z_t\} \sim WN(\mathbf{0}, \Sigma)&lt;/script&gt;, &lt;br /&gt;
if &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\}&lt;/script&gt; is stationary with mean vector &lt;script type=&quot;math/tex&quot;&gt;\mathbf{0}&lt;/script&gt; and covariance matrix function &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align} \Gamma(h) &amp; = \Sigma, \ \ if \ h = 0 \\ &amp; = 0, \ \ \ \ otherwise. \end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;White noise의 선형조합으로 표현되는 m-variate series &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;를 linear process로 부르며, MA(&lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;) 프로세스는 j가 0보다 작은 경우에는 &lt;script type=&quot;math/tex&quot;&gt;C_j=0&lt;/script&gt;인 linear process에 해당합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;br /&gt;
The m-variate series &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is a linear process if it has the representation
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{X_t} = \sum_{j=-\infty}^\infty C_j \mathbf{Z_{t-j}}, \ \ \ \ \ \{\mathbf{Z_{t-j}}\} \sim WN(\mathbf{0}, \mathbf{\Sigma})&lt;/script&gt;,&lt;br /&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\{C_j\}&lt;/script&gt; is a sequence of m X m matrics whose components are absolutely summable.&lt;/p&gt;

&lt;p&gt;또한 causality를 만족하는 모든 ARMA(p, q) 프로세스는 MA(&lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;) 프로세스로 변환할 수 있으며, invertibiliy를 만족하는 모든 ARMA(p, q) 프로세스는 AR(&lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;) 프로세스로 변환할 수 있습니다. causality 조건을 만족하면 항상 stationary하고, stationary ARMA(p, q) process는 항상 causality를 만족합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Causality&lt;/b&gt; &lt;br /&gt;
An ARMA(p, q) process &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is causal, or a causal function of &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\}&lt;/script&gt;, if there exist matrices &lt;script type=&quot;math/tex&quot;&gt;\{\Psi_t\}&lt;/script&gt; with absolutely summable components such that &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;X_t = \sum_{j=0}^{\infty}\Psi_jZ_{t-j}&lt;/script&gt; for all t.&lt;br /&gt;
Causality is equivalent to the condition&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;det\Phi(z) \ne 0&lt;/script&gt; for all &lt;script type=&quot;math/tex&quot;&gt;z \in \mathbb{C}&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;\vert z \vert \le 1&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Causality 조건을 다시 보면 1보다 작은 모든 z에 대해서 &lt;script type=&quot;math/tex&quot;&gt;\Phi(z)&lt;/script&gt;의 determinant는 0이 아니여야합니다.  이는 &lt;b&gt;&lt;script type=&quot;math/tex&quot;&gt;\Phi(z)&lt;/script&gt;의 모든 eigenvalue들이 1보다 작아야한다&lt;/b&gt; 것과 동일합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Yule-walker equation&lt;/b&gt; &lt;br /&gt;
Yule-walker equation을 이용해 모델의 파라미터를 추정하는 방법에 대해서 살펴보도록 하겠습니다. 실제로는 소프트웨어를 통해 계산되기 때문에 복잡한 계산을 수행할 필요는 없지만, 원리를 이해하는 것을 목적으로 합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t = \Phi X_{t-1} + Z_t&lt;/script&gt;

&lt;p&gt;양변에 &lt;script type=&quot;math/tex&quot;&gt;X_{t-h}'&lt;/script&gt;를 곱해줍니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X_t X_{t-h}' = \Phi X_{t-1}X_{t-h}' + Z_tX_{t-h}'&lt;/script&gt;

&lt;p&gt;이후 Expectation을 취해줍니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[X_t X_{t-h}'] = \Phi E[ X_{t-1}X_{t-h}' ] + E[Z_tX_{t-h}' ]&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt;의 평균이 0인 시리즈라고 가정하고, h가 1보다 크거나 같을 때와 h가 0일때로 나눠서 생각해볼수 있습니다.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\Gamma(h) &amp; = \Phi \Gamma(h-1) + \mathbf{0} \ \ \ \ \ \ for \ h \ge 1 \\
\Gamma(0) &amp; = \Phi \Gamma(-1) + \Sigma_Z \\
&amp; = \Phi \Gamma(1)' + \Sigma_Z \ \ \ \ \ \ for \ h =0
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;h가 1일때와 h가 0일때의 두 식을 연립하여 풀면 &lt;script type=&quot;math/tex&quot;&gt;\Phi&lt;/script&gt;를 구할수 있습니다. 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\Gamma(1) &amp; = \Phi \Gamma(0) + \mathbf{0} \ \ \ \ \ \ for \ h = 1 \\
\Gamma(0) &amp; = \Phi \Gamma(1) + \Sigma_Z \ \ \ \ \ \ for \ h =0 
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;cointegration&quot;&gt;Cointegration&lt;/h3&gt;

&lt;p&gt;앞선 nonstationary univariate time series에서 &lt;script type=&quot;math/tex&quot;&gt;\nabla = 1-B&lt;/script&gt;를 이용하여 stationary를 만드는 방법을 이야기한 적 있습니다. 만약 &lt;script type=&quot;math/tex&quot;&gt;\{\nabla^d X_t\}&lt;/script&gt;가 어떤 양수 d에 대해서 stationary이나, &lt;script type=&quot;math/tex&quot;&gt;\{\nabla^{d-1} X_t\}&lt;/script&gt;에 대해서는 nonstationary할 때, &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is integrated of order d라고 하며, &lt;script type=&quot;math/tex&quot;&gt;\{X_t\} \sim I(d)&lt;/script&gt;라고 표기합니다. 마찬가지로 &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; 가 k-variate time series일 경우에도, &lt;script type=&quot;math/tex&quot;&gt;\{\nabla^{d} X_t\}&lt;/script&gt;는 j번째(j=1, …, k) 컴포넌트에 &lt;script type=&quot;math/tex&quot;&gt;(1-B)^d&lt;/script&gt; 오퍼레이터를 적용하여 얻은 시리즈를 의미합니다.&lt;/p&gt;

&lt;p&gt;cointegration이라는 개념은 Granger(1981)에서 처음 도입되고, Engle and Granger(1987)가 개발하였습니다. 여기서는 Lukepohl(1993)의 개념을 사용하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;If d is a positive integer, &lt;script type=&quot;math/tex&quot;&gt;\{\nabla^d X_t\}&lt;/script&gt; is stationary and &lt;script type=&quot;math/tex&quot;&gt;\{\nabla^{d-1} X_t\}&lt;/script&gt; is nonstationary, the k-dimensional time series &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is integrated of order d (&lt;script type=&quot;math/tex&quot;&gt;\{X_t\} \sim I(d)&lt;/script&gt;).&lt;/p&gt;

&lt;p&gt;The I(d) process &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is said to be cointegrated with cointegration vector &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; is a k &lt;script type=&quot;math/tex&quot;&gt;\times&lt;/script&gt; 1 vector such that &lt;script type=&quot;math/tex&quot;&gt;\{\alpha' X_t\}&lt;/script&gt; is integrated of order less than d.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
X_t = \sum_{j=1}^t Z_j, &amp; &amp; t =1, 2, ...,  \ \ &amp; \{Z_t\} \sim IID(0, \sigma^2) \\
Y_t = X_t + W_t, &amp; &amp; t=1, 2, ..., \ \ &amp; \{W_t\} \sim IID(0, \tau^2) \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\{W_t\}&lt;/script&gt; is independent of &lt;script type=&quot;math/tex&quot;&gt;\{Z_t\}&lt;/script&gt;. Then &lt;script type=&quot;math/tex&quot;&gt;\{(X_t, Y_t)'\}&lt;/script&gt; is integrated of order 1 and cointegrated with cointegration vector &lt;script type=&quot;math/tex&quot;&gt;\alpha = (1, -1)'&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;cointegration 개념은 univariate nonstationary time series가 “함께 움직인다”는 아이디어를 설명하는 것입니다.  위의 예제에서 &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt;와 &lt;script type=&quot;math/tex&quot;&gt;\{Y_t\}&lt;/script&gt;는 모두 nonstationary이지만, stationary한 &lt;script type=&quot;math/tex&quot;&gt;\{W_t\}&lt;/script&gt; 부문만 다를뿐 서로 연결되어 있습니다.&lt;/p&gt;

&lt;p&gt;cointegration 방식으로 움직이는 시리즈들은 경제학에서 많이 볼 수 있는데, Engle and Granger (1991)에서는 Northern California와 Southern California에서의 토마토 가격인 &lt;script type=&quot;math/tex&quot;&gt;\{U_t\}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\{V_t\}&lt;/script&gt;를 대표적인 예로 설명하였습니다. 두 시리즈는 서로 연결되어 있기때문에 한 도시에서의 토마토 가격이 상승하면, 다른 도시에서의 토마토를 사서 되파는 상황이 가능하고 이 때문에 두 도시의 가격은 v=u 형태의 직선에 가깝게 됩니다.&lt;/p&gt;

&lt;p&gt;즉, &lt;script type=&quot;math/tex&quot;&gt;\{U_t\}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\{V_t\}&lt;/script&gt;는 시간의 흐름에 따라 nonstationary하게 움직이지만, &lt;script type=&quot;math/tex&quot;&gt;(U_t, V_t)'&lt;/script&gt; 을 2차원 평면에 점으로 표현하면, v=u 직선에서 약간의 랜덤한 편차가 존재하는 형태로 표현될 것입니다. 이때, 이 직선을 attractor for &lt;script type=&quot;math/tex&quot;&gt;(U_t, V_t)'&lt;/script&gt; 라고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;위의 예제에서 &lt;script type=&quot;math/tex&quot;&gt;\nabla = 1-B&lt;/script&gt;를 적용하여 얻은 새로운 시리즈 &lt;script type=&quot;math/tex&quot;&gt;(U_t, V_t)'&lt;/script&gt;라고 하겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
U_t &amp; =  Z_t \\
V_t &amp; = Z_t + W_t - W_{t-1}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\{(U_t, V_t)'\}&lt;/script&gt;는 stationary mutivariate MA(1) process입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
U_t \\
V_t
\end{bmatrix}
= \begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}
\begin{bmatrix}
Z_t \\
Z_t + W_t
\end{bmatrix}
- 
\begin{bmatrix}
0 &amp; 0 \\
-1 &amp; 1
\end{bmatrix}
\begin{bmatrix}
Z_{t-1} \\
Z_{t-1} + W_{t-1}
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;하지만 &lt;script type=&quot;math/tex&quot;&gt;\{(U_t, V_t)'\}&lt;/script&gt;는 AR(&lt;script type=&quot;math/tex&quot;&gt;\infty&lt;/script&gt;)로 표현될수는 없습니다. 메트릭스 &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} - z \begin{bmatrix} 0 &amp; 0 \\ -1 &amp; 1 \end{bmatrix} %]]&gt;&lt;/script&gt; 가 z=1일때 zero determinant이기때문에 causuality condition을 만족하지 않기때문입니다.&lt;/p&gt;

&lt;h2 id=&quot;실제-데이터를-이용한-var-forecasting&quot;&gt;실제 데이터를 이용한 VAR Forecasting&lt;/h2&gt;

&lt;p&gt;앞에서 계속 사용한 초미세먼지 데이터(PM2.5)에 미세먼지(PM10) 농도를 추가하여 Bivariate 시계열 예측을 수행해보도록 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 경남 창원시 의창구 원이대로 450(시설관리공단 실내수영장 앞)에서 측정된 초미세먼지(PM2.5)와 미세먼지(PM10)&lt;/li&gt;
  &lt;li&gt;기간 : 	2018-9-18 19:00 ~ 2018-12-18 17:00 (3개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-07/output_0_0.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;statsmodel의 VAR 모듈을 이용해 multivariate time sereis 모델링을 수행할 수 있습니다. VAR 모듈의 select_order 함수는 AIC, BIC, HQIC와 같은 지표를 기준으로 가장 최적의 order를 결정할수 있도록 도와줍니다. 최대 order를 30으로 하고 최적 order를 탐색한 결과, 아래와 같이 AIC 기준으로는 9, BIC 기준으로 5가 결정된 것을 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pm10Value'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'pm25Value'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'H'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select_order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## &amp;lt;statsmodels.tsa.vector_ar.var_model.LagOrderResults object. Selected orders are: AIC -&amp;gt; 9, BIC -&amp;gt; 5, FPE -&amp;gt; 9, HQIC -&amp;gt; 5&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;BIC 기준으로 order 5를 선택하여 모델을 학습한 결과는 아래와 같습니다. 모델이 추정한 파라미터를 이용해 수식으로 적어보면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \begin{bmatrix} X_t \\ Y_t \end{bmatrix} = &amp; \begin{bmatrix} 0.227950 &amp; 1.021808 \\ 0.013951 &amp; 0.856883 \end{bmatrix} + \begin{bmatrix} X_{t-1} \\ Y_{t-1} \end{bmatrix} + \\ &amp; \begin{bmatrix} 0.175133 &amp; -0.172207 \\ 0.005520 &amp; 0.090531 \end{bmatrix} + \begin{bmatrix} X_{t-2} \\ Y_{t-2} \end{bmatrix} +  \\ &amp; \begin{bmatrix} 0.114712 &amp;-0.170387  \\ -0.000139 &amp; -0.031543 \end{bmatrix} + \begin{bmatrix} X_{t-3} \\ Y_{t-3} \end{bmatrix} + \\ &amp; \begin{bmatrix} 0.07475107 &amp; -0.01361328 \\ -0.00297173 &amp; -0.0174331 \end{bmatrix} +  \begin{bmatrix} X_{t-4} \\ Y_{t-4} \end{bmatrix} + \\ &amp; \begin{bmatrix} 0.16981114 &amp; -0.20771503 \\ 0.00960018 &amp; 0.03822593 \end{bmatrix} + \begin{bmatrix} X_{t-5} \\ Y_{t-5} \end{bmatrix} +  \begin{bmatrix} Z_t \\ W_t \end{bmatrix}\end{align} %]]&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  Summary of Regression Results   
==================================
Model:                         VAR
Method:                        OLS
Date:           Mon, 14, Jan, 2019
Time:                     16:47:40
--------------------------------------------------------------------
No. of Equations:         2.00000    BIC:                    8.37752
Nobs:                     2179.00    HQIC:                   8.35103
Log likelihood:          -15249.5    FPE:                    4170.38
AIC:                      8.33576    Det(Omega_mle):         4139.93
--------------------------------------------------------------------
Results for equation pm10Value
===============================================================================
                  coefficient       std. error           t-stat            prob
-------------------------------------------------------------------------------
L1.pm10Value         0.246944         0.022176           11.136           0.000
L1.pm25Value         0.996998         0.096106           10.374           0.000
L2.pm10Value         0.200154         0.022561            8.872           0.000
L2.pm25Value        -0.199703         0.124451           -1.605           0.109
L3.pm10Value         0.147570         0.022565            6.540           0.000
L3.pm25Value        -0.191717         0.124290           -1.543           0.123
L4.pm10Value         0.113603         0.022163            5.126           0.000
L4.pm25Value        -0.040803         0.096037           -0.425           0.671
===============================================================================

Results for equation pm25Value
===============================================================================
                  coefficient       std. error           t-stat            prob
-------------------------------------------------------------------------------
L1.pm10Value         0.015231         0.005147            2.959           0.003
L1.pm25Value         0.856493         0.022305           38.399           0.000
L2.pm10Value         0.007163         0.005236            1.368           0.171
L2.pm25Value         0.087437         0.028884            3.027           0.002
L3.pm10Value         0.001760         0.005237            0.336           0.737
L3.pm25Value        -0.028244         0.028846           -0.979           0.328
L4.pm10Value         0.000100         0.005144            0.019           0.984
L4.pm25Value         0.023794         0.022289            1.068           0.286
===============================================================================

Correlation matrix of residuals
            pm10Value  pm25Value
pm10Value     1.000000   0.273513
pm25Value     0.273513   1.000000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Univariate에서와 마찬가지로 모델의 적합성을 검증하기 위해 residual analysis를 수행합니다. residual plot과 residual acf 등을 그려 모델 적합성을 검증합니다. 두 시리즈의 residual acf가 거의 zero에 가가운 것을 볼 수가 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acorr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-07/output_1_0.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2019-01-07/output_1_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 plot_forecast 혹은 forecast 함수를 이용해 미래값을 예측할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_forecast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_stderr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-07/output_2_0.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.statsmodels.org/dev/index.html&quot;&gt;Statsmodel’s Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4]  &lt;a href=&quot;https://en.wikipedia.org/wiki/Cointegration&quot;&gt;https://en.wikipedia.org/wiki/Cointegration&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">지금까지는 시계열 데이터가 univariate일 경우를 모델링하는 방법을 알아보았습니다. 이번 포스팅에서는 여러개의 시계열 데이터가 존재할 경우, 즉 multivariate 모델인 Vector AutoRegression (VAR) Model을 알아보도록 하겠습니다.</summary></entry><entry><title type="html">시계열 분석 part3 - Non-stationary</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part3/" rel="alternate" type="text/html" title="시계열 분석 part3 - Non-stationary" /><published>2018-12-31T00:00:00+09:00</published><updated>2018-12-31T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part3</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part3/">&lt;p&gt;Part1에서는 stationarity를 가정으로, 시계열 데이터의 기본 모델인 AR과 MA에 대해서 알아보고 모델의 파라미터를 추정하기 위해서 Yule-Walker Equations을 알아보았습니다.  또한 모델의 order를 결정하기 위해 ACF, PACF를 이용하는 방법을 살펴보았습니다. 실제 분석에서 모델의 파라미터를 추정하는 것은 소프트웨어를 이용해 자동적으로 계산되기 때문에 하나 하나를 기억할 필요는 없지만, 그 원리에 대해서 이해하는 것을 목적으로 합니다. Part2에서는 실제 데이터를 이용해 stationarity 가정을 검증하고, 적합한 모델을 찾고 모델의 order를 결정하는 방법, 추정한 모델을 진단하고 검증하는 방법들을 알아보았습니다. AIC, BIC, HQIC와 같은 지표를 사용하여 여러가지 모델 중 더 나은 성능의 모델을 선택할 수 있고, 모델의 residual을 이용해 모델을 진단하는 과정을 직접 수행해보았습니다. 또한 최종 선택한 모델을 이용해 미래 값을 예측(forecast)해보고, MSE를 이용해 예측력을 평가해보기도 하였습니다.&lt;/p&gt;

&lt;p&gt;이번 Part3에서는 non-stationary 시계열 데이터를 모델링하는 방법들에 대해서 이야기해보도록 하겠습니다. 앞서 포스팅에서 살펴보았듯이 주어진 데이터 &lt;script type=&quot;math/tex&quot;&gt;{x_1, …, x_n}&lt;/script&gt;에 대한 시계열 차트를 그렸을때, (a) stationarity와 비교하여 명확한 편차 변화가 보이지 않고 (b) ACF가 점차 감소하는 모습을 보이면 (평균을 0로 맞춘 후) ARMA를 사용하면 됩니다.&lt;/p&gt;

&lt;p&gt;그렇지 않았을 때는 주어진 데이터를 변환시켜 (a)와 (b) 특정을 갖는 새로운 시계열 데이터를 생성하는 방법을 사용해야합니다. 이 때 주로 사용하는 방법은 “difference(차분)”으로, difference를 통해 얻은 새로운 시리즈 &lt;script type=&quot;math/tex&quot;&gt;{y_1, … y_n}&lt;/script&gt;가 ARMA를 따를 때, ARIMA 프로세스를 따른다고 표현합니다.&lt;/p&gt;

&lt;p&gt;A generalization of this class, which incorporates a wide range of nonstationary series, is provided by the ARIMA processes, i.e., processes that reduce to ARMA processes when differenced finitely many times&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;If d is a nonnegative integer, then &lt;script type=&quot;math/tex&quot;&gt;{X_t}&lt;/script&gt; is an ARIMA(p, d, q) process if &lt;script type=&quot;math/tex&quot;&gt;Y_t := (1-B)^dX_t&lt;/script&gt; is a causal ARMA(p, q) process.&lt;/p&gt;

&lt;p&gt;참고로 B는 backward shift operator를 의미합니다. &lt;script type=&quot;math/tex&quot;&gt;BX_t = X_{t-1}&lt;/script&gt;로 &lt;script type=&quot;math/tex&quot;&gt;\nabla X_t = X_t - X_{t-1} = (1-B) X_t&lt;/script&gt;로 표기합니다.&lt;/p&gt;

&lt;p&gt;이해를 돕기 위해서 ARIMA(1, 1, 0) process를 따르는 데이터를 생성한후, sample ACF, sample PACF를 살펴보도록 하겠습니다. statsmodels의 arma_generate_sample를 이용해 ARMA(1,0) 프로세스를 따르는 데이터를 생성한 후(&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; = 0.8), cumsum()을 이용하면 ARIMA(1,1,0) 프로세스를 따르는 데이터를 생성할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statsmodels.api&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alphas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;arma10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arma_generate_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;arima110&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arma10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 인공 데이터의 sample ACF와 sample PACF를 나타내면 아래와 같습니다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plt.plot(arima110)
plt.show()
sm.tsa.graphics.plot_acf(arima110, lags=50)
sm.tsa.graphics.plot_pacf(arima110, lags=50)
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-31/output_0_0.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_1_0.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_1_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서도 알 수 있듯이 ARIMA 모델의 적합성을 나타내는 가장 큰 증거는 양의 sample ACF가 천천히 감소하는 모습을 띄는 것입니다. 따라서 non-stationary로 진단되는 데이터의 경우에는, 데이터가 ARMA 프로세스로 표현될수 있게  &lt;script type=&quot;math/tex&quot;&gt;\nabla = 1-B&lt;/script&gt; 오퍼레이터를 적용해야합니다.  &lt;script type=&quot;math/tex&quot;&gt;\nabla = 1-B&lt;/script&gt; 오퍼레이터를 적용하는 것은 ACF가 현재보다 더 급격하게 감소하는 모습을 보일 때까지 반복할 수 있습니다. 실제로 위의 인공데이터에서 &lt;script type=&quot;math/tex&quot;&gt;\nabla&lt;/script&gt; 오퍼레이터를 한번 적용한 후 다시 시계열 차트와 sample ACF, sample PACF를 그려본 결과는 아래와 같습니다. (앞의 것에 비해서 ACF가 더 급격히 감소하는 것을 볼 수 있습니다)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plt.plot(arma10)
plt.show()
sm.tsa.graphics.plot_acf(arma10, lags=50)
sm.tsa.graphics.plot_pacf(arma10, lags=50)
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-31/output_2_0.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_2_1.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_2_2.png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;arima_mod110&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ARIMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arima110&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arima_mod110&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'variance :'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arima_mod110&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                             ARIMA Model Results                              
==============================================================================
Dep. Variable:                    D.y   No. Observations:                  199
Model:                 ARIMA(1, 1, 0)   Log Likelihood                -270.813
Method:                       css-mle   S.D. of innovations              0.941
Date:                Mon, 31 Dec 2018   AIC                            545.626
Time:                        06:49:49   BIC                            552.212
Sample:                             1   HQIC                           548.291
                                                                              
==============================================================================
                 coef    std err          z      P&amp;gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1.D.y      0.8085      0.041     19.576      0.000       0.728       0.889
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            1.2369           +0.0000j            1.2369            0.0000
-----------------------------------------------------------------------------
variance : 0.8895674306182718
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Estimated parameters from data : 
&lt;script type=&quot;math/tex&quot;&gt;(1-0.8085)(1-B)X_t = Z_t, \ \ \ \ \ \ \ \{Z_t\} \sim WN(0, 0.8798)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;True generating Process : 
&lt;script type=&quot;math/tex&quot;&gt;(1-0.8)(1-B)X_t = Z_t, \ \ \ \ \ \ \ \ \ \ \ \ \{Z_t\} \sim WN(0, 1)&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;statsmodel의 ARIMA를 이용해 추정한 모델 파라미터와 실제 데이터를 생성할 때 사용한 파라미터가 거의 비슷한 것을 볼 수 있습니다. ARIMA 모델을 추정하는 방법은 difference을 적용하는 것을 제외하고는 이후 과정은 ARMA와 비슷한 맥략을 유지합니다.&lt;/p&gt;

&lt;h3 id=&quot;identification-techniques&quot;&gt;Identification Techniques&lt;/h3&gt;

&lt;p&gt;&lt;b&gt; (a) Preliminary Transformations &lt;/b&gt; 
ARMA 모델을 사용하기 전에 주어진 데이터가 stationarity 가정에 더 부합한 새로운 시리즈로 변환할 필요성이 있는지 검토해야합니다. 예를 들어 스케일에 대해 의존도가 나타나는 경우, 로그변환을 취해서 의존성을 제거해야합니다.(&lt;a href=&quot;https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation&quot;&gt;Box-Cox transformation&lt;/a&gt;) 또한 시계열 차트에서 전체적으로 우상향/우하향하는 추세(trend)나 주기적으로 반복되는 패턴(seasonality)이 발견될 수 있습니다. 이런 경우 2가지 방법으로 처리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;1) Classical decomposition - trend component, seasonal component, random residual component&lt;/p&gt;

&lt;p&gt;2) Differencing - Wine sale의 예시에서는 12개월 주기로 반복되는 패턴이 존재하므로, &lt;script type=&quot;math/tex&quot;&gt;{(1-B^{12})V_t}&lt;/script&gt;를 적용&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statsmodels.api&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'monthly-australian-wine-sales-th.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skiprows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'euc-kr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v_t_st&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;311&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'o'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'$U_t$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;312&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'orange'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'o'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'$V_t = lnU_t$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;313&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'green'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'o'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'$V_t^* = (1-B^{12})V_t$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suptitle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Monthly Australian Wine Sales'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-31/output_6_0.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt; (b) Identification and Estimation &lt;/b&gt; 전처리 변환을 통해서 stationarity 가정에 부합하는 시리즈를 얻을 후에는 적합한 ARMA(p, q)를 찾습니다. p와 q를 먼저 결정해야하는데, 보통 p와 q를 크게 설정할 수록 추정된 모델의 성능이 더 좋은 것으로 나타납니다. 추정해야하는 파라미터 갯수가 많아질수록 패널티가 증가하도록 AIC 등과 같은 지표를 사용하는 것이 바람직합니다. 또한 모델을 선택한 후에는 residual이 white noise가 맞는지 검증하는 작업을 수행해야합니다. 이에 대한 내용은 part2에서 이미 살펴보았으니 이번에는 자세히 다루지 않겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;stationary_series&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_st&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stattools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arma_order_select_ic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stationary_series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'aic'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bic'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## result.aic_min_order = (2,2)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## result.bic_min_order = (1,1)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;wine_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ARMA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_st&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aic_min_order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wine_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'variance :'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wine_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                            ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                  175
Model:                     ARMA(2, 2)   Log Likelihood                  95.322
Method:                       css-mle   S.D. of innovations              0.139
Date:                Mon, 31 Dec 2018   AIC                           -180.643
Time:                        20:50:06   BIC                           -164.819
Sample:                             0   HQIC                          -174.225
                                                                            
==============================================================================
                coef    std err          z      P&amp;gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1.y        0.0304      0.055      0.556      0.579      -0.077       0.138
ar.L2.y        0.8740      0.047     18.621      0.000       0.782       0.966
ma.L1.y        0.2052      0.086      2.398      0.018       0.038       0.373
ma.L2.y       -0.7948      0.085     -9.367      0.000      -0.961      -0.628
                                    Roots                                    
=============================================================================
                Real          Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            1.0524           +0.0000j            1.0524            0.0000
AR.2           -1.0872           +0.0000j            1.0872            0.5000
MA.1           -1.0000           +0.0000j            1.0000            0.5000
MA.2            1.2582           +0.0000j            1.2582            0.0000
-----------------------------------------------------------------------------
variance : 0.019416898661637372
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;seasonal-arima-models&quot;&gt;Seasonal ARIMA models&lt;/h3&gt;

&lt;p&gt;앞선 설명에서 이미 차분을 통해서 seasonality를 제거하는 방법을 언급하였지만, 조금 더 포멀한 방식으로 seasonal ARIMA를 정의하면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;If d and D are nonnegative integers, then &lt;script type=&quot;math/tex&quot;&gt;\{X_t\}&lt;/script&gt; is a seasonal &lt;script type=&quot;math/tex&quot;&gt;ARIMA(p, d, q) \times (P, D, Q)_s&lt;/script&gt; process with period s if the differenced series &lt;script type=&quot;math/tex&quot;&gt;Y_t=(1-B)^d(1-B^s)^D X_t&lt;/script&gt; is a causal ARMA process defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi(B)\Phi(B^s)Y_t = \theta(B)\Theta(B^s)Z_t, \ \ \ \{Z_t\} \sim WN(0, \sigma^2)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\phi(z) = 1 - \phi_1z - ... - \phi_p z^p,  \Phi(z) = 1 -\Phi_1z - ... - \Phi_Pz^P, \\ \theta(z) = 1 + \theta_1z + ... + \theta_qz^q&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\Theta(z) = 1+ \Theta_1z + ... + \Theta_Qz^Q.&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;모델 order를 결정하기 위해서 총 7가지의 파라미터&lt;script type=&quot;math/tex&quot;&gt;(p, d, q, P, D, Q)_s&lt;/script&gt;가 존재합니다. 예를 들어 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;p : order of non-seasonal AR terms&lt;/li&gt;
  &lt;li&gt;d : order of non-seasonal differencing&lt;/li&gt;
  &lt;li&gt;q : order of non-seasonal MA terms&lt;/li&gt;
  &lt;li&gt;P : order of seasonal AR (i.e. SAR) terms&lt;/li&gt;
  &lt;li&gt;D : order of seasonal differencing (I.e. power of (1 - &lt;script type=&quot;math/tex&quot;&gt;B^s&lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;Q : order of seasonal MA (i.e. SMA) terms&lt;/li&gt;
  &lt;li&gt;s : the number of time steps for a single seasonal period&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Example - &lt;script type=&quot;math/tex&quot;&gt;SARIMA(1, 0, 0, 1, 0, 1)_{12}&lt;/script&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;(1-\phi_1B)(1-\Phi_1B^{12})X_t = (1+\Theta_1B^{12})Z_t&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;X_t - \phi_1X_{t-1} - \Phi_1X_{t-12} +  \phi_1\Phi_1X_{t-13} = Z_t + \Theta_1Z_{t-12}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Example - &lt;script type=&quot;math/tex&quot;&gt;SARIMA(0, 1, 1, 0, 0, 1)_{4}&lt;/script&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;(1-B)X_t = (1+\Theta_1B^{4})(1+\theta_1B)Z_t&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;X_t - X_{t-1} = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-4} + \theta_1\Theta_1Z_{t-5}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Seasonality가 존재하는 시계열 데이터의 ACF는 아래와 같이 zero에 수렴하지 않고 주기적인 패턴이 나타나는 것이 특징입니다. 예를 들어 &lt;script type=&quot;math/tex&quot;&gt;SARIMA(0,0,1, 0, 0,1)_{12}&lt;/script&gt; 의 ACF를 계산해보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Example - &lt;script type=&quot;math/tex&quot;&gt;SARIMA(0, 0, 1, 0, 0, 1)_{12}&lt;/script&gt;&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
X_t &amp; = (1 + \Theta_1B^{12})(1+\theta_1B)Z_t \\
X_t &amp; = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-12} + \theta_1\Theta_1Z_{t-13} \\
\\
\gamma(0) &amp; = Cov(X_t, X_t)=Var(X_t) \\
X_t &amp; = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-12} + \theta_1\Theta_1Z_{t-13} \\
Var(X_t) &amp; = \sigma_Z^2 + \theta_1^2\sigma_Z^2 + \Theta_1^2\sigma_Z^2 + \theta_1^2\Theta_1^2\sigma_Z^2 \\
\gamma(0) &amp; = (1+\theta_1^2)(1+\Theta_1^2)\sigma_z^2 \\
\\
\gamma(1) &amp; = Cov(X_t, X_{t-1}) \\
X_t &amp; = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-12} + \theta_1\Theta_1Z_{t-13} \\
X_{t-1} &amp; = Z_{t-1} + \theta_1Z_{t-2} + \Theta_1Z_{t-13} + \theta_1\Theta_1Z_{t-14} \\
\gamma(1) &amp; = \theta_1\sigma_Z^2 + \theta_1\Theta_1^2\sigma_Z^2\\
\gamma(1) &amp; = \theta_1(1+\Theta_1^2)\sigma_Z^2
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;참고. &lt;script type=&quot;math/tex&quot;&gt;Z_t&lt;/script&gt; is independent with &lt;script type=&quot;math/tex&quot;&gt;Z_{t-1}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\rho(1) &amp; = \frac{\gamma(1)}{\gamma(0)} = \frac{\theta_1}{1 + \theta_1^2} \le \frac{1}{2}
\\
\\
\gamma(2) &amp; = Cov(X_t, X_{t-2}) \\
X_t &amp; = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-12} + \theta_1\Theta_1Z_{t-13} \\
X_{t-2} &amp; = Z_{t-2} + \theta_1Z_{t-3} + \Theta_1Z_{t-14} + \theta_1\Theta_1Z_{t-15} \\
\rho(2) &amp; = 0 \\
\rho(i) &amp; = 0, \ \ \ \ \ \ \ for \ i = 2, 3, … 10\\
\\
\gamma(11) &amp; = Cov(X_t, X_{t-11}) \\
X_t &amp; = Z_t + \theta_1Z_{t-1} + \Theta_1Z_{t-12} + \theta_1\Theta_1Z_{t-13} \\
X_{t-11} &amp; = Z_{t-11} + \theta_1Z_{t-12} + \Theta_1Z_{t-23} + \theta_1\Theta_1Z_{t-24} \\
\gamma(11) &amp; = \theta_1\Theta_1\sigma_Z^2\\
\rho(11) &amp; = \frac{\gamma(11)}{\gamma(0)} = \frac{\theta_1\Theta_1}{(1 + \theta_1^2)(1 + \Theta_1^2)} \le \frac{1}{4} 
\end{align} %]]&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statsmodels.api&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sarima_00100112&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arma_generate_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sarima_00100112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sarima_00100112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_pacf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sarima_00100112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SARIMAX&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sarima_00100112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seasonal_order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-31/output_7_0.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_7_1.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_7_2.png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                                Statespace Model Results                                 
==========================================================================================
Dep. Variable:                                  y   No. Observations:                  200
Model:             SARIMAX(0, 0, 1)x(0, 0, 1, 12)   Log Likelihood                -272.506
Date:                            Wed, 02 Jan 2019   AIC                            551.013
Time:                                    22:27:26   BIC                            560.908
Sample:                                         0   HQIC                           555.017
                                            - 200                                         
Covariance Type:                              opg                                         
==============================================================================
                coef    std err          z      P&amp;gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
ma.L1          0.4721      0.070      6.791      0.000       0.336       0.608
ma.S.L12       0.6453      0.061     10.587      0.000       0.526       0.765
sigma2         0.8638      0.093      9.326      0.000       0.682       1.045
===================================================================================
Ljung-Box (Q):                       36.60   Jarque-Bera (JB):                 1.18
Prob(Q):                              0.62   Prob(JB):                         0.55
Heteroskedasticity (H):               1.10   Skew:                            -0.18
Prob(H) (two-sided):                  0.70   Kurtosis:                         2.93
===================================================================================
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 말씀드렸다시피, Seasonal ARIMA는 7개의 hyper parameter(trend order: p,d,q와 seasonal order : P,D,Q,S)를 갖습니다. Part2에서 이야기한 검증 방법들을 사용하여 7개의 hyper parameter를 구성할수 있지만, 각각에 맞춰 신중한 분석과 도메인 지식이 필요합니다. (대안으로 hyper parameter 모음을 그리드 서치 형태로 실험한 후 선택할 수 있습니다. 자세한 내용은 &lt;a href=&quot;https://machinelearningmastery.com/how-to-grid-search-sarima-model-hyperparameters-for-time-series-forecasting-in-python/&quot;&gt;포스팅&lt;/a&gt;을 참고하세요.&lt;/p&gt;

&lt;h2 id=&quot;실제-데이터를-이용한-seasonal-arima-forecasting&quot;&gt;실제 데이터를 이용한 Seasonal ARIMA Forecasting&lt;/h2&gt;

&lt;p&gt;Part2에서 사용한 초미세먼지 농도를 사용하여 Seasonal ARIMA를 적용해보도록 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 경남 창원시 의창구 원이대로 450(시설관리공단 실내수영장 앞)에서 측정된 초미세먼지(PM2.5)&lt;/li&gt;
  &lt;li&gt;기간 : 	2018-9-18 19:00 ~ 2018-12-18 17:00 (3개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-25/output_4_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;grid search방식을 사용하여 적절한 모델 order를 탐색하였습니다. 7개의 파라미터의 탐색범위는 아래와 같고, 모델 선택 기준으로는 AIC 지표를 사용하였습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;p_params = [0, 1, 2]&lt;/li&gt;
  &lt;li&gt;d_params = [0, 1]&lt;/li&gt;
  &lt;li&gt;q_params = [0, 1, 2]&lt;/li&gt;
  &lt;li&gt;t_params = [‘n’,’c’,’t’,’ct’]&lt;/li&gt;
  &lt;li&gt;P_params = [0, 1, 2]&lt;/li&gt;
  &lt;li&gt;D_params = [0, 1]&lt;/li&gt;
  &lt;li&gt;Q_params = [0, 1, 2]&lt;/li&gt;
  &lt;li&gt;m_params = [24] ## 하루 주기가 있다고 가정하여 24시간으로 고정&lt;/li&gt;
  &lt;li&gt;총 1,296개의 조합을 탐색&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;전체 코드는 &lt;a href=&quot;https://gist.github.com/yjucho1/fa517213628e0f8fcbf10a96cbe01141&quot;&gt;여기&lt;/a&gt;를 참고하세요.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;탐색결과&lt;/b&gt;
    best 3 :
    [(2, 0, 2), (1, 1, 2, 24), ‘n’] 11723.18462075862
    [(2, 0, 2), (1, 1, 2, 24), ‘c’] 11725.455126156874
    [(1, 0, 2), (1, 1, 2, 24), ‘n’] 11725.651159324498&lt;/p&gt;

&lt;p&gt;1296가지 모델들의 AIC 히스토그램
&lt;img src=&quot;/assets/img/2018-12-31/output_8_0.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AIC가 가장 낮았던 &lt;script type=&quot;math/tex&quot;&gt;SARIMA(2, 0, 2, 1, 1, 2)_{24}&lt;/script&gt; 모델을 검증하고, 모델을 이용해서 예측을 수행해보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;residual plot
&lt;img src=&quot;/assets/img/2018-12-31/output_8_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;residual acf, pacf
&lt;img src=&quot;/assets/img/2018-12-31/output_8_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;residual qq plot&lt;br /&gt;
&lt;img src=&quot;/assets/img/2018-12-31/output_8_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;residual normality test :&lt;br /&gt;
NormaltestResult(statistic=561.8797124030831, pvalue=9.758222244224708e-123)&lt;/p&gt;

&lt;p&gt;위 결과를 종합해보면 residual이 White Noise이고, 정규분포를 따른다고 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이제 이 모델을 이용하여 forcasting을 수행해보도록 하겠습니다. dynamic 옵션을 False로 설정하는 것은 항상 in-sample 데이터를 사용하여 미래값을 예측하는 것이고, True로 설정할 경우 이전 lag의 모델 예측값을 사용해서 계산하는 것입니다. 첫번째 예측값을 이후 lag에서 계속 사용하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018-12-31/output_8_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;예측력을 평가하기 위해 RMSE는 다음과 같습니다. AR(8) 모델과 비교하여 약 0.0257가 감소한 것을 볼 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;SARIMA(2,0,2,1,1,2, 24) model’s RMSE : 2.8916720525590627&lt;/b&gt;&lt;/li&gt;
  &lt;li&gt;AR(1) model’s RMSE:  3.006486217286414&lt;/li&gt;
  &lt;li&gt;AR(3) model’s RMSE:  2.9717700323027256&lt;/li&gt;
  &lt;li&gt;AR(8) model’s RMSE:  2.9174007777104203&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기까지 non-stationary 모델을 살펴보았습니다. Differencing을 이용해 ARMA을 적용하는 ARIMA모델을 살펴보았고, seasonality까지 함께 고려하는 SARIMA까지 알아보았습니다. 또한 실제 데이터를 이용하여 SARIMA의 하이퍼파라미터를 그리드탐색하여 최적의 모델 order를 결정하였고, 이를 통해서 AR모델 대비 예측력(RMSE)가 0.0257가 향상된 결과를 얻을수 있었습니다.&lt;/p&gt;

&lt;p&gt;다음 포스팅에서는 multivariate time series에 대해서 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;감사합니다!&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.statsmodels.org/dev/index.html&quot;&gt;Statsmodel’s Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://www.coursera.org/learn/practical-time-series-analysis/home/info&quot;&gt;Coursera - Practical Time Series Analysis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://en.wikipedia.org/wiki/Partial_correlation&quot;&gt;wikipedia - Partial correlation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] &lt;a href=&quot;https://machinelearningmastery.com/how-to-grid-search-sarima-model-hyperparameters-for-time-series-forecasting-in-python/&quot;&gt;How to grid search SARIMA model hyperparameters for time series forecasting in python&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><summary type="html">Part1에서는 stationarity를 가정으로, 시계열 데이터의 기본 모델인 AR과 MA에 대해서 알아보고 모델의 파라미터를 추정하기 위해서 Yule-Walker Equations을 알아보았습니다. 또한 모델의 order를 결정하기 위해 ACF, PACF를 이용하는 방법을 살펴보았습니다. 실제 분석에서 모델의 파라미터를 추정하는 것은 소프트웨어를 이용해 자동적으로 계산되기 때문에 하나 하나를 기억할 필요는 없지만, 그 원리에 대해서 이해하는 것을 목적으로 합니다. Part2에서는 실제 데이터를 이용해 stationarity 가정을 검증하고, 적합한 모델을 찾고 모델의 order를 결정하는 방법, 추정한 모델을 진단하고 검증하는 방법들을 알아보았습니다. AIC, BIC, HQIC와 같은 지표를 사용하여 여러가지 모델 중 더 나은 성능의 모델을 선택할 수 있고, 모델의 residual을 이용해 모델을 진단하는 과정을 직접 수행해보았습니다. 또한 최종 선택한 모델을 이용해 미래 값을 예측(forecast)해보고, MSE를 이용해 예측력을 평가해보기도 하였습니다.</summary></entry></feed>