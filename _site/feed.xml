<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-08-28T12:03:47+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">yjucho’s blog</title><subtitle>DATA, Deep Learning, AI</subtitle><author><name>yjucho</name></author><entry><title type="html">SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series</title><link href="http://localhost:4000/s/SOMCPC/" rel="alternate" type="text/html" title="SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series" /><published>2023-08-22T00:00:00+09:00</published><updated>2023-08-22T00:00:00+09:00</updated><id>http://localhost:4000/s/SOMCPC</id><content type="html" xml:base="http://localhost:4000/s/SOMCPC/">&lt;p&gt;&lt;b&gt;Huijben, Iris AM, et al. (ICLR poster 2023)&lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;self-organizing-map-som&quot;&gt;self-organizing map (SOM)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;preserving the topological structure&lt;/code&gt; of the data&lt;/li&gt;
  &lt;li&gt;K개의 node\(\phi\)를 가정하고 각 데이터 포인트 \(z\)를 1개의 카운터파트 노드(winning node) \(q_{\phi}(z)\)로 할당함&lt;/li&gt;
&lt;/ul&gt;

\[q_{\phi}(z) = \phi[argmin_i(||\phi, z||_2^2)] \\\]

&lt;p&gt;At training, each ϕi is updated as follows&lt;/p&gt;

\[\phi(i)^{(n+1)} = \phi(i)^{(n)} + \eta^{(n)}\mathcal{S}_i(q_{\phi}(z))(z - \phi(i)^{(n)} ) \\
where \ \mathcal{S}_i(q_{\phi}(z)) = \text{exp}(-\frac{d_i^{(n)}}{2(\sigma^{(n)})^2}) \\
d_i^{(n)} = ||\mathcal{P}[q_{\phi}(z)],\mathcal{P}[\phi_i^{(n)}]||_2^{2} \\
\sigma^{(n)} =\sigma^{(0)}\text{exp}(-\frac{n}{\lambda})\]

&lt;ul&gt;
  &lt;li&gt;winning node와 그와 가가운 노드들은 데이터 z와 가까운 쪽으로 업데이트됨&lt;/li&gt;
  &lt;li&gt;\(\eta^{(n)}\) : decreasing learning rate&lt;/li&gt;
  &lt;li&gt;\mathcal{S}&lt;em&gt;i(q&lt;/em&gt;{\phi}(z)) : distance from the winning node&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;som-cpc&quot;&gt;SOM-CPC&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;a representation learning model that learns to map windows of time series data to a structured 2D grid for the purpose of pattern discovery
&lt;img src=&quot;/assets/img/2023-08-22/fig1.png&quot; /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TBU&lt;/code&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="s" /><summary type="html">Huijben, Iris AM, et al. (ICLR poster 2023)</summary></entry><entry><title type="html">The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting</title><link href="http://localhost:4000/time-series/LTSF-CD-and-CI/" rel="alternate" type="text/html" title="The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting" /><published>2023-08-22T00:00:00+09:00</published><updated>2023-08-22T00:00:00+09:00</updated><id>http://localhost:4000/time-series/LTSF-CD-and-CI</id><content type="html" xml:base="http://localhost:4000/time-series/LTSF-CD-and-CI/">&lt;p&gt;&lt;b&gt;Han, Lu, Han-Jia Ye, and De-Chuan Zhan (2023)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;우왕 2023년ㅎㅎㅎ&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;h2 id=&quot;analysis&quot;&gt;Analysis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;CD전략과 CI전략에서의 yule-walker equation 분석과 train과 test데이터셋의 각 채널별 ACF와 전체 채널의 ACF합 비교해 봄&lt;/li&gt;
  &lt;li&gt;학습데이터로부터 파라미터 \(W\)를 추정한 모델 (\(R(\hat{W})\))의 리스크분석과 CD 및 CI 전락으로 학습된 모델에 대해 각 데이터셋뱔 통계값(train error, test error, diff W, generalization error)를 확인함&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-guide&quot;&gt;Practical Guide&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이전 섹션을 통해서 CD 학습전략이 capacity는 높지만, robustness 측면에서는 떨어지는 것을 확인하였다. 반대로 CI 학습전략은 robustness 측면에서는 강건함을 보였다.&lt;/li&gt;
  &lt;li&gt;이번 섹션은 위와 같은 특성을 고려하여 CD 전략을 개선함으로써 CI 전략의 성능(capacity)보다 더 좋은 성능을 낼수있음을 실험적으로 확인하고자 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;predict-residuals-with-regularization&quot;&gt;Predict Residuals with Regularization&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2023-08-22/fig7.png&quot; /&gt;&lt;br /&gt;
위에 Fig 7은 실제 값과, CD와 CI 전략간의 예측값을 비교하여 살펴본 결과, CD 학습에 의한 모델이 sharp하며, 강견하지 않은(non-robust) 예측값을 생성하는 것을 예시로 보여주고 있다. 이러한 현상을 개선하기 위해 이 연구에서는 regularization를 이용하며 Residual을 예측하는 objective를 제안하였다.&lt;/p&gt;

\[min_{f} \frac{1}{N} \sum_{i=1}^{N} \ell (f(X^{(i)}-N^{(i)})+N^{(i)}, Y^{(i)}) + \lambda\Omega(f)
\\ where \ N^{(i)}=X_{:,L}^{(i)}\]

&lt;p&gt;\(N^{(i)}\)는 입력값 X의 마지막 값입니다. reqularization term \(\Omega\)는 pytorch의 L2를 사용하였다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-08-22/table4.png&quot; /&gt;&lt;br /&gt;
Table4는 실험 결과를 보여준다. Linear 모델과 Transformer 모델에 제안한 방법(PRReg)를 목적식으로 사용하였을때 결과로, 적절한 \(\lambda\)를 사용할경우 CI전략보다 더 우수한 성능을 보인다. PRReg는 기본적으로 CD전략이고 regularization term의 \(\lambda\)가 너무 크면 언더피팅되고, 너무 작으면 CD와 마찬가지로 오버피팅되어 robustness가 떨어지는 것을 확인할수 있었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-08-22/table5.png&quot; /&gt;&lt;br /&gt;
PatchTST와 비교 (patchtst가 가장 우수하거나, transfomer+PRReg모델모다 더 나은 성능)&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Time-series" /><summary type="html">Han, Lu, Han-Jia Ye, and De-Chuan Zhan (2023)</summary></entry><entry><title type="html">Dynamic Time Warping(DTW)</title><link href="http://localhost:4000/time-series/dtw/" rel="alternate" type="text/html" title="Dynamic Time Warping(DTW)" /><published>2019-05-01T00:00:00+09:00</published><updated>2019-05-01T00:00:00+09:00</updated><id>http://localhost:4000/time-series/dtw</id><content type="html" xml:base="http://localhost:4000/time-series/dtw/">&lt;p&gt;두 시계열 데이터간의 유사도를 어떻게 계산할 수 있을까? 두 시계열이 동일한 길이의 시퀀스라면 단순히 상관계수를 구하는 것이 가능하지만, 현실 세계의 시계열 데이터는 그렇지 않은 경우가 많습니다. 예를 들어 아래와 같은 두 시계열 데이터를 살펴보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig1.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;육안으로 보기엔 두 시계열 모두 두 개의 peak를 가지고 있고 전체적으로 우상향하는 모습이 매우 유사해보입니다. 두 시계열 간의 상관계수를 구해보도록 하겠습니다. 어랏, 두 데이터의 길이가 다르기 때문에 바로 계산되지 않네요.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## ValueError: all the input array dimensions except for the concatenation axis must match exactly
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;유사도를 측정하기 위한 가장 간단한 방법은 상대적으로 길이가 짧은 시계열1 데이터를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;interpolation&lt;/code&gt;하여 길이를 동일하게 맞춘 후, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;np.corrcoef&lt;/code&gt;를 사용하여 상관계수를 계산하는 것입니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;len_ts1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len_ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interp_ind&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len_ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interp_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Comparison : ts1_interp vs. ts2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1 - interpolation'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## correlation coefficent
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#### output
# array([[ 1.        ,  0.85206492],
#        [ 0.85206492,  1.        ]])
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig2.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;단순히 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;선형 보간(linear interpolation)&lt;/code&gt; 방법은 기존의 시계열 데이터1이 가지고 있는 모습을 꽤 왜곡시킨는 결과를 낳습니다. 2개의 spike형태의 peak가 사라진 것을 볼 수 있습니다. 실제로 단순히 데이터 포인트를 늘려서 대응방식으로 비교하는 것은 합리적이지 못한 경우가 많습니다.&lt;/p&gt;

&lt;p&gt;이렇게 길이가 서로 다른 두 시계열의 유사도를 계산하는 방법으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DTW(Dynamic Time Warping)&lt;/code&gt;를 사용할 수 있습니다. DTW는 시퀀스의 길이를 고려하지 않기 때문에 서로 다른 길이의 시퀀스의 유사도를 바로 계산할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Dynamic_time_warping.png/440px-Dynamic_time_warping.png&quot; width=&quot;200&quot; /&gt; &lt;br /&gt; &lt;small&gt;In time series analysis, dynamic time warping (DTW) is one of the algorithms for measuring similarity between two temporal sequences, &lt;u&gt;which may vary in speed&lt;/u&gt;. For instance, similarities in walking could be detected using DTW, even if one person was walking faster than the other, or if there were accelerations and decelerations during the course of an observation. DTW has been applied to temporal sequences of video, audio, and graphics data — indeed, any data that can be turned into a linear sequence can be analyzed with DTW. A well known application has been automatic speech recognition, to cope with different speaking speeds. Other applications include speaker recognition and online signature recognition. Also it is seen that it can be used in partial shape matching application. &lt;i&gt;- &lt;a href=&quot;https://en.wikipedia.org/wiki/Dynamic_time_warping&quot;&gt;위키피디아&lt;/a&gt;&lt;/i&gt; &lt;/small&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;** 아래는 DTW의 개념을 소개하기 위해 &lt;a href=&quot;https://jsideas.net/bitcoin_dtw/&quot;&gt;jsideas님의 포스팅&lt;/a&gt;를 인용하였습니다.&lt;/p&gt;

&lt;p&gt;n개의 데이터포인트가 있는 시퀀스 X와 m개의 데이터포인트가 있는 시퀀스 Y가 있다고 하겠습니다. 이 두 시퀀스를 각 각 x축과 y축에 늘어놓고 데이터 포인트간의 거리(예를 들어 유클리디언 거리)를 구하면, 그 값둘은 m\(\times\)n의 매트릭스 형태가 됩니다. 이 매트릭스를 cost matrix라고 하도록 하겠습니다. cost matrix를 heatmap형식으로 표현하면 아래 그림처럼, 두 데이터 포인트간 거리가 짧은 곳은 어둡게, 거리가 먼 곳은 흰색으로 표현됩니다. DTW알고리즘은 저 cost matrix 상의 좌하단에서 우상단까지 가는 최적의 경로를 찾는 문제를 푸는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig5.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이 최적화문제의 목적식은 좌하단(0,0)에서 우상단(m, n)을 이동하는데 드는 비용을 최소화하는 것이고, 이때 3가지 제약조건이 존재하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig6.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;두 시퀀스의 처음과 끝은 같아야 합니다. 즉 무조건 좌하단에서 시작해서 우하단에서 끝나야합니다.&lt;/li&gt;
  &lt;li&gt;x나 y축, 혹은 그 두 축에서 음의 방향으로 이동하지 않습니다.&lt;/li&gt;
  &lt;li&gt;이동할때 정해진 스텝사이즈 (예를 들어 오른쪽과 위쪽 한칸씩만 이동가능하다던지..(0,1) or (1,0) or (1,1))만큼 이동가능합니다. 가능한 스텝사이즈를 늘릴수록 더 많은 경우 수를 검색하기 때문에 최적에 가까운 경로를 얻을 수 있지만, 그만큼 계산속도가 느려지게 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DTW는 결국 X와 Y를 늘어놓고 X의 특정 데이터포인트가 Y의 어떤 데이터포인트에 가장 적합한지를 판정하는 로직이므로, X와 Y의 길이가 늘어나면 늘어날수록 검색 비용이 늘어나는 단점이 있습니다.&lt;/p&gt;

&lt;p&gt;또한 앞서 언급했듯이 최적값을 찾기 위해 검색가능한 스텝사이즈를 늘리면 계산 속도가 느려지게 되고, 반대로 스텝사이즈를 줄이면 전후 경로만 보고 기계적으로 두 시퀀스를 정렬시켜버리는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pathological alignment&lt;/code&gt; 문제가 발생할 수 있습니다. 일반적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pathological alignment&lt;/code&gt;문제를 피하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Sakoe-Chiba Band&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Itakura Parallelogram&lt;/code&gt;방법 등을 사용하기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig7.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;python에서의-dtw&quot;&gt;python에서의 DTW&lt;/h3&gt;
&lt;p&gt;파이썬에서는 pip 패키지인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dtw&lt;/code&gt;를 통해서 별도의 구현없이 DTW알고리즘을 쉽게 이용할 수 있습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;https://pypi.org/project/dtw/ &lt;br /&gt;&lt;br /&gt;
&lt;b&gt;github description&lt;/b&gt; : https://github.com/pierre-rouanet/dtw&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;패키지를 설치한 후 아래와 같이 사용할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dtw&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtw&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;euclidean_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc_cost_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclidean_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc_cost_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lower'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'gray'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interpolation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nearest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig3.png&quot; width=&quot;150&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;cost matrix와 최적 path는 위 이미지에 표시된것과 같고, 이를 다시 시계열 차트에서 비교하면 아래와 같습니다. dtw를 통해 warping된 시계열데이터1과 시계열데이터2의 상관계수를 구한 결과, 약 0.92로 단순 선형 보간에 의한 상관계수 0.85보다 더 높은 값이 계산되는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Comparison : ts1_dtw vs. ts2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Time series 1 - Warping'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Time series 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrcoef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts1_dtw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ts2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#### output
# array([[ 1.        ,  0.92247328],
#        [ 0.92247328,  1.        ]])
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-05-01/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;긴 글을 읽어주셔서 감사합니다.&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://jsideas.net/bitcoin_dtw/&quot;&gt;jsideas’s blog - Dynamic Time Warping: BitCoin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://en.wikipedia.org/wiki/Dynamic_time_warping&quot;&gt;wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://github.com/pierre-rouanet/dtw&quot;&gt;DTW (Dynamic Time Warping) python module&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Time-series" /><summary type="html">두 시계열 데이터간의 유사도를 어떻게 계산할 수 있을까? 두 시계열이 동일한 길이의 시퀀스라면 단순히 상관계수를 구하는 것이 가능하지만, 현실 세계의 시계열 데이터는 그렇지 않은 경우가 많습니다. 예를 들어 아래와 같은 두 시계열 데이터를 살펴보겠습니다.</summary></entry><entry><title type="html">Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding</title><link href="http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding/" rel="alternate" type="text/html" title="Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding" /><published>2019-03-15T00:00:00+09:00</published><updated>2019-03-15T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/time-series/Nonparametric-Dynamic-Thresholding/">&lt;p&gt;&lt;b&gt;Kyle Hundman et al (2018 KDD, NASA)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Implementation : &lt;a href=&quot;https://github.com/khundman/telemanom&quot;&gt;https://github.com/khundman/telemanom&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;NASA의 우주선은 많은 양의 원격 데이터를 송신합니다. NASA 연구원들은 우주선이 보내는 데이터들을 이용해 엔지니어의 모니터링 부담과 운영 비용을 줄이기 위해서 어노말리 디텍션 시스템을 구축/개선하고 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문은 우주선 데이터에 적용가능한 어노말리 디텍션 알고리즘을 제안합니다. expert-labeled 어노말리 데이터가 포함된 Soil Moiture Active Passive(SMAP) satelite와 Mars Science Laboratory(MSL) rover 데이터에 LSTM 모델을 적용한 새로운 어노말리 디텍션 방법을 제안하였습니다.&lt;/li&gt;
  &lt;li&gt;이 방식은 지도학습에 의한 모델 학습이 아니라 unsupervised and nonparametric anomaly thresholding approach에 해당하며, 후반부에는 false positive를 줄이기 위한 방법들을 추가적으로 논의하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;우주선에서는 온도, 방사선, 전력, 소프트웨어의 계산량 등 복잡하고 방대한 양의 데이터들이 수집되며 각 데이터들의 어노말리 디텍션은 매우 중요한 문제입니다.&lt;/li&gt;
  &lt;li&gt;기존의 어노말리 디텍션 방법들은 사전에 정의된 제한값을 벗어나면 발생하는 알람 형식이거나 수작업이 포함된 시각화 방법과 채널별 통계 분석을 이용합니다. 이러한 방식은 적지않은 전문가적 지식을 요구하며 각 규칙을 정의하거나 노말 범위를 업데이트하는데 수기 작업이 필요합니다. 특히 하루에 85테라바이트의 데이터가 생성되는 방대한 양의 데이터를 처리하는 빅데이터 시스템에서는 더욱 문제가 악화됩니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;다변량 시계열 데이터의 어려운 이슈이 우주선 데이터를 분석하는데 여전히 유효하고, 라벨링 부족한 상황에서 비지도학습방식이나 세미지도학습방법의 필요성 역시 존재합니다. 또한 대부분의 실제 시계열 데이터가 그러하듯이 non-stationary한 특징과 현재 컨텍스에 매우 종속된 특징을 갖는 것들도 어려운 점입니다. 또한 엔지니어에게 인사이트를 줄수 있도록 interpretability도 필요한 요소입니다. 마지막으로 false positive와 false negative를 최소화하면서 적절한 발런스를 찾는 것 역시 중요합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt; Contributions &lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;이 논문은 LSTM을 이용하여 높은 예측력을 얻고, 각 채널별 예측모델을 구축하여 전체 시스템의 interpretability를 유지하였습니다.&lt;/li&gt;
      &lt;li&gt;일단 모델의 예측값을 이용해 실제 값과의 오차(residual)을 이용해 어노말리인지 판단하게 됩니다. 이때 nonparametric, dynamic, and unsupervised thresholding approach를 사용합니다. 이 방식을 이용해 신호의 다양성, 비정상성과 노이즈에 대해서 논의하고 이후 사용자 피드백과 과거 데이터를 이용해 시스템을 향상시키는 방법도 함께 논의하였습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;background-and-related-work&quot;&gt;Background and Related Work&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;일반적으로 3가지 종류의 어노말리가 존재합니다.
    &lt;ul&gt;
      &lt;li&gt;point anomaly : low density regions에 해당하는 싱글 포인트가 발생하는 것을 의미합니다.&lt;/li&gt;
      &lt;li&gt;contextual anomaly : low density region은 아니지만 로컬 값들과 비교했을때는 비정상적인 싱글 포인트가 발생하는 경우입니다.&lt;/li&gt;
      &lt;li&gt;collective anomaly : 여러개의 시퀀스값들이 비정상적일 때를 의미합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;가장 기본적인 어노말리 디텍션은 out-of-limit(OOL)입니다.
    &lt;ul&gt;
      &lt;li&gt;그 외 clustering based approaches, nearest neighbors approaches, expert systems, dimensionality reduction approaches 등이 있지만, parameter specification, interpretability, generalizability, or computational expense 등의 단점이 존재합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;기존에도 우주선에 적용가능한 어노말리 디텍션 방법들이 다수 연구되었습니다. ISACS-DOC, IMSE, ELMER, Deep Space One spacecrash 등과 같은 프로젝트들이 있었습니다만, 여전히 직관적인 결과를 얻을수 있고 관리가 쉬운 OOL 방식이 사용되고 있습니다.&lt;/li&gt;
  &lt;li&gt;최근 딥러닝이 발전하면서 seq-to-seq 학습에서도 큰 성과를 얻고 있습니다. LSTM과 RNN계열의 모델을 이용해 과거값을 이용해 예측값을 학습할수 있습니다. 정상데이터로 학습된 LSTM을 이용하여 정상적인 상태에서의 시스템을 모니터링할수 있습니다. LSTM은 차원축소를 하지 않아도 다변량 시계열 데이터에 적용가능하고, 특별한 도메인 날리지를 요구하지 않기 때문에 다른 우주선에 일반적으로 적용가능합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;

&lt;h3 id=&quot;telemetry-value-prediction-with-lstms&quot;&gt;Telemetry Value Prediction with LSTMs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;single channel models&lt;/b&gt; : 여기서는 각 채널별로 모델을 생성합니다. 싱글 모델의 장점은
    &lt;ul&gt;
      &lt;li&gt;채널 레벨로 추정가능하다는 것&lt;/li&gt;
      &lt;li&gt;로우 레벨의 어노말리를 그룹핑하여 서브시스템 형태로 통합할수 있습니다. 이로인해서 더 세분화된 시스템 관리가 가능합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt;predicting values for a channel &lt;/b&gt;: 주어진 시계열은 \(X=\left\{ x^{(1)}, x^{(2)}, ..., x^{(n)} \right\}\) 이고, \(x^{(t)}\)는 m차원의 벡터를 나타내고 각 element가 채널의 입력값을 나타냅니다.  \(l_s\)는 모델 입력으로 사용한 시퀀스의 길이를 의미합니다. \(l_p\)는 예측할 시퀀스의 길이를 나타내며 이 논문에서는 계산 속도를 위해서 1을 사용하였습니다. 또한 각 채널별 예측을 수행하기 때문에 예측값의 차원 d=1로 설정하였습니다. \(x^{(t)}\) 는 각 채널의 이전 값과 함께 우주선에 전송된 encoded command information이 포함됩니다. 커멘드를 생성한 것과 커멘드를 수신한 정보가 one-hot encoded되어 입력으로 사용됩니다. (Fig3 참고)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamic-error-thresholds&quot;&gt;Dynamic Error Thresholds&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;수천개의 원격 데이터를 자동으로 모니터링하기 위해서는 계산속도가 빠르고, 예측값이 어노말리인지 판단하는 과정이 비지도 학습방식이어야합니다. 이를 위한 일방적인 방식은 과거의 스무딩된 에러들을 가우시안 분포로 가정하여 새로운 에러값과 이전 값들의 compact representation간의 빠른 비교가 되도록 하는 것입니다. 하지만 이 방식은 가우시안 분포라는 가정이 맞지 않을때는 문제가 되기때문에 여기서는 어떠한 가정없이 extreme values를 찾아내는 방식을 제안합니다. distance-based method가 비슷하지만 기존의 distance based method는 각 포인트들을 인근의 k개와 비교하기 때문에 계산량이 많다는 단점이 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Errors and Smoothing&lt;/b&gt; : 우선 예측값과 실제값 사이의 에러를 계산합니다.&lt;/li&gt;
&lt;/ul&gt;

\[e^{(t)} = \left\vert y^{(t)} - \hat{y}^{(t)} \right\vert \\
\boldsymbol{e}=[e^{(t-h)}, ..,e^{(t-1)}, e^{(t)}]\]

&lt;ul&gt;
  &lt;li&gt;이때 각 에러값들은 스무딩(smoothed)된 값들을 사용합니다. 정상적인 상태라도 값이 급변하여 완벽하게 예측이 되지 않아 스파이크 형태의 에러값이 생기는 경우가 종종 있기 때문입니다. 여기서는 Exponentially-weighted average(EWMA)를 사용하였습니다.&lt;/li&gt;
&lt;/ul&gt;

\[\boldsymbol{e_s}=[e_s^{(t-h)}, ..,e_s^{(t-1)}, e_s^{(t)}]\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;값들이 정상인지 판단하기 위해서는 threshold를 설정하여 사용하였습니다. threshold보다 큰 값은 anomalies로 분류됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;Threshold Calculation and Anomaly Scoring &lt;/b&gt; : 일반적으로 threshold를 결정하기 위해서 지도학습방식으로 학습을 합니다. 하지만 이 방식은 라벨링된 데이터가 필요하기 때문에 여기서는 비지도학습 형태로 threshold를 결정하는 방법을 제안하였습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\boldsymbol{\epsilon} = \mu(\boldsymbol{e_s}) + z\sigma(\boldsymbol{e_s})\]

&lt;ul&gt;
  &lt;li&gt;Where \(\epsilon\) is determined by:&lt;/li&gt;
&lt;/ul&gt;

\[\epsilon = argmax(\boldsymbol{\epsilon}) = \frac{\triangle\mu(\boldsymbol{e_s})/\mu(\boldsymbol{e_s}) + \triangle\sigma(\boldsymbol{e_s})/\sigma(\boldsymbol{e_s})}{\left\vert \boldsymbol{e_a} \right\vert + \left\vert \boldsymbol{E_{seq}} \right\vert^2}\]

&lt;ul&gt;
  &lt;li&gt;such that:&lt;/li&gt;
&lt;/ul&gt;

\[\triangle\mu(\boldsymbol{e_s}) = \mu(\boldsymbol{e_s}) - \mu(\left\{ e_s \in \boldsymbol{e_s} \vert e_s \lt \epsilon \right\}) \\
\triangle\sigma(\boldsymbol{e_s}) = \sigma(\boldsymbol{e_s}) - \sigma(\left\{ e_s \in \boldsymbol{e_s} \vert e_s \lt \epsilon \right\}) \\
\boldsymbol{e_a} = \left\{ e_s \in \boldsymbol{e_s} \vert e_s \gt \epsilon \right\} \\
\boldsymbol{E_{seq}} = \mbox{continuous sequences of }e_a \in \boldsymbol{e_a}\]

&lt;ul&gt;
  &lt;li&gt;anomaly score&lt;/li&gt;
&lt;/ul&gt;

\[s^{(i)} = \frac{max(e^{(i)}_{seq})-argmax({\epsilon})}{\mu(\boldsymbol{e_s}) + \sigma( \boldsymbol{e_s})}\]

&lt;h3 id=&quot;mitigating-false-positives&quot;&gt;Mitigating False Positives&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;b&gt;Pruning Anomalies&lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;prediction-based 방식은 과거데이터의 갯수(h)에 영향을 많이 받습니다.&lt;/li&gt;
      &lt;li&gt;너무 많은 과거 데이터를 이용할 경우, 실시간 모니터링 시나리오에서 계산 비용이 너무 크게 됩니다. 너무 적은 과거 데이터를 이용할 경우, 좁은 컨텍스트만 고려하여 판단하기 때문에 false positive가 많아지게 됩니다. 그렇다고 false positive를 너무 줄이다보면 감지되지 못한 어노말리를 찾기위해서 휴먼 인스펙션 부담이 커지게 됩니다. 따라서 false positives를 약화시키기 위해서 pruning procedure를 도입하였습니다.&lt;/li&gt;
      &lt;li&gt;\(\boldsymbol{e_{max}}\) is created containing \(max(\boldsymbol{e_{seq}})\) for all \(\boldsymbol{e_{seq}}\) sorted in descending order. we also add the maximum smoothed error that isn’t anomalous, \(max(\left\{ e_s \in \boldsymbol{e_s} \in \boldsymbol{E_{seq}} \vert e_s \ni \boldsymbol{e_a} \right\} )\), to the end of \(\boldsymbol{e_{max}}\).&lt;/li&gt;
      &lt;li&gt;The sequence is then stepped through incrementally and the the percent decrease \(d^{(i)} = ( e_{max}^{(i-1)} - e_{max}^{(i)}) / e_{max}^{(i-1)}\) at each step \(i\) is calculated where \(i \in \left\{1, 2, ..., (\left\vert \boldsymbol{E_{seq}} \right\vert + 1)\right\}\).&lt;/li&gt;
      &lt;li&gt;If at some step \(i\) a minimum percentage decrease p is exceeded by \(d^{(i)}\), all \(e_{max}^{(j)} \in \boldsymbol{e_{max}} \vert j \lt i\) and their corresponding anomaly sequences remain anomalies.&lt;/li&gt;
      &lt;li&gt;If the minimum decrease p in not met by \(d^{(i)}\) and for all subsequent errors \(d^{(i)}, d^{(i+1)}, ..., d^{(i+\left\vert \boldsymbol{E_{seq}} \right\vert + 1)}\) those smoothed error sequences are reclassified as nominal.&lt;/li&gt;
      &lt;li&gt;이와 같은 pruning 과정은 정상적인 흐름에서의 노이즈가 어노말리로 판단되는 것을 방지합니다. 또한 단순히 값과 값을 여러번 비교하여 판단하는 것보다 잠재가능성이 있는 비정상적인 시퀀스 중에 맥시멈 에러갓을 비교하는 것이 더 효율적이라는 장점이 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Learning from History&lt;/b&gt;
    &lt;ul&gt;
      &lt;li&gt;false postive를 감소시키는 두번째 전략은 적은양이더라도 과거의 비정상 값들 또는 라벨링된 데이터를 적용시키는 것입니다. 각 채널 데이터에서 일정 비율 이상 수집된 값들을 어노말리로 판단하여 미니멈 값 \(s_{min}\)로 설정합니다. 이후 새로운 값들 중 \(s \lt s_{min}\)조건을 만족하는 경우 정상값으로 분류합니다.  \(s_{min}\)는 precision과 recall사이의 적절한 밸러스가 되도록 설정할수 있습니다.&lt;/li&gt;
      &lt;li&gt;또는 유저가 제공하는 라벨링 정보를 이용하여 \(s_{min}\)를 설정할수도 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-03-15/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Deep Learning paper" /><category term="Time-series" /><summary type="html">Kyle Hundman et al (2018 KDD, NASA)</summary></entry><entry><title type="html">RobustSTL : A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series</title><link href="http://localhost:4000/deep%20learning%20paper/time-series/robustSTL/" rel="alternate" type="text/html" title="RobustSTL : A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series" /><published>2019-02-24T00:00:00+09:00</published><updated>2019-02-24T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/time-series/robustSTL</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/time-series/robustSTL/">&lt;p&gt;&lt;b&gt;Qingsong Wen et al (2018, Alibaba Group)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Implementation : &lt;a href=&quot;https://github.com/LeeDoYup/RobustSTL&quot;&gt;https://github.com/LeeDoYup/RobustSTL&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;시계열데이터를 trend, seasonality, and remainder components로 분해하는 것은 어노말리 디텍션이나 예측 모델을 만드는데 중요한 역할을 합니다.&lt;/li&gt;
  &lt;li&gt;기존의 여러가지 성분분해 방식들은
    &lt;ul&gt;
      &lt;li&gt;1) 주기성이 변하거나 이동하는 것, 트렌드나 나머지성분의 갑작스러운 변화를 잘 처리하지 못하며(seasonality fluctuation and shift, and abrupt change in trend and reminder)&lt;/li&gt;
      &lt;li&gt;2) 어노말리 데이터에 대해서 로버스트하지 못하거나&lt;/li&gt;
      &lt;li&gt;3) 주기가 긴 시계열 데이터에 대해서 적용하기 어려운 문제가 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;본 논문에서는 위와 같은 문제점을 해결할 수 있는 새로운 성분 분해 방식을 제안합니다.
    &lt;ul&gt;
      &lt;li&gt;먼저 sparse regularization와 least absolute deviation loss를 이용해 트렌드를 뽑고&lt;/li&gt;
      &lt;li&gt;Non-local seasonal filter를 사용하여 seasonality 성분을 얻습니다.&lt;/li&gt;
      &lt;li&gt;이 과정을 정확한 디컴포지션을 얻을때까지 반복합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;실험데이터와 실제 시계열데이터에 대해서 기존 방법들 대비 더 좋은 성능을 보임을 확인하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;디컴포지션 방법으로 널리 사용되는 방법은 STL(seasonal trend decomposition using Loess), X-13-ARIMA-SEATS, X-11-ARIMA, X-12-ARIMA 등이 있습니다. 하지만 seasonality shift나 fluctuation이 존재할 경우 정확하지 않거나, 빅데이터에 존재하는 long seasonality에는 적합하지 않습니다.
    &lt;ul&gt;
      &lt;li&gt;seasonality fluctuation and shift - 하루가 주기인 시계열 데이터가 있다고 했을때, 오늘 1시에서의 seasonality component는 어제의 12시 30분에 대응되고, 그제의 1시 30분에 대응될수 있음&lt;/li&gt;
      &lt;li&gt;Abrupt change of trend and remainder - local anomaly could be a spike during an idle period (busy day의 높은 값보다는 낮아서 정확히 디텍션하기 어려움&lt;/li&gt;
      &lt;li&gt;Long seasonality - 보통은 quarterly or monthly data임. T 주기의 시즈널리티를 찾기 위해서는 T-1개의 데이터가 필요함. 하루 주기에 1분 간격 데이터의 경우 T=1440개고 이와 같은 long seasonality는 기존 방법들로는 풀기어려움&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이 논문에서 제안한 방법은 Long seasonality period and high noises 더라도 시즈널리티를 비교적 정확하게 디컴포지션할수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;robust-stl-decomposition&quot;&gt;Robust STL Decomposition&lt;/h2&gt;
&lt;h3 id=&quot;model-overview&quot;&gt;Model Overview&lt;/h3&gt;

\[\begin{align}
y_t &amp;amp; = \tau_t + s_t + r_t, &amp;amp; t = 1, 2, …, N \\
r_t &amp;amp; = a_t + n_t \\
\end{align}\]

&lt;p&gt;where \(a_t\) denotes spike or dip, and \(n_t\) denotes the white noise.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;시계열 모델은 트렌드(\(\tau_t\)), 시즈널리티(\(s_t\)), 리마인더(\(r_t\))로 구성되어 있고, 리마인더는 스파크 또는 딥과 같은 어노말리(\(a_t\))와 화이트 노이즈(\(n_t\))로 이루어집니다.&lt;/li&gt;
  &lt;li&gt;제안하는 알고리즘은 크게 4-steps 으로 각 성분을 분해합니다.
    &lt;ul&gt;
      &lt;li&gt;Denoise time series by applying bilateral filtering&lt;/li&gt;
      &lt;li&gt;Extract trend robustly by solving a LAD regression with sparse regularization&lt;/li&gt;
      &lt;li&gt;Calculate the seasonality component by applying a non-local seasonal filtering to overcome seasonality fluctuation and shift&lt;/li&gt;
      &lt;li&gt;Adjust extracted components&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;noise-removal&quot;&gt;Noise Removal&lt;/h3&gt;

\[\begin{align}
y^\prime_t &amp;amp; = \sum_{j \in J} w_j^t y_t, &amp;amp; J = t, t \pm 1, …, t \pm H \\
w_j^t &amp;amp; = \frac{1}{z} e^{-\frac{\left\vert j- t \right\vert ^2}{2\delta_d^2}} e^{-\frac{\left\vert y_j - y_t \right\vert ^2}{2\delta_i^2}}
\end{align}\]

&lt;ul&gt;
  &lt;li&gt;J는 필터의 윈도우를 의미하며, 윈도우 사이즈는 2H+1 입니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;필터의 가중치는 두개의 가우시안 함수로 구성됩니다. bilateral filter는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Bilateral_filter&quot;&gt;여기&lt;/a&gt;를 참고하세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;After denoising,&lt;/li&gt;
&lt;/ul&gt;

\[\begin{align}
y^\prime_t &amp;amp; = \tau_t + s_t + r^\prime_t, &amp;amp; t = 1, 2, …, N \\
r^\prime_t &amp;amp; = a_t + (n_t - \hat{n}_t \\
\end{align}\]

&lt;p&gt;Where the \(\hat{n}_t = y_t - y^\prime_t\) is the filtered noise.&lt;/p&gt;

&lt;h3 id=&quot;trend-extraction&quot;&gt;Trend Extraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;시즈널 디퍼런스 오퍼레이터는 같은 주기의 값을 차분하는 것으로 아래와 같이 정의할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

\[\begin{align}
g_t &amp;amp; = \nabla_T y^\prime_t = y^\prime_t - y^\prime_{t-T} \\
&amp;amp; = \nabla_T \tau_t + \nabla_T s_t + \nabla_T r^\prime_t \\
&amp;amp; = \sum_{I=0}^{T-1} \nabla \tau_{t-i} + ( \nabla_T s_t + \nabla_T r^\prime_t )
\end{align}\]

&lt;ul&gt;
  &lt;li&gt;마지막 줄의 수식에서 첫번째 항이 \(g_t\)에 가장 많은 기여를 합니다. \(s_t\) and \(r^\prime_t\)에 시즈널 디퍼런스 오퍼레이터를 적용하면 값이 매우 작아진다고 가정하기 때문입니다.&lt;/li&gt;
  &lt;li&gt;\(g_t\)에서 트렌드의 first order differece(\(\nabla \tau_t\))를 구하기 위해서 다음과 같은 최적화 식을 사용합니다.&lt;/li&gt;
&lt;/ul&gt;

\[Minimize \ \sum_{t=T+1}^N \left\vert g_t - \sum_{I=0}^{T-1} \nabla \tau_{t-i} \right\vert + \lambda_1 \sum_{t=2}^N \left\vert \nabla \tau_t \right\vert + \lambda_2 \sum_{t=3}^N \left\vert \nabla^2 \tau_t \right\vert\]

&lt;ul&gt;
  &lt;li&gt;첫번째 항은 LAD를 사용한 emprical error를 의미합니다. sum-of-squares 보다 아웃라이어에 대해서 더 로버스트하기 때문에 LAD를 사용하였습니다.&lt;/li&gt;
  &lt;li&gt;두번째와 세번째 항은 각 각 트렌드에 대한 first-order 와 second-order difference operator 입니다.&lt;/li&gt;
  &lt;li&gt;두번째 항은 트렌드 디퍼런스 \(\nabla \tau_t\) 가 천천히 변화하지만 종종 갑작스러운 레벨 쉬프트(abrupt level shift)가 있다는 것을 의미합니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;세번째 항은 트렌드가 smooth하고 piecewise linear such that \(\nabla^2 x_t = \nabla(\nabla x_t)) = x_t -2 x_{t-1} + x_{t-2}\) are sparse&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;이를 매트릭스 형태로 표현하면 다음과 같습니다.&lt;/li&gt;
&lt;/ul&gt;

\[\Vert P \nabla \tau - q \Vert _1\]

&lt;p&gt;where the matrix P and vector q are&lt;/p&gt;

\[P = \begin{bmatrix}
M_{(N-T) \times (N-1)} \\
\lambda_1 I_{(N-1) \times (N-1)} \\
\lambda_2 D_{(N-2) \times (N-1)} \\
\end{bmatrix}, 
q = \begin{bmatrix}
g_{(N-T) \times 1} \\
0_{(2N-3) \times 1} \\
\end{bmatrix}\]

&lt;p&gt;M and D are Toeplitz matrix (refer to the paper for details)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;위의 최적화식을 통해서 \(\tau_1\)에 대한 상대적인 트렌드(relative trend, \(\tilde{\tau}_t^r\))를 구할수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

\[\tilde{\tau}_t^r = \tilde{\tau}_t - \tau_1 = 
\begin{cases}
0, &amp;amp; t=1 \\
\sum_{I=2}^t \nabla \tilde{\tau}_i, &amp;amp; t \ge 2
\end{cases}\]

&lt;ul&gt;
  &lt;li&gt;그리고 나서, 디컴포지션 모델은 아래와 같이 업데이트 됩니다. 
\(y_t'' = y_t' - \tilde{\tau}_t^r = s_t + \tau_1 + r_t'' \\
r_t’’ = a_t + (n_t - \hat{n}_t) +  (\tau_t - \tilde{\tau}_t)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;seasonality-extraction&quot;&gt;Seasonality Extraction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;relative trend component를 분리한 후에는, \(y’’_t\)는 시즈널리티로 오염되어 있다고 생각할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;기존의 시즈널리티 분해 방법들은 주기가 \(T\)인 \(s_t\)’를 구하기 위해서는 K개의 연속적인 값 \(y_{t-KT}, y_{t-(K-1)T}, …, y_{t-T}\) 만 고려하였습니다. 하지만, 이 방식은 시즈널리 쉬프트 현상을 설명할수 없다는 단점이 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;여기서는  \(y’’_{t-KT}\)를 중심으로 인접한 값들을 고려합니다.  \(y’’_{t-KT}\)를 계산할때는 그 값을 중심으로 2H+1개의 인접값들 \(y’’_{t-KT-H}, y’’_{t-KT-H+1}, …, y’’_{t-KT}, y’’_{t-KT+1}…, y’’_{t-KT+H}\)를 사용합니다.&lt;/li&gt;
  &lt;li&gt;시즈널 컴포넌트 \(s_t\) 는 아래와 같이 of \(y’’_t\)의 가중합으로 표현됩니다.&lt;/li&gt;
&lt;/ul&gt;

\[\tilde{s}_t = \sum_{(t’, j) \in \Omega} w^t_{(t’,j’)}y’’_j\]

&lt;p&gt;Where the \(w^t_{(t’,j’)}\) and \(\Omega\) are defined as&lt;/p&gt;

\[w^t_{(t’,j’)} = \frac{1}{z}e^{-\frac{\left\vert j- t \right\vert ^2}{2\delta_d^2}} e^{-\frac{\left\vert y’’_j - y’’_{t’} \right\vert ^2}{2\delta_i^2}} \\
\Omega = \{(t’,j) \vert (t’=t-k \times T, j= t’ \pm h )\} \\
k=1, 2, …, K; \ h=0, 1, …, H\]

&lt;ul&gt;
  &lt;li&gt;시즈널티리를 분리한 후에는, 리마이더 시그널은 아래와 같이 표현됩니다. 
\(r’’’_t = y’’_t - \tilde{s}_t = a_t + (n_t - \hat{n}_t) + (\tau_t - \tilde{\tau}_t) + (s_t - \tilde{s}_t)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;final-adjustment&quot;&gt;Final Adjustment&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;시즈널리티 컴포넌트의 합계는 0으로 조정되어야합니다.&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{I=j}^{I=j+T-1}s_i = 0\]

&lt;ul&gt;
  &lt;li&gt;따라서 평균값(트렌드 \(\tau_1\)에 대응되는 값)을 빼줌으로서 시즈널리트를 조정합니다.&lt;/li&gt;
&lt;/ul&gt;

\[\hat{\tau}_1 = \frac{1}{T\lfloor N/T \rfloor} \sum_{t=1}^{T\lfloor N/T \rfloor} \tilde{s}_t \\
\hat{s}_t = \tilde{s}_t - \hat{\tau}_1 \\
\hat{\tau}_t = \tilde{\tau}^r_t + \hat{\tau}_1 \\
\hat{r}_t = y_t - \hat{s}_t + \hat{\tau}_t\]

&lt;ul&gt;
  &lt;li&gt;리마인더 시그널 \(\hat{r}_t\) 가 수렴할 때까지 위 과정을 반복합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/algorithm1.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-24/table2.png&quot; width=&quot;450&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Deep Learning paper" /><category term="Time-series" /><summary type="html">Qingsong Wen et al (2018, Alibaba Group)</summary></entry><entry><title type="html">How does batch normalization help optimization?</title><link href="http://localhost:4000/deep%20learning%20paper/batchnorm/" rel="alternate" type="text/html" title="How does batch normalization help optimization?" /><published>2019-02-12T00:00:00+09:00</published><updated>2019-02-12T00:00:00+09:00</updated><id>http://localhost:4000/deep%20learning%20paper/batchnorm</id><content type="html" xml:base="http://localhost:4000/deep%20learning%20paper/batchnorm/">&lt;p&gt;&lt;b&gt;Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas et al. (2018, MIT) &lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;BatchNorm은 딥러닝의 안정적이고 학습속도를 빠르게 하는데 도움을 주는 기법으로 널리 활용되고 있습니다.&lt;/li&gt;
  &lt;li&gt;하지만 그 활용성에 비해서 왜 BatchNorm이 효과적인지에 대한 실질적인 고찰은 거의 없었으며, 대부분은 internal covariance shift를 줄이는 효과를 줄이기 때문이라고 믿고 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문에서는 internal covariance shift라는 것이 실제로는 BatchNorm과 거의 상관없다는 것을 실험적으로 확인하였습니다. BatchNorm기법이 최적화 함수를 훨씬 smoother하게 만들어주기 때문이라는 것을 이론적, 실험적으로 확인하였으며, 이 영향으로 인해 그래디언트가 더 안정적으로 움직여 빠른 학습이 가능하다는 것을 주장합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;지난 몇년간 딥러닝이 컴퓨터비전, 스피치 인식 등과 같은 풀기어려운 문제를 해결하는데 성공하였으며, 이러한 성공에는 BatchNorm이 큰 기여를 하고 있습니다.&lt;/li&gt;
  &lt;li&gt;BatchNorm의 실용성은 논란의 여기가 없지만, 그러한 효과가 왜 발생하느지에 대한 명확한 이유는 아직 밝혀지지 않았습니다.&lt;/li&gt;
  &lt;li&gt;BatchNorm이 처음 제안되었을 때는 internal covariance shift(ICS)를 최소화하기 위한 방안으로 설명되었지만, 이 연구에서는 ICS와의 연관성을 말해주는 상세한 증거를 찾지 못하였습니다,&lt;/li&gt;
  &lt;li&gt;Constribution
    &lt;ul&gt;
      &lt;li&gt;BatchNorm과 ICS는 아무런 관련이 없다는 것을 설명하며&lt;/li&gt;
      &lt;li&gt;BatchNorm이 효과적인 이유는 최적화 함수를 더 smooth하게 만들어 learning rate가 더 크더라도 안정적인 그래디언트를 보장하여 더 빠른 학습을 가능하게 하기 때문임을 확인하였습니다.&lt;/li&gt;
      &lt;li&gt;이러한 내용을 실험적인 확인 이외에 loss함수와 그 gradient의 Lipschitzness 를 이용해 이론적으로 설명하였습니다.&lt;/li&gt;
      &lt;li&gt;이 고찰을 통해서 BatchNorm과 동일한 효과를 가져오는 다른 기법들이 존재할수 있는 가능성을 제시하였습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;batch-normalization-and-internal-covariance-shift&quot;&gt;Batch normalization and internal covariance shift&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;처음에 Ioffe and Szegedy의 BatchNorm은 모델이 학습될때는 파라미터가 바뀌기때문에 각 레이어의 입력값들의 분포가 달라지는 현상(internal covariate shift)를 줄이기 위해 제안되었습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;BatchNorm이란 각 레이어의 액티베이션값을 평균과 분산을 각 각 0과 1로 정규화시킨 후, 모델의 설명력을 유지하기 위해 다시 scaled and shifted를 해주는 과정으로 이루집니다. 이 과정은 이전 레이어의 non-linearity전에 이루어집니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Does BatchNorm’s performance stem form controlling internal covariate shift?
    &lt;ul&gt;
      &lt;li&gt;BatchNorm 논문에서는 각 레이어의 인풋 분포의 평균과 분산을 제한하는 것이 학습성능에 직접적인 영향을 준다고 주장하였습니다. 이 것을 입증하기 위해 한가지 실험을 수행하였습니다.&lt;/li&gt;
      &lt;li&gt;배치놈 이후에 랜덤한 노이즈를 일부러 주입하여 네트워크를 학습시켜 보았습니다. 노이즈는 평균이 0이 아니고, 분산도 1이 아닌 분포에서 추출하여 각 레이어의 액티베이션에 더해주었습니다. 이 때, 각 스텝마다 노이즈의 분포가 달라지도록 하여 꽤 심한 covariate shift를 만들어보았습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-12/fig2.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fig2는 standard, standard + batchnorm, standard + noisy batchnorm 세가지 네트워크의 학습 성능(좌)을 나타냅니다. 또한 시간에 따른 레이어의 액티베이션의 분포들(우)을 함께 표시하였습니다. 그림에서 볼수 있듯이, 학습데이터셋을 기준으로 batchnorm과 noisy batchnorm의 성능차이는 거의 없는 것을 확인하였습니다. 두가지 모두 standard 보다 높은 성능을 보였습니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;i&gt;Noisy batchnorm의 액티베이션 분포들은 불안정하지만, 학습 성능은 좋다는 실험 결과는 batchnorm의 효과가 레이어의 인풋 분포를 안정시키기 때문이다는 주장을 반박하는 결과입니다.&lt;/i&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Is BatchNorm reducing internal covariate shift?
    &lt;ul&gt;
      &lt;li&gt;그렇다면 더 광의적인 측면의 internal covariate shift가 batchnorm의 높은 학습성능과 직접적으로 연관된 것은 아닐까?&lt;/li&gt;
      &lt;li&gt;네트워크의 각각 레이어는 주어진 인풋에 대해서 리스크 최적화 문제를 푸는 것으로 생각할수 있고, 파라미터가 업데이트될 때마다 인풋을 바꾸고, 결과적으로 최적화 문제 자체를 바꾸게 됩니다. Ioffe and Szegedy는 이 현상을 internal covariate shift라고 불렀고, 각 레이어의 인풋 분포 관점에서 설명하려고 했습니다. 하지만 이 관점은 batchnorm의 성공적인 성능을 설명해주지 못한다는 것을 앞서 실험을 통해 살펴보았습니다.&lt;/li&gt;
      &lt;li&gt;인풋 분포가 아니라 전체 최적화 관점에서 각 레이어의 그래디어트 변화를 살펴보도록 하겠습니다.&lt;/li&gt;
      &lt;li&gt;이를 위해서 어떤 레이어의 전(before)/후(after) 그래디언트 변화를 다음과 같이 정의하도록 하겠습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mbox{We define internal covariate shift(ICS) of activation i at time t  to be the difference } \lVert G_{t, i} - G’_{t, I} \rVert_2  \mbox{ where} \\
G_{t,i} = \nabla_{W_i^{(t)}} \mathcal{L}(W_1^{(t)}, …, W_k^{(t)} ; x^{(t)}, y^{(t)}) \\
G^\prime_{t,i}  = \nabla_{W_i^{(t)}} \mathcal{L}(W_1^{(t+1)}, …, W_{i-1}^{(t+1)}, W_i^{(t)}, W_{i+1}^{(t)}, …, W_k^{(t)} ; x^{(t)}, y^{(t)})\]

&lt;ul&gt;
  &lt;li&gt;\(G_{t, i}\)는 모든 레이어가 동시에 업데이트되는 가정에서의 그래디언트(as is typical)이고, \(G’_{t, I}\)는 i번째 레이어 이전의 레이어들이 새로운 값으로 업데이트된 후의 그래디언트입니다. 따라서 G와 G’의 차이는 i번째 레이어의 인풋이 변함에 따라 그 파라미터(\(W_i\))의 optimization landscape가 얼마나 변화하는지를 나타냅니다.&lt;/li&gt;
  &lt;li&gt;정의된 지표를 internal covariate shift 정도로 사용하고, batchnorm을 사용했을때와 사용하지 않았을때를 비교했습니다. &lt;i&gt;기존의 Batchnorm 논문의 주장대로라면 batchnorm을 사용하는 경우, G와 G’간의 상관관계가 높아지기 때문에 ICS는 낮아져야합니다.&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-12/fig3.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실험결과, BatchNorm을 사용한 네트워크의 ICS가 오히려 증가하는 것으로 나타났습니다. - fig3&lt;/li&gt;
  &lt;li&gt;(Fig3) Standard + batchNorm가 standard 보다 더 빠르게 학습되지만 (첫번째 컬럼, 정확도와 로쓰 차트),  Standard + batchNorm와 standard의 ICS 변화는 거의 비슷하거나, Standard + batchNorm의 ICS가 standard보다 높은 것으로 나타났습니다. (두번째 &amp;amp; 세번째 컬럼)&lt;/li&gt;
  &lt;li&gt;&lt;i&gt;이 실험결과는 batchNorm 사용하더라도 G와 G’가 서로 uncorrelated하다는 것을 의미합니다. 즉 batchnorm을 사용하여 인풋 분포를 조절하는게 internal covariate shift를 줄이지 못한다는 것입니다.&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-does-batchnorm-work&quot;&gt;Why does BatchNorm work?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The smoothing effect of BatchNorm
    &lt;ul&gt;
      &lt;li&gt;그렇다면 왜 BatchNorm이 효과적일까?&lt;/li&gt;
      &lt;li&gt;결론부터 말하면, BatchNorm이 우리가 풀어야할 최적화문제의 landscape를 smooth하게 만들어주기 때문입니다. loss function의 Lipschitzness를 높여줘, 더 효과적인 \(\beta\)-smoothness를 갖도록 합니다. loss가 작은 비율로 변화하면 gradient의 변화량도 작아집니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(\mbox{f is L-Lipschitz, If} \left\vert f(x_1) - f(x_2) \right\vert \le L \lVert x_1 - x_2 \rVert, \mbox{for all} x_1 \ and \ x_2 \\
\mbox{f is } \beta-smooth \mbox{, If its gradients are } \beta-Lipschitz \mbox{i.e, if} \left\vert \nabla f(x_1) - \nabla f(x_2) \right\vert \le \beta \lVert x_1 - x_2 \rVert, \mbox{for all } x_1 \ and \ x_2\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Non-BatchNorm 네트워크의 loss function은 non-convex하고 flat regions 또는 sharp local minima를 갖고 있고 있어 gradient가 갑자기 사라지거나(flat region), 갑자기 폭발하기도(sharp local minima)하죠. 반면 BatchNorm에 의해 smooth된 loss function은 gradient가 이러한 위험에 빠질 가능성이 더 낮아 더 안정적이고 예측가능한 학습을 할수 있게 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Exploration of the optimization landscape
&lt;img src=&quot;/assets/img/2019-02-12/fig4.png&quot; width=&quot;550&quot; /&gt;&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;우선 Loss function의 Lipschitzness를 실험적으로 살펴보았습니다.&lt;/li&gt;
      &lt;li&gt;(Fig4)(a)는 학습시간에 따라 그래디언트에 따라서 움직였을때, loss값이 얼마나 바뀌었는지를 나타냅니다. BatchNorm을 사용한지 않은 바닐라 네트워크에서는 값의 변동폭이 큰 것을 볼수 있습니다. (b)현재 그래디언트 방향과 이전 그래디언트 방향간의 l2 distance를 나타납니다. 마찬가지로 바닐라 네트워크는 그래디언트 간의 거리가 상대적으로 멀고 이는 predictiveness of the gradient가 낮다는 것을 의미합니다. (c)는 effective \(\beta\)-smoothness를 나타냅니다. effective라는 것은 그래디언트 방향으로 움직였을때 그래디언트가 얼마나 바뀌는지를 나타내며, 낮을수록 effective하다고 생각합니다. 이 결과도 앞서와 마찬가지로 BatchNorm을 사용한 경우가 더 effective하다고 나타납니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Is BatchNorm the best (only?) way to smoothen the landscape?
    &lt;ul&gt;
      &lt;li&gt;loss function의 landscape을 smooth하게 만드는 것이 BatchNorm방식이 유일한 것일까?&lt;/li&gt;
      &lt;li&gt;실험을 위해서 여기서는 first momentum(평균)은 batchnorm처럼 고정하고 normalizes를 \(l_p\)-norm으로 normalizes해보았습니다. (이렇게 정규화된 값들은 더이상 가우시안 분포가 아니고 안정적인 분포를 보장하진 않지만, Fig5에서 나타나듯 BatchNorm과 동일한 성능을 보입니다.&lt;/li&gt;
      &lt;li&gt;논문에서는 Appendix 결과들을 통해서 \(l_p\)-normalization 기법들이 covariate shift를 더 많이 일으키지만, Batchnorm과 마찬가지로 standard 네트워크보다 성능이 좋고 landscape의 smoothness를 개선시킨다는 결과를 말해주고 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;theoretical-analysis&quot;&gt;Theoretical Analysis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;TBU&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문에서는 batchnorm의 효과성이 어디에서 오는지 근본적인 원인을 살펴보았습니다.&lt;/li&gt;
  &lt;li&gt;batchnorm은 internal covariate shift와 거의 상관이 없으며, batchnorm이 오히려 internal covariate shift를 증가시키는 것으로 나타났습니다.&lt;/li&gt;
  &lt;li&gt;대신에 batchnorm은 최적화문제의 landscape를 부드럽게 해주는 효과를 가져오고, 이로 인해서 그래디언트가 예측가능하고, 잘 움직이게 합니다. 이로 인해서 하이퍼파라미터에 로버스트하고, 그래디언트가 사라지거나 폭발하는 현상이 줄어들게 됩니다. 또한 이러한 효과는 batchnorm이 유일하지 않고, 다른 노말리제이션방법들도 동일한 결과를 얻을수 있음을 확인하였습니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>yjucho</name></author><category term="Deep Learning paper" /><summary type="html">Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas et al. (2018, MIT)</summary></entry><entry><title type="html">Self-Supervised Generative Adversarial Networks</title><link href="http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan/" rel="alternate" type="text/html" title="Self-Supervised Generative Adversarial Networks" /><published>2019-02-08T00:00:00+09:00</published><updated>2019-02-08T00:00:00+09:00</updated><id>http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan</id><content type="html" xml:base="http://localhost:4000/generative%20adversarial%20network/deep%20learning%20paper/self-supervised-gan/">&lt;p&gt;&lt;b&gt; Ting Chen et al. (Google Brain, 2018)&lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Conditional GAN은 이미지 생성에서 탁월한 성능을 보이지만, 많은 양의 라벨링 데이터를 필요로 한다는 단점이 있습니다.&lt;/li&gt;
  &lt;li&gt;이 논문은 self-supervision learning과 adversarial training 기법을 적용하여 별도의 라벨링 없이도 image representations을 학습하고 좋은 품질의 이미지를 생성할 수 있음을 보였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;GAN의 학습은 고차원의 파라미터 공간에서 non-convex 게임의 내쉬 이퀼리브리움을 찾는 것이기때문에 매우 불안정한다는 단점은 잘 알려져있습니다.&lt;/li&gt;
  &lt;li&gt;학습이 불안정한 현상을 보이는 이유는 generator와 discrimator가 non-stationary environment 에서 학습되기 때문입니다. 특히 discriminator는 fake class의 분포가 계속 변하게 되어 학습에 어려움을 겪습니다. Non-stationary 환경에서는 뉴럴넷은 이전에 학습 정보를 잊어버리고, 만약 discriminator가 이전의 분류 바운더리를 잊어버리면 학습 과정이 불안정(unstable)해지거나 주기적(cyclic)인 현상이 나타납니다.&lt;/li&gt;
  &lt;li&gt;이 현상을 극복하기 위해서 이전 연구들은 주로 conditioning 기법을 사용하였습니다. Supervised information(클래스 라벨)을 이용해 discriminator를 학습시키면 학습이 더 안정되고 catastrophic forgetting같은 현상이 경감됩니다.&lt;/li&gt;
  &lt;li&gt;하지만 기존 방식은 많은 양의 라벨링 데이터가 필요합니다. 또한 라벨링데이터가 있다하더라도 굉장히 sparse하기 때문에 고차원의 추상화된 공간을 모두 커버하기에는 한계가 존재합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Contribution&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이 논문은 라벨링된 데이터 없이 conditioning기법의 장점을 이용하고자 기존 GAN에 self-supervised loss를 더한 Self supervised GAN(SSGAN)을 제안하였습니다.&lt;/li&gt;
  &lt;li&gt;실험을 통해서 self-supervised GAN(SSGAN)이 동일한 실험 조건에서는 unconditional GAN보다 더 좋은 성능을 보임을 확인하였습니다.&lt;/li&gt;
  &lt;li&gt;SSGAN은 향후  high quality, fully unsupervised, natural image synthesis의 새로운 가능성을 제시하였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-key-issue--discriminator-forgetting&quot;&gt;A key Issue : discriminator forgetting&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig2.png&quot; width=&quot;400&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fig2 : 학습이 진행될동안 discriminator의 분류 정확도를 관찰한 결과, unconditional GAN은 500k iterations 이후에는 학습된 정보를 잃어버리고 성능이 낮아지는 현상이 일어났습니다. 반면 SSGAN은 학습이 지속됨에 따라 분류 성능도 점차 향상하는 것을 볼 수 있었습니다. (이미지넷 데이터)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig3.png&quot; width=&quot;450&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fig3 : cifar10 데이터에 대해서 각 클래스마다 1k iterations을 학습시키고 10개 클래스에 대해서 10k iterations이 지나면, 다시 처음 클래스를 학습하는 실험을 하였습니다. (a)는 바닐라 클래시파이어로 10k 이후에도 클래스가 바뀔때마다 학습성능이 떨어졌다가 올라가는 모습이 나타나지만, (b)self-supervised loss가 추가된 클래시파이어는 이전 정보를 잃어버리는 현상이 완화된 것을 볼 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-self-supervised-gan&quot;&gt;The Self-Supervised GAN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig1.png&quot; width=&quot;700&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Fig1 : SSGAN의 구조는 discriminator가 generator의 학습성능과 상관없이 의미있는 representation을 학습하도록 되어있습니다. 이를 위해서 이미지를 회전시킨 후 회전된 각도를 예측하도록 하는 self-supervision task을 사용하였습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;회전각도를 예측하는 것을 포함한 loss function은 다음과 같습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[L_G = -V(G,D) - \alpha \mathbb{E}_{x \sim P_G}  \mathbb{E}_{r \sim R} [log Q_D (R = r \vert x^r )], \\
L_D = V(G,D) - \beta \mathbb{E}_{x \sim P_{data}}  \mathbb{E}_{r \sim R} [log Q_D (R = r \vert x^r )]\]

&lt;ul&gt;
  &lt;li&gt;\(V(G,D)\)은 GAN의 loss function이고, \(r \in R\)은 회전각입니다. 이 논문에서는 \(R={0도, 90도, 180도, 270도}\)을 사용하였습니다. 이미지 x가 r degree만큼 회전한 것을 \(x^r\)이라고 나타냈으며, \(Q(R \vert x^r)\)은 주어진 샘플에 대해서 discriminator의 회전각 예측 분포를 의미합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt; Collaborative Adversarial Training&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;SSGAN에서는 기존 GAN과 마찬가지로 true vs. fake prediction에서는 적대적인 학습을 합니다. 하지만 rotation task에서는 discriminator와 generator가 서로 협력적인 (collaborative) 학습을 하게 됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;먼저 generator가 실제 이미지와 유사하게 이미지를 생성하여 회전시킨 후 discriminator에게 전달하면, discriminator는 회전된 각도를 감지하게 됩니다. 여기서 generator는 조건부 정보(rotation)을 사용하지 않으므로 항상 회전되지 않은 unright 이미지를 생성합니다.&lt;/li&gt;
  &lt;li&gt;discriminator는 실제 데이터에 대해서만 rotation 을 얼마나 정확하게 예측했는지를 기준으로 학습됩니다. 즉 실제 데이터에 대한 rotation loss만 반영하여 파라미터가 업데이트 됩니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;generator는 회전을 쉽게 감지할수 있도록 이미지를 생성하여 discriminator가 회전을 잘 감지할수있도록 도와줍니다. (discriminator는 실제 이미지의 로테이션을 잘 감지하도록 학습되었기때문에)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Fig1은 학습과정의 파이프라인을 나타냅니다.
    &lt;ul&gt;
      &lt;li&gt;discriminator의 목적은 1) non-rotated img에 대해서 true or fake를 잘 맞추는 것 2) rotated real img에 대해서 rotation angle을 잘 찾는 것 입니다.&lt;/li&gt;
      &lt;li&gt;generator의 목적은 실제 데이터와 유사하게 이미지를 생성하는 것인데, discrimator가 실제 데이터의 로테이션을 잘 감지되도록 학습했기때문에 generator도 회전을 쉽게 감지할수 있는 이미지를 생성하게 됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;실험을 통해서 1) self-supervision이 baseline GAN과 비교하여 representation의 품질을 향상시킴 2) 동일한 학습 조건에서 conditional GAN과 비교가능 수준으로 conditional generation을 향상시킴 을 보였습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experimental-settings&quot;&gt;Experimental settings&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;dataset : IMAGENET, CIFAR10, LSUN-BEDROOM, CELEBA-HQ&lt;/li&gt;
  &lt;li&gt;Models :
    &lt;ul&gt;
      &lt;li&gt;baseline models
        &lt;ul&gt;
          &lt;li&gt;unconditional GAN with spectral normalization (Uncond-GAN)&lt;/li&gt;
          &lt;li&gt;conditional GAN using the label-conditioning strategy (Cond-GAN)&lt;/li&gt;
          &lt;li&gt;label-conditional batch normalization in Cond-GAN&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;ResNet architectures for the genertor and discriminator&lt;/li&gt;
      &lt;li&gt;self-modulated batch normalization in SS-GAN(sBN)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig4.png&quot; width=&quot;700&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/fig5.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/tab1.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-02-08/tab2.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Generative Adversarial Network" /><category term="Deep Learning paper" /><summary type="html">Ting Chen et al. (Google Brain, 2018)</summary></entry><entry><title type="html">시계열 분석 part6 - Spectral analysis</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6/" rel="alternate" type="text/html" title="시계열 분석 part6 - Spectral analysis" /><published>2019-01-23T00:00:00+09:00</published><updated>2019-01-23T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part6/">&lt;p&gt;지금까지 우리는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time domain&lt;/code&gt;에서의 여러가지 시계열 모델을 살펴보았습니다. 이번 포스팅은 주어진 시계열 데이터를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;frequency domain&lt;/code&gt;에서 분석하는 방법에 대해서 설명하도록 하겠습니다. 수학적으로 다소 복잡해보이지만, 실제로는 numpy 등을 통해서 쉽게 활용할수 있는 방법입니다. 여기서는 이론적인 내용을 통해서 주파수 도메인에서의 개념을 직관적으로 이해하고, 실제 데이터를 통해서 결과값을 이해하고 활용할 수 있는 것을 목표로 합니다. 주파수 분석은 주어진 시계열 데이터의 주기성을 확인하거나, 노이즈를 제거하는 등에 활용될 수 있습니다.&lt;/p&gt;

&lt;p&gt;What we can do with spectral analysis is&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Frequency detection&lt;/li&gt;
  &lt;li&gt;Noise removal&lt;/li&gt;
  &lt;li&gt;Model detection&lt;/li&gt;
  &lt;li&gt;Lag detection (lagged regression)&lt;/li&gt;
  &lt;li&gt;Feature detection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Time domain에서의 시계열 데이터는 특정 시점의 데이터가 과거 시점의 데이터와 어떤 관계가 있는지를 알아보기 위해서 auto covariance function(ACF)을 이용하였습니다. 먼저, Time domain에서의 ACF가 frequency domain에서의 spectral density \(f\)로 변형될수 있음(interchangeable)을 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;spectral-density&quot;&gt;spectral density&lt;/h2&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Suppose that \(\{X_t\}\) is a zero-mean stationary time series with auto covariance function \(\gamma(\cdot)\) satisfying \(\sum_{h=-\infty}^\infty \left\vert \gamma(h) \right\vert \lt \infty\). The spectral density of \(\{X_t\}\) is the function \(f(\cdot)\) defined by&lt;/p&gt;

\[f(\lambda) = \frac{1}{2\pi} \sum_{h=-\infty}^\infty e^{-ih\lambda} \gamma(h), \ \ \ \ -\infty \lt \lambda \lt \infty\]

&lt;p&gt;where \(e^{ i\lambda} = cos(\lambda) + i sin(\lambda)\) and \(i = \sqrt{-1}\).&lt;/p&gt;

&lt;p&gt;\(\left\vert \gamma(\cdot) \right\vert\)의 summability로 인해 \(f\) 역시 절대적으로 수렴하며, cos와 sin의 주기가 \(2\pi\)이기때문에 \(f\)의 주기도 \(2\pi\)가 됩니다. 또한 앞으로의 수식에서는 \((-\pi, \pi]\) 구간에서의 \(f\)의 값만 고려하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Basic Properties of \(f\)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;(a) \(f\) is even, i.e., \(f(\lambda) = f(-\lambda)\) &lt;br /&gt;
(b) \(f(\lambda) \ge 0\) for all \(\lambda \in (-\pi, \pi]\), &lt;br /&gt;
and &lt;br /&gt;
(c) \(\gamma(k) =\int_{-\pi}^\pi e^{ik\lambda} f(\lambda) d\lambda = \int_{-\pi}^\pi cos(k\lambda) f(\lambda) d\lambda\)&lt;/p&gt;

&lt;p&gt;\(f(\lambda)\)는 대칭성을 가지고 있고, \((-\pi, \pi]\)에서 항상 양수값을 갖습니다. 그리고 spectral density를 (c)와 같이 적분하여 타임 도메인의 auto covariance function으로 변환할 수 있습니다.&lt;/p&gt;

&lt;p&gt;즉, \(\gamma_X\)가 가진 정보와 \(f_X(\lambda)\)가 가진 정보가 완전히 동일합니다. 또한 spectral densities는 essentially unique하기 때문에 \(\gamma(\cdot)\)에 대응되는 Spectral densities \(f\)와 \(g\)가 있다면, 이 둘은 \(f\)와 \(g\)는 서로 동일한 Fourier coefficients를 갖게 되어, 서로 동일한 함수라고 할수 있습니다.&lt;/p&gt;

&lt;p&gt;다음은 우리가 알고 있는 몇개의 stationary time series의 sepectral density를 구하는 예제를 살펴보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;White noise&lt;/b&gt; :
If \(\{X_t\} \sim WN(0, \sigma^2)\), then \(\gamma(0)=\sigma^2\) and \(\gamma(h)=0\) for all \(\left\vert h \right\vert \gt 0\). This process has a flat spectral density&lt;/p&gt;

\[f(\lambda) = \frac{\sigma^2}{2\pi}, \ \ \ \ \ \ -\pi \gt \lambda \gt \pi\]

&lt;p&gt;Each Frequency in the spectrum contributes equally to the variance of the process.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;AR(1)&lt;/b&gt;:
If 
\(X_t = \phi X_{t-1} + Z_t\)
where \(\{Z_t\} \sim WN(0, \sigma^2)\), then \(\{X_t\}\) has spectral density&lt;/p&gt;

\[\begin{align}
f(\lambda) &amp;amp; = \frac{\sigma^2}{2\pi(1-\phi^2)} (1 + \sum_{h=1}^\infty \phi^h (e^{-ih\lambda} + e^{ih\lambda})) \\
&amp;amp; = \frac{\sigma^2}{2\pi(1-\phi^2)} (1 + \frac{\phi e^{i\lambda}}{1- \phi e^{i\lambda}} + \frac{\phi e^{-i\lambda}}{1- \phi e^{-i\lambda}}) \\
&amp;amp; = \frac{\sigma^2}{2\pi} (1 -2\phi cos \lambda + \phi^2)^{-1}
\end{align}\]

&lt;p&gt;&lt;b&gt;MA(1)&lt;/b&gt;:
If 
\(X_t = Z_t + \theta Z_{t-1}\)
where \(\{Z_t\} \sim WN(0, \sigma^2)\), then \(\{X_t\}\) has spectral density&lt;/p&gt;

\[\begin{align}
f(\lambda) &amp;amp; = \frac{\sigma^2}{2\pi} (1 + \theta^2 + \theta(e^{-i\lambda} + e^ {i\lambda})) \\
&amp;amp; = \frac{\sigma^2}{2\pi} (1 + 2\theta cos \lambda + \theta^2)
\end{align}\]

&lt;p&gt;&lt;b&gt;ARMA(p, q)&lt;/b&gt; :
If \(\{X_t\}\) is a causal ARMA(p, q) process satisfying \(\phi(B)X_t = \theta(B)Z_t\), then&lt;/p&gt;

\[f_X(\lambda) = \frac{\sigma^2}{2\pi} \frac{\left\vert \theta(e^{-i\lambda})\right\vert ^2}{\left\vert \phi(e^{-i\lambda})\right\vert ^2}\]

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig1.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;
&lt;small&gt;출처 : &lt;a href=&quot;http://contents.kocw.or.kr/contents4/document/lec/2013/Hanyang/Lee%20Kichun/11.pdf&quot;&gt;Time Series Analysis Lecture Note&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;여기까지 주어진 시계열데이터의 타임 도메인에서의 auto-covariance function이 주파수 도메인의 spectral density function으로 변환가능함을 살펴보았습니다. 앞서 우리는 시계열 데이터의 샘플들로부터 sample ACF를 추정하는 방법을 알아보았습니다. 마찬가지로 주어진 샘플데이터로부터 spectral density function을 추정하는 것은 어떻게 할까요? 이제 시계열 데이터의 spectral density function의 estimate인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;periodogram&lt;/code&gt;에 대해서 알아보도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;periodogram&quot;&gt;Periodogram&lt;/h2&gt;

&lt;p&gt;먼저 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;periodogram&lt;/code&gt;을 설명하기 위해 복소수 벡터 \(x\)를 생각해보도록 하겠습니다.&lt;/p&gt;

\[x = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} \in \mathbb{C^n}\]

&lt;p&gt;여기서 \(\mathbb{C^n}\)는 복소수를 포함한 가능한 모든 컬럼벡터의 집합을 의미합니다. 이제 \(w_k = 2 \pi k/n\)라고 표기하고, 여기서 \(k\) 는  -(n-1)/2와  n/2 사이의 (inclusive) 자연수라고 하겠습니다. 즉,&lt;/p&gt;

\[w_k = \frac{2\pi k}{n},  \ \ \ k = -[\frac{n-1}{2}], \cdots, [\frac{n}{2}],\]

&lt;p&gt;[y]라는 표기는 y보다 작거나 같은 가장 큰 자연수를 나타냅니다.&lt;/p&gt;

&lt;p&gt;\(w_k\)와 같은 값들의 집합 \(F_n\)를 샘플사이즈가 n인 &lt;b&gt;Fourier frequencies&lt;/b&gt; 라고 합니다. 이때, \(F_n\) 는 \((-\pi, \pi]\) 구간의 부분집합으로 표현됩니다.&lt;/p&gt;

&lt;p&gt;마찬가지로 아래와 같은 n개의 벡터를 생각해보도록 하겠습니다.&lt;/p&gt;

\[e_k = \frac{1}{\sqrt{n}} \begin{bmatrix} e^{iw_k} \\ e^{2iw_k} \\ \vdots \\ e^{niw_k}  \end{bmatrix}, \ \ \ \ \  k = -[\frac{n-1}{2}], \cdots, [\frac{n}{2}].\]

&lt;p&gt;여기서 \(e_1, \cdots, e_n\) 는 아래와 같은 관계를 만족시키는 서로 수직(&lt;b&gt;orthonormal&lt;/b&gt;)인 벡터들입니다.&lt;/p&gt;

\[e_j * e_k = \begin{cases}
1, &amp;amp; \mbox{if } j =k  \\
0, &amp;amp; \mbox{if } j \ne k
\end{cases}\]

&lt;p&gt;\(e_j *\)는 \(e_j\)의 k번째 컴포넌트를 복소수 컨주게이트값으로 바꾼 행벡터를 타나냅니다.  row vector whose \(k\)th component is the complex conjugate of the \(k\)th component of \(e_j\).&lt;/p&gt;

&lt;p&gt;이는 곧 \(\{e_1, \cdots, e_n\}\) 가 \(\mathbb{C^n}\) 집합의 basis인 것을 의미하고, 따라서, \(\mathbb{C^n}\) 에 속하는 임의의 벡터 \(x\)는 이 basis의 선형 조합으로 표현될 수 있습니다.&lt;/p&gt;

\[x = \sum_{k = -[\frac{n-1}{2}]}^{[\frac{n}{2}]} a_k e_k  \ \ \ \ \mbox{(eq.1)}\]

&lt;p&gt;이 때, coefficients \(a_k\)는 다음과 같이 구할수 있습니다.&lt;/p&gt;

\[a_k = e_k * x = \frac{1}{\sqrt{n}} \sum_{t=1}^n x_t e^{-itw_k}\]

&lt;p&gt;여기서 {\(a_k\)} 시퀀스를 \(\{x_1, \cdots, x_n\}\)의 &lt;b&gt;discrete Fourier transform&lt;/b&gt; 라고 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The periodogram of \(\{x_1, \cdots, x_n\}\) is the function&lt;/p&gt;

\[I_n(\lambda) = \frac{1}{n} \left\vert \sum_{t=1} ^{n} x_t e^{-it \lambda} \right\vert ^2\]

&lt;p&gt;다음의 proposition은 \(I_n(\lambda)\)가 \(2\pi f(\lambda)\)의 샘플 추정값으로 간주될수 있음을 보입니다. 먼저 sepectral density \(f(\lambda)\)의 정의가 다음과 같다는 것을 상기하도록 합니다.&lt;/p&gt;

\[2\pi f(\lambda) = \sum_{h=-\infty}^\infty \gamma(h)e^{-ih\lambda}, \ \ \ \ \ \lambda \in (-\pi, \pi]
 \ \ \ \ \ \ \ \mbox{(eq.2)}\]

&lt;p&gt;&lt;b&gt;proposition&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;If \(x_1, \cdots, x_n\) are any real numbers and \(w_k\) is any of the nonzero Fourier frequencies \(2\pi k/n\) in \((-\pi, \pi]\), then&lt;/p&gt;

\[I_n(w_k) = \sum_{\left\vert h \right\vert \lt n} \hat{\gamma}(h)e^{-ihw_k},  \ \ \ \ \ \ \ \mbox{(eq.3)}\]

&lt;p&gt;where \(\hat{\gamma}(h)\) is the sample ACVF of \(x_1, \cdots, x_n\).&lt;/p&gt;

&lt;p&gt;(eq.2)와 (eq.3)을 비교하면 두 식이 비슷한 것을 볼수 있고, 자연스럽게 \(I_n(w_k)\)이 \(f(\lambda)\)의 estimator로 사용할 수 있다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;이제 실제 시계열 데이터에서 spectral analysis를 수행해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 북창원의 기상 데이터(온도)&lt;/li&gt;
  &lt;li&gt;기간 : 2018-11-01 ~ 2018-12-1 (1개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;먼저 Fourier transform통해서 데이터의 주기를 파악해보도록 하겠습니다. Discrete Fourier transform는 numpy 패키지를 통해 쉽게 이용할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'지점'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'stn'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'일시'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'기온(°C)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'temp'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'풍속(m/s)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ws'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'풍향(16방위)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'wd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;'습도(%)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hm'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'%Y-%m-%d %H:%M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'dataTime'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;## 온도 데이터
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;### fft 수행 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fftfreq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;### 주파수 시퀀스
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'frequency(Hz)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'amplitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig2.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;주파수 도메인으로 변환된 그래프를 살펴보면 2개의 peak가 있는 것을 볼 수 있습니다. 해당 주파수 대역을 좀더 확대해서 보면 다음과 같이 약 0.041 과 0.083 에서 peak가 발생한 것으로 보입니다. 따라서 주어진 온도 데이터는 주파수가 0.041인 시그널1과 주파수가 0.083인 시그널2의 합쳐진 것으로 생각할 수 있습니다.&lt;/p&gt;

&lt;p&gt;주기 = 1/주파수 이기때문에 주어진 온도 데이터의 주기는 1/0.041 = 24로 구해집니다. 해당 데이터의 시간 단위가 1시간이고 주기가 24라는 것을 통해 온도 데이터가 24시간의 주기를 가지고 있다는 사실을 확인할 수 있습니다. 하루동안의 온도 패턴이 반복적인 것을 생각하면 매우 직관적인 결과입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig3.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이제 주파수 값들에서 노이즈에 해당하는 값들을 0으로 바꾼 후 다시 타임 도메인으로 변경해보도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;## fourier[60]과 fourier[120]의 값을 제외하고 모두 0으로 변경
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;61&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;121&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## inverse fourier transform 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;denoise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;denoise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fourier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'frequency(Hz)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'amplitude'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-23/fig4.png&quot; width=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;디노이즈 작업은 주파수 도메인에서 강한 값으로 보인 부분(fourier[60]과 fourier[120])을 제외한 나머지 값들은 모두 0으로 변경하는 방식을 사용하였습니다. 그 후 다시 타임 도에인으로 바꿔 시그널의 패턴을 확인하였습니다. 변환된 시계열 데이터는 24시간을 주기로 매우 반복적인 패턴을 보이는 시그널로 변경된 것을 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;위와 같은 주파수 도메인에서의 분석은 음향이나 설비의 진동 등의 신호처리에 많이 사용되고 있으니 알아두시면 매우 유용할 것같습니다.&lt;/p&gt;

&lt;p&gt;그동안 시계열 분석 포스팅을 읽어주셔서 감사합니다. 시계열 분석 포스팅은 이 포스팅을 마지막으로 마무리짓고자 합니다.
이후에는 딥러닝 논문 리뷰, 모델 구현 등의 포스팅으로 찾아뵙도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;앞으로도 같이 즐겁고 재미나게 공부합시다!&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.fft.html#module-numpy.fft&quot;&gt;numpy - Discrete Fourier Transform&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Spatio-Temporal Data" /><category term="Time-series" /><summary type="html">지금까지 우리는 time domain에서의 여러가지 시계열 모델을 살펴보았습니다. 이번 포스팅은 주어진 시계열 데이터를 frequency domain에서 분석하는 방법에 대해서 설명하도록 하겠습니다. 수학적으로 다소 복잡해보이지만, 실제로는 numpy 등을 통해서 쉽게 활용할수 있는 방법입니다. 여기서는 이론적인 내용을 통해서 주파수 도메인에서의 개념을 직관적으로 이해하고, 실제 데이터를 통해서 결과값을 이해하고 활용할 수 있는 것을 목표로 합니다. 주파수 분석은 주어진 시계열 데이터의 주기성을 확인하거나, 노이즈를 제거하는 등에 활용될 수 있습니다.</summary></entry><entry><title type="html">django - AWS 배포하기</title><link href="http://localhost:4000/django/django-deploy-aws/" rel="alternate" type="text/html" title="django - AWS 배포하기" /><published>2019-01-17T00:00:00+09:00</published><updated>2019-01-17T00:00:00+09:00</updated><id>http://localhost:4000/django/django-deploy-aws</id><content type="html" xml:base="http://localhost:4000/django/django-deploy-aws/">&lt;p&gt;django application을 Amazon Web Service(AWS)에 배포하는 과정을 요약한 포스팅입니다. &lt;a href=&quot;https://nachwon.github.io/django-deploy-1-aws/&quot;&gt;이 블로그&lt;/a&gt;를 주로 참고하였고, 수행 중 발생하는 문제에 대한 trouble shooting 과정을 기억하기 위해 작성하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;aws-가입-후-ec2-서버-셋팅&quot;&gt;AWS 가입 후 EC2 서버 셋팅&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;계정 가입 후 콘솔 로그인
    &lt;ul&gt;
      &lt;li&gt;서비스 검색에 IAM(Identity and Access Management)&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/1.png&quot; width=&quot;400&quot; /&gt;
&lt;img src=&quot;/assets/img/2019-01-17/2.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;사용자 탭에 사용자 추가
    &lt;ul&gt;
      &lt;li&gt;엑세스 유형 : 프로그래밍 방식 액세스&lt;/li&gt;
      &lt;li&gt;기존 정책 직접 연결 : AmazonEC2FullAccess&lt;/li&gt;
      &lt;li&gt;완료 창의 Access key ID 와 Secret access key는 꼭 저장해두어야 합니다. “download.csv”를 눌러 저장합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;EC2 서비스로 이동&lt;/li&gt;
  &lt;li&gt;키페어 생성 - pem 파일 다운로드
    &lt;ul&gt;
      &lt;li&gt;다운로드한 pem 파일은 ~/.ssh 폴더에 보관합니다.&lt;/li&gt;
      &lt;li&gt;chmod 400 pem파일 로 권한을 변경합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;인스턴스 생성
    &lt;ul&gt;
      &lt;li&gt;Ubuntu Server 16.04&lt;/li&gt;
      &lt;li&gt;보안 그룹 이름 및 설명 입력&lt;/li&gt;
      &lt;li&gt;검토 후 시작 클릭 후 생성한 키페어 선택합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;생성된 인스턴스에 sss 접속
    &lt;ul&gt;
      &lt;li&gt;ssh -i 키페어경로 유저명@EC2퍼블릭DNS주소&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;서버 환경 설정
    &lt;ul&gt;
      &lt;li&gt;locale 설정&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vi /etc/default/locale

LC_CTYPE=&quot;en_US.UTF-8&quot;
LC_ALL=&quot;en_US.UTF-8&quot;
LANG=&quot;en_US.UTF-8&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get dist-upgrade
sudo apt-get install python-pip
sudo apt-get install zsh
sudo curl -L http://install.ohmyz.sh | sh
sudo chsh ubuntu -s /usr/bin/zsh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;pyenv 설치
    &lt;ul&gt;
      &lt;li&gt;먼저 Ubuntu에서 Build 할 때 공통적으로 발생하는 문제를 방지하기 위해 필요한 패키지들을 설치해준다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev \
libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev \
xz-utils tk-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;git clone 후 설치해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git clone https://github.com/pyenv/pyenv.git ~/.pyenv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;~/.zshrc 의 pyenv 환경변수 설정을 해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export PATH=&quot;/home/ubuntu/.pyenv/bin:$PATH&quot;
eval &quot;$(pyenv init -)&quot;
eval &quot;$(pyenv virtualenv-init -)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Python 설치
    &lt;ul&gt;
      &lt;li&gt;pyenv를 통해서 Python을 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv install 3.6.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;Pillow를 위한 Python 라이브러리 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install python-dev python-setuptools
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;scp를 사용하여 django 프로젝트 파일 업로드하기
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   scp -i 키페어경로 -r 보낼폴더경로 유저명@퍼블릭DNS:받을폴더경로
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;서버에서 Python 가상환경 설치하기
    &lt;ul&gt;
      &lt;li&gt;AWS 서버에 로컬 서버에서 생성했던 pyenv 가상환경 이름과 동일한 이름으로 가상환경을 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pyenv virtualenv 3.6.7 mysite
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;다음의 명령어를 입력하여 requirements.txt 에 기재되어있는 패키지들을 설치해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;만약 pip 버전이 최신버전이 아니라는 에러가 날 경우 아래 명령어를 입력해준 다음 다시 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   pip install --upgrade pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;보안 그룹에 포트 추가하기
    &lt;ul&gt;
      &lt;li&gt;EC2 관리 화면으로 접속한 뒤, 보안 그룹 화면으로 이동합니다.&lt;/li&gt;
      &lt;li&gt;보안 그룹 목록에서 생성한 보안 그룹을 체크하고 인바운드 탭의 편집 버튼을 누릅니다.&lt;/li&gt;
      &lt;li&gt;규칙 추가 버튼을 누른 다음, 포트 범위에 8080 을 입력하고 저장을 누릅니다. &lt;br /&gt;
   &lt;img src=&quot;/assets/img/2019-01-17/3.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;runserver 실행하기
    &lt;ul&gt;
      &lt;li&gt;srv 폴더안의 프로젝트 폴더로 이동하여 runserver 를 포트 8080에 실행합니다.&lt;br /&gt;
   ./manage.py runserver 0:8080&lt;/li&gt;
      &lt;li&gt;위의 모든 과정이 올바르게 수행되었다면 django application 화면이 보일 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;wsgi와-nginx&quot;&gt;WSGI와 NGINX&lt;/h2&gt;

&lt;p&gt;웹 서버 게이트웨이 인터페이스(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WSGI&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Web Server Gateway Interface&lt;/code&gt;)는 웹서버와 웹 애플리케이션의 인터페이스를 위한 파이선 프레임워크입니다. runserver 는 개발용이므로 실제 서비스를 운영하는데 부적합하기 때문에 실제로 어플리케이션을 서비스할 때는 웹서버를 사용하게 됩니다. 또한 웹서버가 직접적으로 Python으로 된 장고와 통신할 수 없기 때문에 그 사이에서 WSGI Server(middleware) 가 실행되어 웹서버와 장고를 연결해주는 역할을 합니다.  웹서버가 전달받은 사용자의 요청을 WSGI Server에서 처리하여 Django로 넘겨주고, 다시 Django가 넘겨준 응답을 WSGI Server가 받아서 웹서버에 전달하게 됩니다. WSGI Server에는 여러 가지 종류가 있는데, 그 중 기능이 강력하고 확장성이 뛰어난 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;uWSGI&lt;/code&gt; 를 사용하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;웹 서버(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Web Server&lt;/code&gt;)는 HTTP를 통해 웹 브라우저에서 요청하는 HTML 문서나 오브젝트(이미지 파일 등)을 전송해주는 서비스 프로그램을 말합니다. 웹 서버의 주된 기능은 웹 페이지를 클라이언트로 전달하는 것입니다. 주로 그림, CSS, 자바스크립트를 포함한 HTML 문서가 클라이언트로 전달됩니다. 주된 기능은 콘텐츠를 제공하는 것이지만 클라이언트로부터 콘텐츠를 전달 받는 것도 웹 서버의 기능에 속하고, 클라이언트에서 제출한 웹 폼을 수신하는 것이 그 예에 해당합니다. 여기서는 성능에 중점을 둔 차세대 웹 서버 소프트웨어인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Nginx&lt;/code&gt;를 사용하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-2-wsgi/&quot;&gt;referece&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;uWSGI 설치
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh&lt;/code&gt;로 접속 후 배포에 사용할 유저 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 를 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo adduser deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;uWSGI를 설치할 별도의 python 가상환경을 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv virtualenv 3.6.7 uwsgi-env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이 가상환경을 지금 현재의 가상 컴퓨터 셸에만 일시적으로 적용하도록 설정해줍니다. 서버 전체에서 하나의 uwsgi를 사용하게 하기 위함입니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv shell uwsgi-env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이제 가상환경에 uwsgi 를 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;uWSGI로 서버 열어보기
    &lt;ul&gt;
      &lt;li&gt;uWSGI를 실행하려면 pyenv shell uwsgi-env 를 입력해 uwsgi-env를 적용한 다음, 아래와 같이 입력합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi \
--http :[포트번호] \
--home [virtualenv 경로] \
--chdir [장고프로젝트폴더 경로] \
-w [wsgi 모듈명].wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;uwsgi \
--http :8080 \
--home /home/ubuntu/.pyenv/versions/mysite \
--chdir /srv/air-pollution/mysite \
-w  mysite.wsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ini 파일로 uWSGI 실행하기
    &lt;ul&gt;
      &lt;li&gt;매번 uWSGI를 실행할 때마다 위의 복잡한 명령을 입력하기 번거로우므로, 미리 옵션을 파일로 만들어 저장해놓고 실행할 수 있습니다.&lt;/li&gt;
      &lt;li&gt;로컬에서 장고 프로젝트 폴더에 .config 라는 폴더를 하나 새로 생성하고 그 안에 다시 uwsgi 폴더를 생성하고, uwsgi 폴더 안에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; 파일을 만들어 줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   └── uwsgi
│       ├── mysite.ini
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; :&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[uwsgi]
chdir = /srv/air-pollution/mysite
module = mysite.wsgi:application
home = /home/ubuntu/.pyenv/versions/mysite

uid = deploy
gid = deploy

http = :8080

enable-threads = true
master = true
vacuum = true
pidfile = /tmp/mysite.pid
logto = /var/log/uwsgi/mysite/@(exec://date +%%Y-%%m-%%d).log
log-reopen = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;uWSGI를 실행하기 전에 mysite.ini 파일에 설정해주었던 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;logto&lt;/code&gt; 옵션의 디렉토리를 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo mkdir -p /var/log/uwsgi/mysite
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;그 다음 아래의 명령을 실행해 ini 파일로 uWSGI를 실행합니다. sudo 권한으로 실행해야 하기 때문에, uwsgi-env 가상환경 폴더 안에 있는 uwsgi를 직접 실행해주어야 합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo /home/ubuntu/.pyenv/versions/uwsgi-env/bin/uwsgi -i /srv/air-pollution/.config/uwsgi/mysite.ini 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Nginx 설치
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# PPA 추가를 위한 필요 패키지
sudo apt-get install software-properties-common python-software-properties

# nginx 안정화 최신버전 PPA 추가
sudo add-apt-repository ppa:nginx/stable

# PPA 저장소 업데이트
sudo apt-get update

# nginx 설치
sudo apt-get install nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;유저 설정
배포에 관한 작업은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 유저가 담당하므로 Nginx 의 유저를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deploy&lt;/code&gt; 로 바꿔줍니다.
Nginx 관련 설정은 /etc/nginx/nginx.conf 에서 관리합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo vi /etc/nginx/nginx.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;파일의 첫 줄 user www-data; 를 user deploy; 로 수정해줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;user deploy;
worker_processes auto;
pid /run/nginx.pid;
include /etc/nginx/modules-enabled/*.conf;

events {
        worker_connections 768;
        # multi_accept on;
}

http {
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;Nginx 설정 파일 생성 및 연결
이제 로컬 서버로 빠져나가서 장고 프로젝트 폴더로 이동합니다. 
uWSGI 설정을 저장했던 .config 폴더에 nginx 폴더를 새로 만들고 그 아래에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; 파일을 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   ├── nginx
│   │   └── mysite.conf
│   └── uwsgi
│       ├── mysite.ini
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; :&lt;/p&gt;
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;server {
  listen 80;
  server_name *.compute.amazonaws.com;
  charset utf-8;
  client_max_body_size 128M;

  location / {
      uwsgi_pass  unix:///tmp/mysite.sock;
      include     uwsgi_params;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;장고 프로젝트 폴더 내의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.conf&lt;/code&gt; 파일을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/nginx/sites-available/&lt;/code&gt; 경로에 복사해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo cp -f /srv/air-pollution/.config/nginx/mysite.conf /etc/nginx/sites-available/mysite.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이제 다음 명령을 입력하여 sites-available 에 있는 설정파일을 sites-enabled 폴더에 링크해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ln -sf /etc/nginx/sites-available/mysite.conf /etc/nginx/sites-enabled/mysite.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;sites-enabled 폴더의 default 링크는 삭제해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo rm /etc/nginx/sites-enabled/default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;uWSGI 설정
    &lt;ul&gt;
      &lt;li&gt;이제 uWSGI를 Nginx와 통신하도록 설정해줍니다.&lt;/li&gt;
      &lt;li&gt;리눅스에서 관리하는 service 파일을 만들어 서버가 실행될 때 자동으로 uWSGI를 백그라운드에 실행시켜주도록 해야합니다.&lt;/li&gt;
      &lt;li&gt;/장고 프로젝트 폴더/.config/uwsgi/ 에 uwsgi.service 파일을 생성합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;air-pollution
├── .config
│   ├── nginx
│   │   └── mysite.conf
│   └── uwsgi
│       ├── mysite.ini
│       └── uwsgi.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;uwsgi.service 파일안에 아래와 같이 작성합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=uWSGI service
After=syslog.target

[Service]
ExecStart=/home/ubuntu/.pyenv/versions/uwsgi-env/bin/uwsgi -i /srv/air-pollution/.config/uwsgi/mysite.ini

Restart=always
KillSignal=SIGQUIT
Type=notify
StandardError=syslog
NotifyAccess=all

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;AWS 서버에 접속해서 uwsgi.service 파일을 /etc/systemd/system/ 에 하드링크를 걸어줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ln -f /srv/air-pollution/.config/uwsgi/uwsgi.service /etc/systemd/system/uwsgi.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;파일을 연결해준 뒤 아래 명령을 실행해서 데몬을 리로드 해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl daemon-reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;그 다음 아래 명령어로 uwsgi 데몬을 활성화 해줍니다. 이제 서버에 접속하기만 해도 uwsgi와 Nginx가 백그라운드에서 실행됩니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl enable uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;소켓 통신 설정 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt; 파일을 열어 http = :8080 을 삭제하고 그 부분에 아래와 같이 추가합니다. uWSGI가 http 요청을 받는 대신, /tmp/mysite.sock 파일을 통해 요청을 받도록 소켓 통신을 설정해주는 것입니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mysite.ini&lt;/code&gt;&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[uwsgi]
chdir = /srv/air-pollution/mysite
module = mysite.wsgi:application
home = /home/ubuntu/.pyenv/versions/mysite

uid = deploy
gid = deploy

socket = /tmp/mysite.sock
chmod-socket = 666
chown-socket = deploy:deploy

enable-threads = true
master = true
vacuum = true
pidfile = /tmp/mysite.pid
logto = /var/log/uwsgi/mysite/@(exec://date +%%Y-%%m-%%d).log
log-reopen = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;데몬 리로드로 다시 불러와주고, Nginx와 uWSGI를 재부팅해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo systemctl daemon-reload
sudo systemctl restart nginx uwsgi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS 서버 설정
    &lt;ul&gt;
      &lt;li&gt;mysite.conf 파일을 보면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;listen 80&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;server_name *.compute.amazonaws.com&lt;/code&gt;부문이 있습니다. listen 80 은 요청을 80번 포트를 통해 받도록 설정하는 것이고, server_name 의 *.compute.amazonaws.com 는 서버의 URL 주소입니다.&lt;/li&gt;
      &lt;li&gt;80번 포트는 웹 브라우저에서 기본적으로 요청을 보내는 포트인데, 아직 AWS 서버의 보안 그룹에 등록되어 있지 않기 때문에 80번 포트를 등록시켜주어야합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/4.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;설정이 끝났으므로 브라우저에서 접속해보면 django app 모습이 나타납니다.&lt;/li&gt;
      &lt;li&gt;만약 에러가 난다면 아래의 명령으로 에러 로그를 확인해서 문제점을 찾을 수 있습니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Nginx 에러 로그
cat /var/log/nginx/error.log

# uWSGI 로그
cat /var/log/uwsgi/mysite/로그작성날짜.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;static-files을-s3에-저장하기&quot;&gt;static files을 S3에 저장하기&lt;/h2&gt;

&lt;p&gt;Amazon S3 는 아마존 웹 서비스(AWS)에서 제공하는 클라우드 스토리지 서비스입니다. 여기서는 장고 프로젝트에 필요한 스태틱 파일 및 미디어 파일들을 Amazon S3라는 별도의 저장소에 저장하여 관리하는 방법을 정리하였습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;django-storages&lt;/code&gt; 패키지 설치
    &lt;ul&gt;
      &lt;li&gt;터미널에서 아래 명령을 입력하여 django_storages 패키지를 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install django_storages
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;INSTALLED_APPS&lt;/code&gt;에 storages를 추가해줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;INSTALLED_APPS = [
'django.contrib.admin',
...
'storages',
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boto3&lt;/code&gt; 설치하기
    &lt;blockquote&gt;
      &lt;p&gt;Boto is the Amazon Web Services (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2. Boto provides an easy to use, object-oriented API as well as low-level direct service access. &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&quot;&gt;출처&lt;/a&gt;&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;django_storages 패키지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boto3&lt;/code&gt; 라는 패키지를 사용하여 S3와 통신하도록 구성되어있습니다.&lt;/li&gt;
      &lt;li&gt;터미널에서 아래 명령을 입력하여 boto3 패키지를 설치합니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS에서 S3 시작하기
    &lt;ul&gt;
      &lt;li&gt;먼저, S3는 EC2와 별개의 서비스이므로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IAM&lt;/code&gt;으로 생성했던 유저에게 S3 사용 권한을 추가해주어야 합니다.&lt;/li&gt;
      &lt;li&gt;AWS 콘솔로 접속한 다음 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;IAM&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;User&lt;/code&gt;탬을 눌러 사용자 관리 화면으로 갑니다.&lt;/li&gt;
      &lt;li&gt;생성되어 있는 사용자 이름을 클릭하여 수정화면으로 들어갑니다.&lt;/li&gt;
      &lt;li&gt;Permissions 탭에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Add permissions&lt;/code&gt; 버튼을 클릭합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/5.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;버킷(bucket) 생성하기
    &lt;ul&gt;
      &lt;li&gt;S3 서비스는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;버킷(bucket)&lt;/code&gt;이라는 단위로 저장소를 제공합니다.&lt;/li&gt;
      &lt;li&gt;AWS의 S3콘솔로 이동하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;버킷 만들기&lt;/code&gt;를 눌러 새로운 버킷을 생성합니다.&lt;/li&gt;
      &lt;li&gt;생성한 버킷을 선택하여 Permissions에서 아래와 같이 설정합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-17/6.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;django 설정
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에서 아래와 같은 변수들을 추가해줍니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_ACCESS_KEY_ID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_ACCESS_KEY_ID&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_SECRET_ACCESS_KEY&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-BUCKET_NAME&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_DEFAULT_ACL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'public-read'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ap-northeast-2'&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;### When AWS region is 'SEOUL' 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_S3_CUSTOM_DOMAIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'%s.s3.%s.amazonaws.com'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_OBJECT_PARAMETERS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'CacheControl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'max-age=86400'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;이제 모든 설정이 끝났습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;S3에 Static 파일 모으기
    &lt;ul&gt;
      &lt;li&gt;S3에 잘 저장이 되는지 확인해보기위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;static&lt;/code&gt; 폴더를 생성한후 test.txt 파일을 생성합니다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;setting.py&lt;/code&gt;에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;STATICFILES_DIRS&lt;/code&gt;에 경로를 추가하여 최종적으로는 아래와 같아야합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;STATIC_URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'/static/'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_STORAGE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'storages.backends.s3boto3.S3Boto3Storage'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_ACCESS_KEY_ID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_ACCESS_KEY_ID&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-AWS_SECRET_ACCESS_KEY&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;your-BUCKET_NAME&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_DEFAULT_ACL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'public-read'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ap-northeast-2'&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;### When AWS region is 'SEOUL' 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_S3_CUSTOM_DOMAIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'%s.s3.%s.amazonaws.com'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_STORAGE_BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_REGION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AWS_S3_OBJECT_PARAMETERS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'CacheControl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'max-age=86400'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATIC_DIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BASE_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'static'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;STATICFILES_DIRS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;STATIC_DIR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;모든 세팅이 끝나면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;collectstatic&lt;/code&gt; 명령으로 모든 정적 파일들을 모아줍니다.
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python manage.py collectstatic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;실행이 완료되면 S3 콘솔로 가서 생성했던 버킷으로 들어가 저장된 파일을 확인합니다.&lt;/li&gt;
      &lt;li&gt;테스트로 추가한 test.txt도 추가된 것을 볼 수 있을 것입니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;외부도메인-연결을-위해-route-53-사용하기&quot;&gt;외부도메인 연결을 위해 Route 53 사용하기&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;도메인 구입하기
    &lt;ul&gt;
      &lt;li&gt;도메인을 구매하는 사이트는 많으나, 여기서는 cafe24를 이용하였습니다. 
https://www.cafe24.com/?controller=domain_main&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;고정IP 부여받기
    &lt;ul&gt;
      &lt;li&gt;EC2는 기본적으로 유동IP를 가집니다. 그때문에 인스턴스를 stoping 후 다시 시작을 하는 경우, IP가 변경됩니다.&lt;/li&gt;
      &lt;li&gt;유동IP를 사용할 경우 인스턴스를 재시작할때마다 DNS 연결설정을 다시 해주어야하는 번거로움이 생기기 때문에 우선 elastic IP 할당(고정IP 할당)후 도메인을 연결하도록 하겠습니다.&lt;/li&gt;
      &lt;li&gt;EC2 서비스에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;탄력적 IP(Elastic IP)&lt;/code&gt;를 클릭합니다.&lt;/li&gt;
      &lt;li&gt;‘새주소 할당’ -&amp;gt; ‘할당’&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;할당된 IP에 ‘작업’ -&amp;gt; ‘주소 연결’
&lt;img src=&quot;/assets/img/2019-01-17/7.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;아래와 같이 EC2 인스턴스를 연결합니다. 
&lt;img src=&quot;/assets/img/2019-01-17/8.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AWS의 Route53 설정
    &lt;ul&gt;
      &lt;li&gt;Amazon &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Route 53&lt;/code&gt;은 가용성과 확장성이 우수한 DNS(도메인 이름 시스템) 웹 서비스입니다.&lt;/li&gt;
      &lt;li&gt;https://console.aws.amazon.com/route53/home?#&lt;/li&gt;
      &lt;li&gt;Create Hosted Zone 을 클릭합니다.
        &lt;ul&gt;
          &lt;li&gt;도메인 이름에 구매한 외부 도메인 주소를 적고 create를 클릭합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;아래와 같은 레코드 셋이 생성된 것을 볼 수 있습니다.&lt;/li&gt;
      &lt;li&gt;create record set을 클릭하여 A type 레코드를 생성합니다.
        &lt;ul&gt;
          &lt;li&gt;value 에 인스턴스에 할당된 고정IP를 적어줍니다. 
&lt;img src=&quot;/assets/img/2019-01-17/9.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;외부도메인에 Name Server 연결하기
    &lt;ul&gt;
      &lt;li&gt;cafe24의 도메인 관리 페이지에 들어가서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;네임서버 변경&lt;/code&gt;을 클릭합니다.&lt;/li&gt;
      &lt;li&gt;네임서버를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Route 53&lt;/code&gt;의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NS 레코드값&lt;/code&gt;들로 변경해줍니다. 
&lt;img src=&quot;/assets/img/2019-01-17/10.png&quot; width=&quot;400&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모든 것이 완료되었고, 구입한 도메인으로 연결이 성공할때까지 약 30분 정도 소요 시간이 걸릴 수 있습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;trouble-shooting&quot;&gt;trouble shooting&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;b&gt;어드민 로그인 시 “attempt to write a readonly database” 에러 발생&lt;/b&gt;&lt;br /&gt;
db.sqlite3의 권한 문제로 아래 명령어를 이용해 권한 부여를 해주어야합니다. 이때 db.sqlite3가 위치한 부모 디렉토리에도 권한이 부여되여있어야하니 주의하셔야합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo chgrp [deploy를 수행하는 유저그룹] [path-to-db.sqlite3]
sudo chown [deploy를 수행하는 유저] [path-to-db.sqlite3]
sudo chown [deploy를 수행하는 유저] [path-to-parent-directory-of-db.sqlite3]
sudo chgrp [deploy를 수행하는 유저그룹] [path-to-parent-directory-of-db.sqlite3]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-1-aws/&quot;&gt;https://nachwon.github.io/django-deploy-1-aws/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-2-wsgi/&quot;&gt;https://nachwon.github.io/django-deploy-2-wsgi/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-3-nginx/&quot;&gt;https://nachwon.github.io/django-deploy-3-nginx/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nachwon.github.io/django-deploy-7-s3/&quot;&gt;https://nachwon.github.io/django-deploy-7-s3/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>yjucho</name></author><category term="django" /><summary type="html">django application을 Amazon Web Service(AWS)에 배포하는 과정을 요약한 포스팅입니다. 이 블로그를 주로 참고하였고, 수행 중 발생하는 문제에 대한 trouble shooting 과정을 기억하기 위해 작성하였습니다.</summary></entry><entry><title type="html">시계열 분석 part5 - ARMAX, ARFIMA, ARCH, GARCH</title><link href="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5/" rel="alternate" type="text/html" title="시계열 분석 part5 - ARMAX, ARFIMA, ARCH, GARCH" /><published>2019-01-15T00:00:00+09:00</published><updated>2019-01-15T00:00:00+09:00</updated><id>http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5</id><content type="html" xml:base="http://localhost:4000/spatio-temporal%20data/time-series/time-series-part5/">&lt;p&gt;지금까지 우리는 시계열 데이터를 설명하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMA&lt;/code&gt;모델을 살펴보고, non-stationary 시그널의 경우 differecing을 통해서 stationary 시그널을 얻은 후, ARMA를 적용하는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt; 모델을 공부하였습니다. 또한 여러개의 시그널을 동시에 모델링하도록
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vector AR&lt;/code&gt; 모델도 알아보았습니다.&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 1) ARMA 모델에 exogenous(외적 요인) 입력이 추가된 형태인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt; 모델과 2) 자연수 형태였던 difference order를 유리수로 확장하여 long-term memory를 모델링한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt; 모델, 3) non-linear 모형의 대표적인 예인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARCH&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;에 대해서 설명드리고자 합니다. 각 각의 모델들은 ARIMA 모델들의 확장판으로 기존 모델과의 차이점을 이해하는 것을 목표로 합니다.&lt;/p&gt;

&lt;h2 id=&quot;armax---arma-with-exogenous-inputs&quot;&gt;ARMAX - ARMA with exogenous inputs&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt;는 일반적인 ARMA(p, q) process에 시간따라 변하는 외적 요인(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;exogenous inputs&lt;/code&gt;, \(d_t\))을 추가하여 고려하는 모델입니다. ARMA 모델에 과거 b개의 외적 요인 \(\{d_t\}\)의 선형 조합이 포함되며, 이에 따라 \(\eta_1, ..., \eta_k\)가 모델 파라미터로 추가됩니다.&lt;/p&gt;

&lt;p&gt;ARMA(p, q) : \(X_t = Z_t + \sum_{i=1}^p \phi_i X_{t-i} + \sum_{j=1}^q \theta_j Z_{t-j}\)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;
ARMAX(p, q, b) :&lt;/p&gt;

\[X_t = Z_t + \sum_{i=1}^p \phi_i X_{t-i} + \sum_{j=1}^q \theta_j Z_{t-j} + \sum_{k=1}^b \eta_k d_{t-k}\]

&lt;p&gt;statsmodels의 시계열 모형 클래스 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMA&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SARIMAX&lt;/code&gt; 등은 모두 외부 시계열의 영향을 포함하기 위한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;exog&lt;/code&gt; 라는 인자를 가지고 있습니다. 이 인자에 외부요인에 해당하는 데이터를 지정해주면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMAX&lt;/code&gt; 모델이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 : 경남 창원시 의창구 원이대로 450(시설관리공단 실내수영장 앞)에서 측정된 초미세먼지(PM2.5)와 인근 북창원의 기상 데이터(온도, 습도)&lt;/li&gt;
  &lt;li&gt;기간 : 	2018-11-01 ~ 2018-12-1 (1개월, 1시간 단위)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;미세먼지 측정 농도는 온도와 습도에 영향을 받습니다. 측정방식에 따른 한게점이기도 하고, 미세먼지 발생량 자체가 온도, 습도 기상 상태에 따라 달라질 수 있기 때문입니다. 따라서 초미세먼지 농도를 예측함에 있어서 해당 시간대의 기상 데이터를 외부 요인으로 사용하여 모델을 추정해보았습니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;df = df[['pm25Value', 'temp','hm']]
df = np.array(df)

arma_mod30 = sm.tsa.ARMA(df[:,0], (3,0)).fit(disp=False)
predict_pm25 = arma_mod30.predict(dynamic=True)
print(&quot;AR(3) model's RMSE: &quot;, mean_forecast_err(df[3:,0], predict_pm25))

armax_mod30 = sm.tsa.ARMA(df[:,0], (3,0), exog=df[:,1:]).fit(disp=False)
predict_pm25 = armax_mod30.predict(dynamic=True)
print(&quot;ARX(3) model's RMSE: &quot;, mean_forecast_err(df[3:,0], predict_pm25))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AR(3) model's RMSE:  8.036039331569588
ARX(3) model's RMSE:  7.710071937116329
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;추정결과, 예측정확도를 평가하는 RMSE가 0.3 줄어든 것을 볼수 있습니다. 외부 요인을 도입함으로서 예측 성능을 높일 수 있다는 것을 보여주는 결과입니다.&lt;/p&gt;

&lt;h2 id=&quot;arfima---autoregressive-fractionally-integrated-moving-average&quot;&gt;ARFIMA - Autoregressive fractionally integrated moving average&lt;/h2&gt;

&lt;p&gt;일반적인 ARMA(p, q)모델은 ACF가 빠르게 감소하는 모습을 띕니다. 이러한 형태를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;short-term memory process&lt;/code&gt;라고 합니다.&lt;/p&gt;

\[\rho(h) \to 0 \ as \ h \to \infty\]

&lt;p&gt;하지만 실제 사례에서의 시그널의 ACF는 이상적인 것처럼 빠르게 감소하지 않습니다. 이 경우, &lt;a href=&quot;/spatio-temporal%20data/time-series/time-series-part3/&quot;&gt;Part3&lt;/a&gt;에서 알아본 것처럼 differencing 등을 통해서 이상적인 성질(fast dacaying ACF)을 갖는 새로운 시그널로 변환하여 모델링한다고 설명하였지만, differencing을 반복적으로 수행하더라도 여전히 ACF가 long tail 형태를 띄는 경우가 있습니다. 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;long-term memory process&lt;/code&gt;라고 하며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt; 모델을 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

\[(1-B)^d X_t = Z_t, \ \ \ \ \ 0 \lt d \lt \frac{1}{2}\]

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt;의 \((1-B)^d\) 부분은 d가 양수로 몇번의 differencing을 수행할것인지를 의미했습니다. 하지만 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARFIMA&lt;/code&gt;모델에서는 d가 0과 1/2 사이의 유리수라는 점이 다릅니다. 여기서 \((1-B)^d\)는 “fractionally differenced”된 \(\Phi(B)\) 라고 부릅니다.&lt;/p&gt;

\[X_t = (1-B)^{-d} Z_t
= \sum_{j=0}^\infty \Theta_j B^j Z_t\]

&lt;p&gt;ACF of \(X_t\):&lt;/p&gt;

\[\rho(h) = \frac{\Gamma(h+d)\Gamma(1-d)}{\Gamma(h-d+1)\Gamma(d)} \sim h^{2d-1} \ for \ large \ h\]

\[\sum_{h=-\infty}^{\infty} |\rho(h)| = \infty\]

&lt;p&gt;위와 같이 모든 lag에 대한 ACF를 모두 더하면 \(\infty\)가 되기 때문에, 이를 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;long-term memory process&lt;/code&gt;를 설명할 수 있습니다. 추정해야할 모델 파라미터는 \(d\)가 되며, 일반적인 ARFIMA(p, d, q)는 다음과 같습니다.&lt;/p&gt;

\[\Phi(B)(1-B)^d X_t = \Theta(B) Z_t\]

&lt;p&gt;&lt;small&gt;statsmodels에는 ARFIMA 기능이 지원되지 않아, 분석 사례는 생략하도록 하겠습니다.&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;arch&quot;&gt;ARCH&lt;/h2&gt;

&lt;p&gt;앞서 살펴본 모델들은 {X_t}가 이전 값 혹은 white noise 등 과의 선형(linear) 조합으로 설명되는 경우였습니다. 지금부터는 non-linear 모델의 대표적인 예인 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARCH&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;를 소개하도록 하겠습니다. 먼저 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARCH(autoregressive conditional heteroskedasticity)&lt;/code&gt; 모델은 다음과 같이 정의됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

\[\begin{align}
X_t &amp;amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp;amp; = \alpha_0 + \sum_{I=1}^p \alpha_i x_{t-i}^2
\end{align}\]

&lt;p&gt;ARCH(p)를 이해하기 위해서 평균과 분산을 살펴보겠습니다.&lt;/p&gt;

\[\begin{align}
E[X_t \vert  X_{t-1}, X_{t-2}, …] &amp;amp; = E[\sigma_t * Z_t \vert  X_{t-1}, X_{t-2}, …] \\
&amp;amp; = \sigma_t E[ Z_t \vert  X_{t-1}, X_{t-2}, …]  \\
&amp;amp; = 0 \\ 
\\
E[X_t] &amp;amp; = E_{X_{t-1}, X_{t-2}, …}[E_{X_t \vert  X_{t-1}, X_{t-2}, …} [X_t] ] \\
&amp;amp;= 0\\
\\
Var[X_t \vert  X_{t-1}, X_{t-2}, …] &amp;amp; = E[X_t^2 \vert  X_{t-1}, X_{t-2}, …] \\
&amp;amp; = E[ \sigma_t^2Z_t^2 \vert  X_{t-1}, X_{t-2}, …] \\ 
&amp;amp; = \sigma_t^2 E[ Z_t^2 \vert  X_{t-1}, X_{t-2}, …] \\
&amp;amp; = \sigma_t^2 \\ 
\\
Cov[X_{t+h}, X_t] &amp;amp; = E[X_{t+h} X_t] \\
&amp;amp; = E_{X_{t+h-1}, X_{t+h-2}, …}[X_t E_{X_{t+h} \vert  X_{t+h-1}, X_{t+h-2}, …} [X_{t+h}] ]\\
&amp;amp; =0
\end{align}\]

&lt;p&gt;\(\{X_t\}\)의 평균은 0이고, lag=h인 관측값간의 공분산은 0입니다. 즉 시간에 따라 변하지 않는 성질을 가지고 있습니다. (\(\{X_t\}\)가 white noise라는 것을 의미합니다) 하지만 \(Var[X_t]=\sigma_t^2\)이기때문에, nonstationary합니다.  \(\sigma_t^2\)를 volatility 라고 부르기도 합니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;ARCH(1) : 
\(\left\{
\begin{align}
X_t &amp;amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp;amp; = \alpha_0 + \alpha_1 X_{t-1}^2 \\
\end{align}
\right.\)&lt;/p&gt;

&lt;p&gt;첫번째 식을 제곱한 후, 두 식을 빼면 다음과 같습니다.&lt;/p&gt;

\[\begin{align}
X_t^2 &amp;amp; = \sigma_t^2 * Z_t^2 \\
\alpha_0 + \alpha_1 X_{t-1}^2  &amp;amp; = \sigma_t^2 \\
X_t^2 - (\alpha_0 + \alpha_1 X_{t-1}^2) &amp;amp; = \sigma_t^2(Z_t^2 - 1) \\
X_t^2 &amp;amp; = \alpha_0 + \alpha_1 X_{t-1}^2 + \sigma_t^2(Z_t^2 - 1)
\end{align}\]

&lt;p&gt;마지막 수식을 살펴보면 \(\{X_t^2\}\) 가 직전 값인 \(\{X_{t-1}^2\}\)에 영향을 받는 auto-regressive 형태로 설명됩니다. 즉, ARCH(1) 모델은 \(\{X_t^2\}\)가 AR(1)인 프로세스와 동일한 것을 알 수 있습니다. 다만 AR(1)의 noise가 non-Gaussian인 것은 주의해야합니다.&lt;/p&gt;

&lt;p&gt;ARCH(p) 모델에서 추정해야하는 모델 파라미터는 \(\alpha_0, \alpha_1\)으로 Maximum Likelihood Estimation(MLE)를 이용해 추정합니다.&lt;/p&gt;

&lt;p&gt;ARCH(p) 모델을 앞서 살펴본 linear 모델들과 합친 joint ARCH model도 생각해볼수 있습니다. 예를 들어, AR(1)-ARCH(1) 모델은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;AR(1)-ARCH(1) : \(\{X_t\}\)는 AR(1) process이고, \(\{Z_t\}\)가 ARCH인 모델&lt;/p&gt;

\[\left\{
\begin{align}
X_t &amp;amp; = \phi X_{t-1} + Z_t \\
\sigma_t^2 &amp;amp; = \alpha_0 + \alpha_1 Z_{t-1}^2 \\
\end{align}
\right.\]

&lt;h2 id=&quot;generalized-archgarch&quot;&gt;Generalized ARCH(GARCH)&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GARCH&lt;/code&gt;는 ARCH 모델의 \(\sigma_t^2\)에 auto-regressive한 성질을 추가한 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;example&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;GARCH(1, 1) : 
\(\left\{
\begin{align}
X_t &amp;amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp;amp; = \alpha_0 + \alpha_1 X_{t-1}^2 + \beta_1 \sigma_{t-1}^2 \\
\end{align}
\right.\)&lt;/p&gt;

&lt;p&gt;일반적인 GARCH(p, q) 모델은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/p&gt;

\[\begin{align}
X_t &amp;amp; = \sigma_t * Z_t \\
\sigma_t^2 &amp;amp; = \alpha_0 + \sum_{i=1}^p \alpha_i X_{t-i}^2 + \sum_{j=1}^q \beta_j \sigma_{t-j}^2
\end{align}\]

&lt;p&gt;\(\{X_t\}\)가 ARCH(p) 모델일 경우, \(\{X_t^2\}\)는 AR(p)모델이 된다는 것을 앞서 설명드렸습니다. 마찬가지로,  \(\{X_t\}\)가 GARCH(p, q) 모델일 경우, \(\{X_t^2\}\)는 ARMA(p, q)모델이 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;실제 데이터를 이용한 분석&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;ARCH 계열의 모델에 적합한 시계열 데이터은 그 자체로는 auto-correlation 관계가 없지만, 데이터의 제곱값간의 auto-correlation이 존재하는 경우입니다. 주가의 수익률이 대표적인 ARCH모델에 설명되는 시계열 데이터입니다.&lt;/p&gt;

&lt;p&gt;여기서는 ARCH모델을 이용해 주가의 수익률을 예측해보았습니다.&lt;a href=&quot;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&quot;&gt;이 분석 사례&lt;/a&gt;를 참고하여 작성하였습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas_datareader.data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1990&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;en&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_data_yahoo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^GSPC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;en&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Adj Close'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pct_change&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropna&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;수익률 그 자체로는 자기 상관관계가 없지만, 수익률의 제곱값은 자기 상관관계를 갖고 있는 것을 볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig4.png&quot; /&gt;
&lt;img src=&quot;/assets/img/2019-01-15/fig5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ARCH모델은 파이썬의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;arch&lt;/code&gt;패키지를 통해서 사용할 수 있습니다. ARCH(1)모델로 추정해보도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;arch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arch_model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;am1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arch_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;am1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Iteration:      1,   Func. Count:      5,   Neg. LLF: 10051.187042085134
Iteration:      2,   Func. Count:     14,   Neg. LLF: 10047.115662777182
Iteration:      3,   Func. Count:     23,   Neg. LLF: 9820.333972115874
Iteration:      4,   Func. Count:     29,   Neg. LLF: 9810.75544390718
Iteration:      5,   Func. Count:     35,   Neg. LLF: 9804.073095175208
Iteration:      6,   Func. Count:     40,   Neg. LLF: 9801.645677600663
Iteration:      7,   Func. Count:     45,   Neg. LLF: 9801.613667614067
Iteration:      8,   Func. Count:     50,   Neg. LLF: 9801.613523562157
Iteration:      9,   Func. Count:     55,   Neg. LLF: 9801.613520460578
Optimization terminated successfully.    (Exit mode 0)
            Current function value: 9801.613520460529
            Iterations: 9
            Function evaluations: 55
            Gradient evaluations: 9
                      Constant Mean - ARCH Model Results                      
==============================================================================
Dep. Variable:              Adj Close   R-squared:                      -0.000
Mean Model:             Constant Mean   Adj. R-squared:                 -0.000
Vol Model:                       ARCH   Log-Likelihood:               -9801.61
Distribution:                  Normal   AIC:                           19609.2
Method:            Maximum Likelihood   BIC:                           19629.6
                                        No. Observations:                 6552
Date:                Sat, Jan 19 2019   Df Residuals:                     6549
Time:                        17:13:45   Df Model:                            3
                                 Mean Model                                 
============================================================================
                 coef    std err          t      P&amp;gt;|t|      95.0% Conf. Int.
----------------------------------------------------------------------------
mu             0.0482  1.487e-02      3.239  1.202e-03 [1.902e-02,7.732e-02]
                            Volatility Model                            
========================================================================
                 coef    std err          t      P&amp;gt;|t|  95.0% Conf. Int.
------------------------------------------------------------------------
omega          0.9115  4.354e-02     20.935  2.568e-97 [  0.826,  0.997]
alpha[1]       0.3147  4.866e-02      6.467  9.971e-11 [  0.219,  0.410]
========================================================================

Covariance estimator: robust
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;res1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/2019-01-15/fig3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reference&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.springer.com/us/book/9781475777505&quot;&gt;Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.statsmodels.org/dev/index.html&quot;&gt;Statsmodel’s Documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;http://www.kocw.net/home/search/kemView.do?kemId=977301&quot;&gt;시계열분석 강의, 한양대학교(이기천)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4]  &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_average&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model#ARMAX&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model#ARMAX&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] &lt;a href=&quot;https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity&quot;&gt;https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[7] &lt;a href=&quot;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&quot;&gt;https://datascienceschool.net/view-notebook/dac8a9bfac6740ff85d5b6dcc9e9e908/&lt;/a&gt;&lt;/p&gt;</content><author><name>yjucho</name></author><category term="Spatio-Temporal Data" /><category term="Time-series" /><summary type="html">지금까지 우리는 시계열 데이터를 설명하기 위해 ARMA모델을 살펴보고, non-stationary 시그널의 경우 differecing을 통해서 stationary 시그널을 얻은 후, ARMA를 적용하는 ARIMA 모델을 공부하였습니다. 또한 여러개의 시그널을 동시에 모델링하도록 Vector AR 모델도 알아보았습니다.</summary></entry></feed>