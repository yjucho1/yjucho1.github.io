<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>시계열 분석 - part1 - yjucho’s blog</title>
<meta name="description" content="시계열 데이터는 일정 시간동안 수집된 일련의 데이터로, 시간에 따라서 샘플링되었기 때문에 인접한 시간에 수집된 데이터는 서로 상관관계가 존재하게 됩니다. 따라서 시계열 데이터를 추론하는데, 전통적인 통계적 추론이 적합하지 않을수 있습니다. 현실 세계에서는 날씨, 주가, 마케팅 데이터 등등 다양한 시계열 데이터가 존재하고, 시계열 분석을 통해 이러한 데이터가 생성되는 메카니즘을 이해하여 설명가능한 모델로서 데이터를 표현하거나, 미래 값을 예측하는 것, 의미있는 신호값만만 분리하는 일에 활용할 수 있습니다.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_EN">
<meta property="og:site_name" content="yjucho's blog">
<meta property="og:title" content="시계열 분석 - part1">
<meta property="og:url" content="http://localhost:4000/time%20series/time-series-part1/">


  <meta property="og:description" content="시계열 데이터는 일정 시간동안 수집된 일련의 데이터로, 시간에 따라서 샘플링되었기 때문에 인접한 시간에 수집된 데이터는 서로 상관관계가 존재하게 됩니다. 따라서 시계열 데이터를 추론하는데, 전통적인 통계적 추론이 적합하지 않을수 있습니다. 현실 세계에서는 날씨, 주가, 마케팅 데이터 등등 다양한 시계열 데이터가 존재하고, 시계열 분석을 통해 이러한 데이터가 생성되는 메카니즘을 이해하여 설명가능한 모델로서 데이터를 표현하거나, 미래 값을 예측하는 것, 의미있는 신호값만만 분리하는 일에 활용할 수 있습니다.">







  <meta property="article:published_time" content="2018-12-18T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/time%20series/time-series-part1/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "yjucho",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="yjucho's blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">yjucho's blog</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/category/" >Category</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/img/bio-photo.jpg" alt="yjucho" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">yjucho</h3>
    
    
      <p class="author__bio" itemprop="description">
        Data science, Deep Learning, AI
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="http://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Seoul, Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:jyj0729@gmail.com"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
          
        
          
        
          
        
          
            <li><a href="https://www.facebook.com/yjucho"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i> Facebook</a></li>
          
        
          
            <li><a href="https://github.com/yjucho1"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="시계열 분석 - part1">
    <meta itemprop="description" content="시계열 데이터는 일정 시간동안 수집된 일련의 데이터로, 시간에 따라서 샘플링되었기 때문에 인접한 시간에 수집된 데이터는 서로 상관관계가 존재하게 됩니다. 따라서 시계열 데이터를 추론하는데, 전통적인 통계적 추론이 적합하지 않을수 있습니다. 현실 세계에서는 날씨, 주가, 마케팅 데이터 등등 다양한 시계열 데이터가 존재하고, 시계열 분석을 통해 이러한 데이터가 생성되는 메카니즘을 이해하여 설명가능한 모델로서 데이터를 표현하거나, 미래 값을 예측하는 것, 의미있는 신호값만만 분리하는 일에 활용할 수 있습니다.">
    <meta itemprop="datePublished" content="December 18, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">시계열 분석 - part1
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>시계열 데이터는 일정 시간동안 수집된 일련의 데이터로, 시간에 따라서 샘플링되었기 때문에 인접한 시간에 수집된 데이터는 서로 상관관계가 존재하게 됩니다. 따라서 시계열 데이터를 추론하는데, 전통적인 통계적 추론이 적합하지 않을수 있습니다. 현실 세계에서는 날씨, 주가, 마케팅 데이터 등등 다양한 시계열 데이터가 존재하고, 시계열 분석을 통해 이러한 데이터가 생성되는 메카니즘을 이해하여 설명가능한 모델로서 데이터를 표현하거나, 미래 값을 예측하는 것, 의미있는 신호값만만 분리하는 일에 활용할 수 있습니다.</p>

<p>일반적인 시계열분석의 과정은 아래와 같습니다.</p>

<ul>
  <li>Plot the series and examine the main features of the graph, checking in particular whether there is
    <ul>
      <li>A trend</li>
      <li>A seasonal component</li>
      <li>Any apparent sharp changes in behavior</li>
      <li>Any outlying observations</li>
    </ul>
  </li>
  <li>Remove the trend and seasonal components to get stationary residuals
    <ul>
      <li>To achieve goal, you may need to apply a preliminary transformation like taking logarithms</li>
      <li>Estimate the trend and seasonal components using classical decomposition model</li>
      <li>Or Eliminate the trend and seasonal components using differencing</li>
      <li>Anyway, the goal is to get stationary residuals</li>
    </ul>
  </li>
  <li>Choose a model to fit the residuals</li>
  <li>Forecasting the residuals and then inverting the transformations for original series</li>
  <li>Alternative approach is to express the series in terms of its Fourier components. But it will not be discussed in here.</li>
</ul>

<p>시계열 분석은 시간의 경과에 따라 변하지 않는 어떤 특성을 가진 프로세스를 분석하는 것입니다. 만약 시계열 데이터를 예측하고자 한다면, 우리는 시간에 따라 변하지 않는 무언가가 있다는 것을 반드시 가정해야합니다. 예를 들면 평균이 변하지 않는것(no trend), 분산이 변하지 않고, 주기적인 패턴이 없는 데이터를 가정합니다. 이러한 속성을 “stationary”하다고 합니다. 어떤 시계열 데이터가 stationary하다는 가정을 하면, 우리는 다양한 기법들을 활용할수 있습니다. 앞으로의 포스팅에서는 이러한 기법들이 무엇인지 소개하려고 합니다.</p>

<h3 id="stationary-auto-covariance-function-and-auto-correlation-function">Stationary, Auto-Covariance Function and Auto-Correlation Function</h3>

<p>시계열 <script type="math/tex">\{X_t, t=0, \pm 1, ...\}</script> 가 stationary하다는 것은 h lag만큼 time-shifted 된 시계열 <script type="math/tex">\{X_{t+h}, t=0, \pm 1, ...\}</script>와 통계적인 속성이 유사하다는 것을 의미합니다. 이 때 통계적인 속성을 first and second order moments(mean and covariance)로만 제한하면, 아래와 같이 수식적 정의를 할 수 있습니다.</p>

<p><b>Definition<b></b></b></p>

<p>Let <script type="math/tex">{X_t}</script> be a time series with <script type="math/tex">% <![CDATA[
E(X_t^2) < \infty %]]></script>.</p>

<p>The mean function of <script type="math/tex">{X_t}</script> is <script type="math/tex">\mu_X(t) = E(X_t)</script>.</p>

<p>The covariance function of <script type="math/tex">{X_t}</script> is <script type="math/tex">\rho_X(r, s) = Cov(X_r, X_s) = E[(X_r - \mu_X(r))(X_s - \mu_X(s))]</script> for all integers r and s.</p>

<p><b>Definition</b></p>

<p><script type="math/tex">{X_t}</script> is (weakly) stationary if</p>

<p>1) <script type="math/tex">\mu_X(t)</script> is independent of t.</p>

<p>2) <script type="math/tex">\gamma_X(t+h, t)</script> is independent of t for each h.</p>

<p>Strictly stationary is also</p>

<p>3) <script type="math/tex">(X_1, ..., Xn)</script> and <script type="math/tex">(X_{1+h}, ..., X_{n+h})</script> have the same joint distributions for all h and n &gt;0</p>

<p>2)에서의 정의를 이용해 stationary한 타임시리즈의 <script type="math/tex">\gamma_X(t+h, t)</script>는 t에 대해서 무관하기 때문에 <script type="math/tex">\gamma(\cdot)</script>는 “autocovariance function”으로 부르며, <script type="math/tex">\gamma_X(h)</script>는 h lag에서의 값을 지칭하는 것으로 하겠습니다. 또한 covariance를 normalization하여 correlation을 함께 정의할수 있습니다.</p>

<p><b>Definition</b></p>

<p>Let <script type="math/tex">{X_t}</script> be a stationary time series.</p>

<p>The autocovariance function (ACVF) of <script type="math/tex">{X_t}</script> at lag h is <script type="math/tex">\gamma_X(h) = Cov(X_{t+h}, X_t)</script>.</p>

<p>The autocorrelation function (ACF) of <script type="math/tex">{X_t}</script> at lag h is <script type="math/tex">\rho_X(h) \equiv \frac{\gamma_X(h)}{\gamma_X(0)} = Cor(X_{t+h}, X_t)</script></p>

<p>stationary time series의 대표적인 예는 iid noise와 white noise가 있습니다. iid noise는 <script type="math/tex">\{X_t\}</script>가 동일하고(identically) 서로 독립적인(independent) 분포를 따르며, 평균이 0인 확률변수로 정의됩니다. t에 상관없이 평균이 0이고, <script type="math/tex">\gamma_X(\cdot)</script>도 0이기때문에 stationary 조건을 만족합니다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\gamma_X(t+h, t) & = \sigma^2, \ & if \ h=0 \\ 
                 & = 0, \ & if \ h \ne 0
\end{align} %]]></script>

<p>마찬가지로 white noise with zero mean and variance <script type="math/tex">\sigma^2</script>도 (weak) staionary 조건을 만족합니다. (참고로 iid noise와 white noise는 다릅니다. 모든 iid noise는 white noise이지만, 그 역은 성립하지 않습니다. [참고] (https://www.researchgate.net/post/What_is_the_difference_between_white_noise_and_iid_noise))</p>

<p>시계열 데이터(realization)가 주어졌을때, 이 프로세스의 mean과 covariance를 추정하기 위해 sample mean과 sample covariance function, sample autocorrelation function를 사용합니다.</p>

<p><b>Definition</b></p>

<p>Let <script type="math/tex">x_1, ..., x_n</script> be observations of a time series.</p>

<p>The sample mean of <script type="math/tex">x_1, ..., x_n</script> is
<script type="math/tex">\bar{x} = \frac{1}{n} \sum_{t=1}^n x_t</script></p>

<p>The sample autocovariance function is
<script type="math/tex">% <![CDATA[
\hat{\gamma} := n^{-1} \sum_{t=1}^{n-|h|}(x_{t+|h|} - \bar{x})(x_{t} - \bar{x}), -n < h < n %]]></script></p>

<p>The sample autocorrelation function is
<script type="math/tex">% <![CDATA[
\hat{\rho} := \frac{\hat{\gamma}(h)}{\hat{\gamma}(0)}, -n < h < n %]]></script></p>

<h3 id="실제-데이터---초미세먼지-농도">실제 데이터 - 초미세먼지 농도</h3>

<ul>
  <li>데이터 : 서울 용산구 한강대로 405(서울역 앞)의 초미세먼지 농도</li>
  <li>기간 : 	2018-11-18 19:00 ~ 2018-12-18 17:00 (1시간 단위)</li>
</ul>

<p><img src="/assets/img/2018-12-18/df.png" width="300" /></p>

<p><img src="/assets/img/2018-12-18/pm25.png" width="500" /></p>

<p>statmodels 패키지를 이용해 ACF를 바로 구할수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">statsmodels.graphics.tsaplots</span> <span class="kn">import</span> <span class="n">plot_acf</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_acf</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">pm25Value</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/img/2018-12-18/acf.png" width="500" /></p>

<p>acf 그래프를 보면 lag h(가로축)가 증가할수록 값이 점차 감소하며, 일정시간 양의 상관관계를 보이다가 음의 상관관계로 변화하는 패턴이 반복되는 것이 나타납니다(periodic). 이는 시계열 데이터가 stationary하지 않고 시간에 의존되는 성질을 가지고 있다는 것을 의미합니다.</p>

<p>시계열 데이터에서 trend와 seasonality 성분을 추정하는 것을 decompose라고 합니다. 이론적인 내용은 다음 포스팅에서 다루도록하고, 여기서는 결과값만 확인하도록 하겠습니다. statsmodels라는 패키지에서 seasonal_decompose를 사용할수 있습니다. 참고로 seasonal_decompose의 trend estimation은 moving window 방식을 이용합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">statsmodels.tsa.seasonal</span> <span class="kn">import</span> <span class="n">seasonal_decompose</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">pm25Value</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/img/2018-12-18/decompose.png" width="500" /></p>

<p>trend와 seasonality를 제거하고 남은 값(residual)만 가지고 다시 acf를 그려보면 아래와 같습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_acf</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span> 
<span class="n">plot_acf</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">dropna</span><span class="p">(),</span> <span class="n">lags</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> 
</code></pre></div></div>
<p><img src="/assets/img/2018-12-18/residual_acf_all.png" width="500" /></p>

<p>original data의 ACF에서 나타났던 주기적인 변화는 거의 없어진 것을 볼수 있습니다.</p>

<p><img src="/assets/img/2018-12-18/residual_acf.png" width="500" /></p>

<p>하지만 lags=50 이전 부분을 살펴보면 여전히 lags=3까지 강한 상관계수를 갖고 반복적인 변화패턴을 보이는 것을 알수 있습니다. 이는 residual에 남아있는 패턴이 여전히 미래 값을 예측하는데 도움이 되는 것을 의미합니다.</p>

<h3 id="moving-average-and-auto-regressive-process">Moving Average and Auto Regressive process</h3>

<p>시계열 분석의 문제는 stocastic process의 realization인 시계열 데이터 <script type="math/tex">\{X_t\}</script>가 주어졌을때(그리고 <script type="math/tex">\{X_t\}</script>가 stationary할때), 우리는 이 데이터가 생성된 본래의 stocastic process를 모델링하고 싶다는 겁니다. 데이터가 주어져있기때문에 우리는 (sample) mean과 lag에 따른 covariance과 correlation은 쉽게 구할수 있는 상황입니다.(auto covariance function과 auto correlation function)</p>

<p>만약 ACF가 주어졌을때 이에 대응되는 stationary stochatic process가 unique하게 결정된다면 아주 쉬운 문제가 됩니다. analytic한 솔루션이 1개 존재하는 것이고, 그건 공식에 맞춰 계산하면 되는 문제가 되니까요. 그러한 특징과 관련된 2가지 모델을 살펴보도록 하겠습니다.</p>

<p>The MA(q) process:<br />
<script type="math/tex">\{X_t\}</script> is a moving-average process of order q if
<script type="math/tex">X_t = Z_t + \theta_1 Z_{t-1} + ... + \theta_q Z_{t-q}</script> <br />
where <script type="math/tex">\{Z_t\} \sim WN(0, \sigma^2)</script> and <script type="math/tex">\theta_1, ..., \theta_q</script> are constants.</p>

<p><script type="math/tex">\{X_t\}</script>가 t 이전 시점의 white noise <script type="math/tex">\{Z_x\}</script>(s <script type="math/tex">\le</script> t)로 표현되는 프로세스를 Moving Average process라고 합니다.  앞서 본 “stationary” 정의에 따라, MA(q) process는 항상 (weakly) stationary합니다.</p>

<p>invertibility :</p>

<p>흥미롭게도 MA(1)은 AR(<script type="math/tex">\infty</script>)로 변환될수 있습니다. 아래 수식에서 볼수 있듯이 <script type="math/tex">Z_t</script>는 <script type="math/tex">X_t</script>의 과거값들의 linear combination로 표현될수 있습니다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
X_t & = Z_t + \beta Z_{t-1} \\
Z_t & = X_t - \beta Z_{t-1} \\
    & = X_t - \beta(X_{t-1} - \beta Z_{t-2}) \\
    & = X_t - \beta X_{t-1} + \beta^2 (X_{t-2} - \beta Z_{t-3}) \\
    & = X_t - \beta X_{t-1} + \beta^2 X_{t-2} - \beta^3 X_{t-3} + ... + (-\beta)^n Z_{t-n}, &
when \left\vert \beta \right\vert \lt 1, (-\beta)^n Z_{t-n} \approx 0 \\
    & = \sum_{n=0}^{\infty} (-\beta)^nX_{t-n} \\
\end{align} %]]></script>

<p>이러한 성질을 일반화하여 MA(q)에 대해 이야기할 수 있습니다. white noise인 <script type="math/tex">Z_t</script>를 <script type="math/tex">X_t</script>의 무한등비급수의 형태로 표현할수 있다면, 주어진 <script type="math/tex">\{X_t\}</script>는 invertible하다고 정의합니다. 이 때 수렴 조건(MA(1)에서의 <script type="math/tex">\left\vert \beta \right\vert \lt 1</script>)을 invertibility condition이라고 하고 합니다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
Z_t & = \beta(B)X_t, \ & where \ \beta(\cdot) \ are \ the \ q-th \ degree \ polynomials \\
\beta(z) & = 1+ \beta_1 z + ... + \beta_q z^q
\end{align} %]]></script>

<p>자세한 증명은 여기서 다루지 않지만, 결론적으로는 <script type="math/tex">\beta(z)</script>의 해가 unit circle 밖에 있는 경우 invertible 조건을 만족하게 됩니다.</p>

<p>Invertibility is equivalent to the condition</p>

<script type="math/tex; mode=display">\beta(z) = 1+ \beta_1 z + ... + \beta_q z^q \ne 0 \ for \ all \left\vert z \right\vert \le 1</script>

<p>invertible이 중요한 이유는 ACF가 주어질 때, 이 ACF를 만족하는 MA process가 unique하게 결정되기 때문입니다.</p>

<p>두번재 모델은 Auto-Regressive Process입니다. <script type="math/tex">\{X_t\}</script>가 이전 시점의 자기 자신 값 <script type="math/tex">\{X_s\}</script>(s <script type="math/tex">\le</script> t)와 t 시점의 white noise <script type="math/tex">\{Z_x\}</script>로 표현되는 프로세스를 Auto-Regress process라고 합니다. 기억해야할 점은 MA process와 달리 AR process는 항상 stationary한 것은 아니라는 점입니다.</p>

<p>The AR(q) process:<br />
<script type="math/tex">\{X_t\}</script> is a auto-regressive process of order q if
<script type="math/tex">X_t = Z_t + \theta_1 X_{t-1} + ... + \theta_q X_{t-q}</script> <br />
where <script type="math/tex">\{Z_t\} \sim WN(0, \sigma^2)</script> and <script type="math/tex">\theta_1, ..., \theta_q</script> are constants</p>

<p>MA process의 invertibility 와 유사한 개념으로 AR process에 casuality 개념을 도입할수 있습니다. 아래는 AR(1) process를 MA(<script type="math/tex">\infty</script>)로 변환하는 예시입니다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
X_t & = \phi X_{t-1} + Z_t \\
    & = \phi (\phi X_{t-2} + Z_{t-1}) + Z_t \\
    & = \phi^2 X_{t-2} + \phi Z_{t-1} + Z_t  \\
    & = \phi^2 (\phi X_{t-3} + Z_{t-2}) + \phi Z_{t-1} + Z_t \\
    & = Z_t + \phi Z_{t-1} + \phi^2 Z_{t-3} + ... + \phi^n X_{t-n}, &
when \left\vert \phi \right\vert \lt 1, \phi^n X_{t-n} \approx 0 \\
    & = \sum_{n=0}^{\infty} (\phi)^n Z_{t-n} \\
\end{align} %]]></script>

<p><script type="math/tex">X_t</script>를 white noise인 <script type="math/tex">Z_x</script>(단, s <script type="math/tex">\le</script> t)의 linear combination 형태로 표현된다면, 주어진 <script type="math/tex">\{X_t\}</script>는 causal하다고 정의합니다. 위의 예시인 AR(1) process <script type="math/tex">\{X_t\}</script>가 causal하기 위해서는 <script type="math/tex">\left\vert \phi \right\vert \lt 1</script> 입니다.</p>

<p>이러한 성질을 일반적인 AR(p) process에 대해서도 이야기할수 있습니다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
X_t & = \phi(B)X_t, \ & where \ \phi(\cdot) \ are \ the \ p-th \ degree \ polynomials \\
\phi(z) & = 1+ \phi z + ... + \phi_p z^p
\end{align} %]]></script>

<p>자세한 증명은 여기서 다루지 않지만, 결론적으로는 <script type="math/tex">\phi(z)</script>의 해가 unit circle 밖에 있는 경우 causality 조건을 만족하게 됩니다.</p>

<p>Causality is equivalent to the condition</p>

<script type="math/tex; mode=display">\phi(z) = 1 + \phi_1 z + ... + \phi_p z^p \ne 0 \ for \ all \left\vert z \right\vert \le 1</script>

<p>중요한 것은 causality를 만족하는 AR(p) process는 항상 stationary하고, stationary AR(p) process는 항상 causality를 만족합니다.</p>

<h3 id="armap-q">ARMA(p, q)</h3>

<p>AR(p)와 MA(q)가 합쳐진 process를 ARMA(p, q)로 표기하고 ARMA(p,q) process가 유일한 stationary solution <script type="math/tex">\{X_t\}</script>를 갖는 조건은 causality condition을 만족할 때이며, 그 역도 성립합니다.</p>

<p><b>Definition</b></p>

<p><script type="math/tex">\{X_t\}</script> is an ARMA(p, q) process if <script type="math/tex">\{X_t\}</script> is stationary and if for every t,</p>

<script type="math/tex; mode=display">X_t - \phi_1 X_{t-1} - ... - \phi_p X_{t-p} = Z_t + \theta_1 Z_{t-1} + ... + \theta_q Z_{t-q}</script>

<p>where <script type="math/tex">\{Z_t\} \sim WN(0, \sigma^2)</script> and the polynomials <script type="math/tex">( 1 - \phi z - ... - \phi_p z^p)</script> and <script type="math/tex">(1+\theta_1 z + ... + \theta_q z^q )</script> have no common factors.</p>

<p>Existence and Uniqueness :</p>

<p>A stationary solution <script type="math/tex">\{X_t\}</script> of equation ARMA(p, q) exists (and is also the unique stationary solution) if and only if</p>

<script type="math/tex; mode=display">\phi(z) = 1 + \phi_1 z + ... + \phi_p z^p \ne 0 \ for \ all \left\vert z \right\vert \le 1</script>

<p><b>Example</b></p>

<p>아래와 같은 조건을 만족하는 ARMA(1, 1) process <script type="math/tex">\{X_t\}</script>를 생각해보도록 하겠습니다.</p>

<script type="math/tex; mode=display">X_t - 0.5 X_{t-1} = Z_t + 0.4 Z_{t-1}, \ \ \ {Z_t} \sim WN(0, \sigma^2)</script>

<p><script type="math/tex">\phi(z) = 1 - 0.5 z</script>는 z=2 일때 0이 되고, 이는 unit circle밖에 위치하기 때문에 이는 causality 조건을 만족합니다. 즉, 유니크한 솔루션이 존재합니다. causal하기때문에 <script type="math/tex">X_t = \sum_{j=0}^\infty \psi_j Z_{t-j}</script>로 표현되는 constant <script type="math/tex">\{\psi\}</script>가 존재합니다.</p>

<p><script type="math/tex">X_t = \sum_{j=0}^\infty \psi_j Z_{t-j}</script>를 <script type="math/tex">X_t - \phi X_{t-1} = Z_t + \theta Z_{t-1}</script>에 대입하면 아래와 같은 식이 성립해야합니다.</p>

<script type="math/tex; mode=display">(1-\phi z - ... - \phi_p z^p)(\psi_0 +\psi_1 z + ...) = 1 +\theta_1z + ... + \theta_qz^q</script>

<p>양변의 <script type="math/tex">z^j, j=0,1,...</script> 계수가 동일해야하므로,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
1 & = \psi_0 \\
\theta_1 & = \psi_1 - \psi_0 \phi_1 \\
\theta_2 & = \psi_2 - \psi_1 \phi_1 - \psi_0 \phi_2 \\
\vdots
\end{align} %]]></script>

<script type="math/tex; mode=display">\psi_j - \sum_{k=1}^p \phi_k \psi_{j-k} = \theta_j, j=0,1, ...</script>

<p>예제의 계수를 대입하면,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\psi_0 & = 1\\
\psi_1 & = 0.4 + 1 * 0.5   \\
\psi_2 & = 0.5 (0.4 + 0.5) \\
\psi_j & = 0.5^{j-1} (0.4 + 0.5)
\end{align} %]]></script>

<h3 id="particial-acf">Particial ACF</h3>

<h3 id="arima">ARIMA</h3>

<h3 id="다시-미세먼지">다시 미세먼지</h3>

<p><b>reference</b></p>

<p>[1] <a href="https://www.springer.com/us/book/9781475777505">Introduction to Time Series and Forecasting, Peter J. Brockwell, Richard A. Davis,</a></p>

<p>[2] <a href="https://www.statsmodels.org/dev/index.html">Statsmodel’s Documentation</a></p>

<p>[3] <a href="https://www.coursera.org/learn/practical-time-series-analysis/home/info">Practical Time Series Analysis</a></p>

<p>[4] <a href="http://www.kocw.net/home/search/kemView.do?kemId=977301">시계열분석 강의, 한양대학교(이기천)</a></p>

        
      </section>

      <footer class="page__meta">
        
        


  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#time-series" class="page__taxonomy-item" rel="tag">time series</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2018-12-18T00:00:00+09:00">December 18, 2018</time></p>
        
      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=%EC%8B%9C%EA%B3%84%EC%97%B4+%EB%B6%84%EC%84%9D+-+part1%20http%3A%2F%2Flocalhost%3A4000%2Ftime%2520series%2Ftime-series-part1%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Ftime%2520series%2Ftime-series-part1%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http%3A%2F%2Flocalhost%3A4000%2Ftime%2520series%2Ftime-series-part1%2F" class="btn btn--google-plus" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Google Plus"><i class="fab fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Ftime%2520series%2Ftime-series-part1%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/spatio-temporal%20data/ST-resnet/" class="pagination--pager" title="Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 yjucho. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>







    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/time%20series/time-series-part1/";  // Replace PAGE_URL with your page's canonical URL variable
      this.page.identifier = "/time%20series/time-series-part1"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://yjucho.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  



<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



  </body>
</html>